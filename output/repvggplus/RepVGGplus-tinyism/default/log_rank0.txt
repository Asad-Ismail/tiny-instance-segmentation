[2022-12-20 12:46:05 RepVGGplus-tinyism] (train_repvgg.py 258): INFO Full config saved to ./output/repvggplus/RepVGGplus-tinyism/default/config.json
[2022-12-20 12:46:05 RepVGGplus-tinyism] (train_repvgg.py 261): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.2
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: null
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 4
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: hub://aismail2/cucumber_OD
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 4
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  ARCH: RepVGGplus-tinyism
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: ./output/repvggplus/RepVGGplus-tinyism/default
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: default
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 7.8125e-06
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.05

[2022-12-20 12:46:05 RepVGGplus-tinyism] (train_repvgg.py 66): INFO Creating model:RepVGGplus-tinyism
[2022-12-20 12:46:34 RepVGGplus-tinyism] (train_repvgg.py 73): INFO tinyModel(
  (backbone): RepVGGplusPhen(
    (stage0): RepVGGplusBlock(
      (nonlinearity): ReLU()
      (post_se): SEBlock(
        (down): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (up): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (rbr_dense): Sequential(
        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(3, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (stage1): RepVGGplusStage(
      (blocks): ModuleList(
        (0): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_dense): Sequential(
            (conv): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(64, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (4): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (6): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (7): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (stage2): RepVGGplusStage(
      (blocks): ModuleList(
        (0): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_dense): Sequential(
            (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (4): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (6): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (7): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (8): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (9): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (10): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (11): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (12): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (13): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (stage3): RepVGGplusStage(
      (blocks): ModuleList(
        (0): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_dense): Sequential(
            (conv): Conv2d(320, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(320, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (4): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (6): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (7): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (8): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (9): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (10): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (11): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (12): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (13): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (14): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (15): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (16): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (17): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (18): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (19): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (20): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (21): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (22): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (23): RepVGGplusBlock(
          (nonlinearity): ReLU()
          (post_se): SEBlock(
            (down): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (up): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (rbr_identity): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (rbr_dense): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (rbr_1x1): Sequential(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (class_head): Sequential(
    (0): Conv2d(514, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (conv_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_0): ReLU()
    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_1): ReLU()
    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_2): ReLU()
    (conv_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_3): ReLU()
    (conv_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_4): ReLU()
    (conv_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_5): ReLU()
    (cls): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (box_head): Sequential(
    (0): Conv2d(514, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (conv_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_0): ReLU()
    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_1): ReLU()
    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_2): ReLU()
    (conv_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_3): ReLU()
    (conv_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_4): ReLU()
    (conv_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_5): ReLU()
  )
  (box): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (offset_head): Sequential(
    (0): Conv2d(514, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (conv_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_0): ReLU()
    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_1): ReLU()
    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_2): ReLU()
    (conv_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_3): ReLU()
    (conv_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_4): ReLU()
    (conv_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_5): ReLU()
  )
  (offset): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
  (seg_head): Sequential(
    (0): Conv2d(5, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (conv_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_0): ReLU()
    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_1): ReLU()
    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_2): ReLU()
    (conv_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_3): ReLU()
    (conv_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_4): ReLU()
    (conv_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu_5): ReLU()
  )
  (seg): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
[2022-12-20 12:46:36 RepVGGplus-tinyism] (train_repvgg.py 88): INFO number of params: 99485497
[2022-12-20 12:46:36 RepVGGplus-tinyism] (train_repvgg.py 104): INFO Start training
[2022-12-20 12:46:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][0/74]	eta 0:05:07 lr 0.000000	time 4.1589 (4.1589)	loss 277.9577 (277.9577)	grad_norm 26.9124 (26.9124)	mem 14369MB
[2022-12-20 12:46:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][10/74]	eta 0:01:16 lr 0.000000	time 0.9667 (1.2010)	loss 243.5136 (265.7517)	grad_norm 22.6654 (24.0208)	mem 14369MB
[2022-12-20 12:46:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][20/74]	eta 0:00:57 lr 0.000000	time 0.8640 (1.0608)	loss 257.5560 (257.2241)	grad_norm 28.8696 (24.4302)	mem 14369MB
[2022-12-20 12:47:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][30/74]	eta 0:00:44 lr 0.000000	time 0.8576 (1.0064)	loss 210.5063 (242.4778)	grad_norm 30.5937 (24.5731)	mem 14369MB
[2022-12-20 12:47:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][40/74]	eta 0:00:32 lr 0.000000	time 0.8551 (0.9702)	loss 267.4217 (240.4779)	grad_norm 14.5302 (24.2888)	mem 14369MB
[2022-12-20 12:47:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][50/74]	eta 0:00:22 lr 0.000000	time 0.8665 (0.9513)	loss 186.2683 (241.0107)	grad_norm 24.8863 (23.6474)	mem 14369MB
[2022-12-20 12:47:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][60/74]	eta 0:00:13 lr 0.000000	time 0.8538 (0.9360)	loss 249.7673 (243.8451)	grad_norm 16.7187 (23.5139)	mem 14369MB
[2022-12-20 12:47:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [0/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8555 (0.9248)	loss 259.2487 (245.7738)	grad_norm 26.6949 (23.6379)	mem 14369MB
[2022-12-20 12:47:45 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 0 training takes 0:01:08
[2022-12-20 12:47:45 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_0.pth saving......
[2022-12-20 12:47:46 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_0.pth saved !!!
[2022-12-20 12:47:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][0/74]	eta 0:01:50 lr 0.000000	time 1.4953 (1.4953)	loss 239.8614 (239.8614)	grad_norm 25.0708 (25.0708)	mem 14369MB
[2022-12-20 12:47:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8642 (0.9259)	loss 227.2240 (230.0052)	grad_norm 32.8802 (27.6639)	mem 14369MB
[2022-12-20 12:48:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8620 (0.8956)	loss 250.2435 (235.6797)	grad_norm 36.8637 (26.3249)	mem 14369MB
[2022-12-20 12:48:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][30/74]	eta 0:00:38 lr 0.000001	time 0.8580 (0.8831)	loss 247.1859 (242.8040)	grad_norm 21.4748 (23.8652)	mem 14369MB
[2022-12-20 12:48:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][40/74]	eta 0:00:29 lr 0.000001	time 0.8559 (0.8775)	loss 261.7065 (240.6149)	grad_norm 28.9742 (23.7276)	mem 14369MB
[2022-12-20 12:48:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][50/74]	eta 0:00:20 lr 0.000001	time 0.8726 (0.8749)	loss 171.3958 (239.3163)	grad_norm 15.9068 (23.0221)	mem 14369MB
[2022-12-20 12:48:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8560 (0.8722)	loss 240.1192 (241.9460)	grad_norm 38.7077 (23.2219)	mem 14369MB
[2022-12-20 12:48:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [1/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8784 (0.8707)	loss 192.8998 (242.5929)	grad_norm 12.4167 (23.7803)	mem 14369MB
[2022-12-20 12:48:50 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 1 training takes 0:01:04
[2022-12-20 12:48:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5197 (1.5197)	loss 208.5481 (208.5481)	grad_norm 13.1999 (13.1999)	mem 14369MB
[2022-12-20 12:49:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8644 (0.9299)	loss 257.5915 (234.1872)	grad_norm 38.0263 (21.0664)	mem 14369MB
[2022-12-20 12:49:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8709 (0.9021)	loss 233.8179 (233.8174)	grad_norm 23.7725 (21.0429)	mem 14369MB
[2022-12-20 12:49:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8646 (0.8908)	loss 331.1351 (247.3703)	grad_norm 27.5907 (22.7988)	mem 14369MB
[2022-12-20 12:49:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8648 (0.8853)	loss 192.1313 (247.3196)	grad_norm 31.9462 (22.8524)	mem 14369MB
[2022-12-20 12:49:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8670 (0.8822)	loss 226.9350 (245.8667)	grad_norm 29.6184 (23.8470)	mem 14369MB
[2022-12-20 12:49:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8672 (0.8806)	loss 203.4644 (245.4322)	grad_norm 28.8383 (23.2883)	mem 14369MB
[2022-12-20 12:49:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [2/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8596 (0.8784)	loss 324.6681 (243.9808)	grad_norm 20.3365 (23.0995)	mem 14369MB
[2022-12-20 12:49:55 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 2 training takes 0:01:04
[2022-12-20 12:49:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5231 (1.5231)	loss 194.2691 (194.2691)	grad_norm 13.3917 (13.3917)	mem 14369MB
[2022-12-20 12:50:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8702 (0.9274)	loss 233.4407 (235.7221)	grad_norm 20.8227 (21.9779)	mem 14369MB
[2022-12-20 12:50:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8701 (0.8996)	loss 215.9071 (234.1284)	grad_norm 13.1652 (22.4210)	mem 14369MB
[2022-12-20 12:50:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8758 (0.8887)	loss 184.0252 (237.2251)	grad_norm 13.3091 (21.5786)	mem 14369MB
[2022-12-20 12:50:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][40/74]	eta 0:00:29 lr 0.000001	time 0.8605 (0.8818)	loss 246.7920 (239.3168)	grad_norm 35.4255 (22.5866)	mem 14369MB
[2022-12-20 12:50:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8606 (0.8788)	loss 271.4241 (237.3723)	grad_norm 21.4150 (22.5294)	mem 14369MB
[2022-12-20 12:50:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8709 (0.8767)	loss 217.4449 (242.3526)	grad_norm 44.2362 (22.9580)	mem 14369MB
[2022-12-20 12:50:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [3/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8682 (0.8761)	loss 256.5298 (242.5810)	grad_norm 15.7196 (22.9994)	mem 14369MB
[2022-12-20 12:51:00 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 3 training takes 0:01:04
[2022-12-20 12:51:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5090 (1.5090)	loss 232.8025 (232.8025)	grad_norm 40.0446 (40.0446)	mem 14369MB
[2022-12-20 12:51:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8581 (0.9236)	loss 260.0428 (234.3724)	grad_norm 16.5083 (24.5274)	mem 14369MB
[2022-12-20 12:51:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8600 (0.8968)	loss 310.5063 (241.1627)	grad_norm 15.8755 (22.7955)	mem 14369MB
[2022-12-20 12:51:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][30/74]	eta 0:00:38 lr 0.000002	time 0.8598 (0.8863)	loss 220.1901 (240.5543)	grad_norm 35.9606 (23.1252)	mem 14369MB
[2022-12-20 12:51:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][40/74]	eta 0:00:29 lr 0.000002	time 0.8819 (0.8810)	loss 172.4373 (240.8015)	grad_norm 18.4341 (23.5509)	mem 14369MB
[2022-12-20 12:51:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8623 (0.8785)	loss 281.5208 (241.1384)	grad_norm 22.3619 (22.8113)	mem 14369MB
[2022-12-20 12:51:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8571 (0.8763)	loss 309.0003 (242.5881)	grad_norm 34.7961 (23.4693)	mem 14369MB
[2022-12-20 12:52:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [4/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8588 (0.8752)	loss 338.4731 (243.0051)	grad_norm 16.7135 (23.2230)	mem 14369MB
[2022-12-20 12:52:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 4 training takes 0:01:04
[2022-12-20 12:52:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5083 (1.5083)	loss 274.1752 (274.1752)	grad_norm 26.9494 (26.9494)	mem 14369MB
[2022-12-20 12:52:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8772 (0.9230)	loss 189.7259 (253.9205)	grad_norm 16.3370 (21.7877)	mem 14369MB
[2022-12-20 12:52:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8686 (0.8963)	loss 230.0674 (238.9777)	grad_norm 31.9558 (20.6157)	mem 14369MB
[2022-12-20 12:52:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][30/74]	eta 0:00:38 lr 0.000002	time 0.8773 (0.8860)	loss 221.9005 (241.4928)	grad_norm 19.8305 (21.4428)	mem 14369MB
[2022-12-20 12:52:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8818 (0.8835)	loss 202.2793 (240.8118)	grad_norm 12.9993 (21.7466)	mem 14369MB
[2022-12-20 12:52:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8804 (0.8815)	loss 188.8193 (241.5578)	grad_norm 13.7370 (22.0634)	mem 14369MB
[2022-12-20 12:52:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8654 (0.8796)	loss 343.4555 (243.5094)	grad_norm 27.6616 (22.1749)	mem 14369MB
[2022-12-20 12:53:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [5/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8750 (0.8779)	loss 238.2914 (241.8605)	grad_norm 18.5607 (22.3567)	mem 14369MB
[2022-12-20 12:53:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 5 training takes 0:01:04
[2022-12-20 12:53:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][0/74]	eta 0:01:50 lr 0.000002	time 1.4927 (1.4927)	loss 287.7214 (287.7214)	grad_norm 16.2620 (16.2620)	mem 14369MB
[2022-12-20 12:53:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][10/74]	eta 0:00:58 lr 0.000002	time 0.8570 (0.9193)	loss 334.8517 (257.4683)	grad_norm 20.1239 (25.1742)	mem 14369MB
[2022-12-20 12:53:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8576 (0.8933)	loss 264.1980 (250.9329)	grad_norm 14.4582 (24.9438)	mem 14369MB
[2022-12-20 12:53:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][30/74]	eta 0:00:38 lr 0.000003	time 0.8594 (0.8834)	loss 284.3130 (257.8713)	grad_norm 16.9808 (23.7079)	mem 14369MB
[2022-12-20 12:53:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][40/74]	eta 0:00:29 lr 0.000003	time 0.8626 (0.8801)	loss 255.3421 (252.3044)	grad_norm 22.5175 (23.0399)	mem 14369MB
[2022-12-20 12:53:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8623 (0.8794)	loss 304.0378 (247.0816)	grad_norm 19.3029 (23.1639)	mem 14369MB
[2022-12-20 12:54:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8617 (0.8774)	loss 249.5291 (248.3241)	grad_norm 36.6099 (23.6796)	mem 14369MB
[2022-12-20 12:54:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [6/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8767 (0.8777)	loss 260.5732 (245.1410)	grad_norm 25.1188 (23.2048)	mem 14369MB
[2022-12-20 12:54:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 6 training takes 0:01:04
[2022-12-20 12:54:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5165 (1.5165)	loss 258.2765 (258.2765)	grad_norm 16.2787 (16.2787)	mem 14369MB
[2022-12-20 12:54:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8707 (0.9297)	loss 220.6587 (239.4083)	grad_norm 16.5595 (22.7566)	mem 14369MB
[2022-12-20 12:54:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8750 (0.9019)	loss 262.5107 (237.3565)	grad_norm 17.5539 (21.4309)	mem 14369MB
[2022-12-20 12:54:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8798 (0.8930)	loss 211.8183 (240.4717)	grad_norm 28.2540 (23.4935)	mem 14369MB
[2022-12-20 12:54:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8679 (0.8886)	loss 314.8716 (240.1968)	grad_norm 38.9069 (23.6104)	mem 14369MB
[2022-12-20 12:54:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8717 (0.8861)	loss 209.6327 (239.5030)	grad_norm 24.2246 (23.4377)	mem 14369MB
[2022-12-20 12:55:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8636 (0.8835)	loss 354.9379 (242.3417)	grad_norm 20.5694 (23.8309)	mem 14369MB
[2022-12-20 12:55:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [7/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8616 (0.8811)	loss 315.2227 (241.9028)	grad_norm 17.7189 (23.3394)	mem 14369MB
[2022-12-20 12:55:19 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 7 training takes 0:01:05
[2022-12-20 12:55:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5178 (1.5178)	loss 229.3497 (229.3497)	grad_norm 23.4329 (23.4329)	mem 14369MB
[2022-12-20 12:55:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8631 (0.9248)	loss 222.9404 (242.5019)	grad_norm 18.7648 (29.9686)	mem 14369MB
[2022-12-20 12:55:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8621 (0.8998)	loss 220.6835 (238.0973)	grad_norm 20.4407 (25.8192)	mem 14369MB
[2022-12-20 12:55:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8599 (0.8886)	loss 267.4884 (238.5988)	grad_norm 28.3679 (25.2045)	mem 14369MB
[2022-12-20 12:55:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8629 (0.8836)	loss 282.6867 (237.8398)	grad_norm 17.3312 (24.9254)	mem 14369MB
[2022-12-20 12:56:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8667 (0.8808)	loss 336.5232 (243.9199)	grad_norm 20.6009 (24.6126)	mem 14369MB
[2022-12-20 12:56:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8587 (0.8784)	loss 353.1992 (245.6454)	grad_norm 21.8255 (24.2746)	mem 14369MB
[2022-12-20 12:56:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [8/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8633 (0.8797)	loss 313.5023 (245.9157)	grad_norm 21.1464 (24.0915)	mem 14369MB
[2022-12-20 12:56:24 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 8 training takes 0:01:04
[2022-12-20 12:56:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5160 (1.5160)	loss 285.0069 (285.0069)	grad_norm 19.5175 (19.5175)	mem 14369MB
[2022-12-20 12:56:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8711 (0.9276)	loss 170.5047 (246.8223)	grad_norm 31.7457 (23.1041)	mem 14369MB
[2022-12-20 12:56:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8733 (0.8988)	loss 195.8306 (242.4223)	grad_norm 26.7431 (24.1468)	mem 14369MB
[2022-12-20 12:56:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8670 (0.8904)	loss 244.7236 (247.3765)	grad_norm 40.2214 (25.0339)	mem 14369MB
[2022-12-20 12:57:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8717 (0.8851)	loss 287.5259 (248.2160)	grad_norm 28.7010 (24.1799)	mem 14369MB
[2022-12-20 12:57:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8823 (0.8824)	loss 205.5524 (245.2836)	grad_norm 20.1110 (23.9476)	mem 14369MB
[2022-12-20 12:57:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8729 (0.8806)	loss 208.1473 (243.3091)	grad_norm 22.0360 (23.8910)	mem 14369MB
[2022-12-20 12:57:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [9/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8650 (0.8798)	loss 192.6472 (240.8862)	grad_norm 26.1886 (23.8630)	mem 14369MB
[2022-12-20 12:57:29 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 9 training takes 0:01:04
[2022-12-20 12:57:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][0/74]	eta 0:01:51 lr 0.000004	time 1.5126 (1.5126)	loss 249.4545 (249.4545)	grad_norm 22.1601 (22.1601)	mem 14369MB
[2022-12-20 12:57:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8694 (0.9271)	loss 270.0348 (251.0032)	grad_norm 24.2317 (22.8051)	mem 14369MB
[2022-12-20 12:57:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8772 (0.8996)	loss 217.7528 (242.2254)	grad_norm 15.1910 (23.3110)	mem 14369MB
[2022-12-20 12:57:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8893 (0.8915)	loss 149.2285 (232.5244)	grad_norm 16.5038 (23.1081)	mem 14369MB
[2022-12-20 12:58:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8713 (0.8870)	loss 232.5096 (233.5941)	grad_norm 36.1299 (23.9246)	mem 14369MB
[2022-12-20 12:58:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8723 (0.8843)	loss 229.9519 (233.8901)	grad_norm 27.6194 (24.7501)	mem 14369MB
[2022-12-20 12:58:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8656 (0.8818)	loss 237.5311 (236.1704)	grad_norm 19.0315 (24.4232)	mem 14369MB
[2022-12-20 12:58:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [10/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8683 (0.8796)	loss 225.2684 (238.6981)	grad_norm 54.0710 (25.5306)	mem 14369MB
[2022-12-20 12:58:34 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 10 training takes 0:01:04
[2022-12-20 12:58:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][0/74]	eta 0:01:50 lr 0.000004	time 1.4997 (1.4997)	loss 268.8204 (268.8204)	grad_norm 21.8734 (21.8734)	mem 14369MB
[2022-12-20 12:58:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8699 (0.9268)	loss 235.7281 (218.4814)	grad_norm 19.1776 (23.2427)	mem 14369MB
[2022-12-20 12:58:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8804 (0.8976)	loss 185.9658 (227.7275)	grad_norm 30.6274 (25.2731)	mem 14369MB
[2022-12-20 12:59:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8635 (0.8889)	loss 338.9831 (239.2867)	grad_norm 20.8630 (24.9690)	mem 14369MB
[2022-12-20 12:59:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8669 (0.8844)	loss 248.0689 (238.5161)	grad_norm 38.4285 (25.4812)	mem 14369MB
[2022-12-20 12:59:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8881 (0.8826)	loss 205.5028 (236.5306)	grad_norm 35.6689 (26.0587)	mem 14369MB
[2022-12-20 12:59:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8629 (0.8799)	loss 235.5779 (243.0235)	grad_norm 28.6500 (26.3316)	mem 14369MB
[2022-12-20 12:59:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [11/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8871 (0.8791)	loss 223.3887 (241.2724)	grad_norm 31.5522 (26.8040)	mem 14369MB
[2022-12-20 12:59:39 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 11 training takes 0:01:04
[2022-12-20 12:59:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5178 (1.5178)	loss 227.7881 (227.7881)	grad_norm 19.4348 (19.4348)	mem 14369MB
[2022-12-20 12:59:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8694 (0.9273)	loss 264.2258 (245.4403)	grad_norm 27.1517 (26.6750)	mem 14369MB
[2022-12-20 12:59:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8649 (0.9010)	loss 318.7957 (235.3557)	grad_norm 31.2524 (26.8245)	mem 14369MB
[2022-12-20 13:00:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8634 (0.8914)	loss 236.6828 (234.7115)	grad_norm 25.9186 (27.3165)	mem 14369MB
[2022-12-20 13:00:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8695 (0.8859)	loss 296.4655 (236.8712)	grad_norm 22.3635 (29.0638)	mem 14369MB
[2022-12-20 13:00:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8661 (0.8827)	loss 195.4218 (235.0915)	grad_norm 49.9450 (29.0999)	mem 14369MB
[2022-12-20 13:00:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8653 (0.8805)	loss 365.2902 (237.5440)	grad_norm 29.5208 (29.7788)	mem 14369MB
[2022-12-20 13:00:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [12/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8655 (0.8790)	loss 245.3044 (237.9529)	grad_norm 25.5481 (29.2097)	mem 14369MB
[2022-12-20 13:00:44 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 12 training takes 0:01:04
[2022-12-20 13:00:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][0/74]	eta 0:01:51 lr 0.000005	time 1.5072 (1.5072)	loss 308.7256 (308.7256)	grad_norm 40.0437 (40.0437)	mem 14369MB
[2022-12-20 13:00:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8706 (0.9256)	loss 191.4284 (229.4974)	grad_norm 27.7052 (34.4166)	mem 14369MB
[2022-12-20 13:01:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8851 (0.8989)	loss 184.9854 (241.9414)	grad_norm 20.2161 (34.2064)	mem 14369MB
[2022-12-20 13:01:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8569 (0.8885)	loss 241.1823 (244.9478)	grad_norm 24.6651 (34.1215)	mem 14369MB
[2022-12-20 13:01:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8699 (0.8856)	loss 226.8387 (243.0888)	grad_norm 29.4789 (33.0939)	mem 14369MB
[2022-12-20 13:01:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8906 (0.8842)	loss 193.1386 (238.4820)	grad_norm 34.2623 (33.1010)	mem 14369MB
[2022-12-20 13:01:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8705 (0.8825)	loss 251.4765 (237.3347)	grad_norm 49.4462 (34.0584)	mem 14369MB
[2022-12-20 13:01:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [13/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8678 (0.8816)	loss 264.6718 (236.9319)	grad_norm 25.7618 (33.5805)	mem 14369MB
[2022-12-20 13:01:49 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 13 training takes 0:01:05
[2022-12-20 13:01:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5222 (1.5222)	loss 184.0227 (184.0227)	grad_norm 35.7774 (35.7774)	mem 14369MB
[2022-12-20 13:02:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8848 (0.9311)	loss 152.4115 (220.5169)	grad_norm 35.5787 (32.8076)	mem 14369MB
[2022-12-20 13:02:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8781 (0.9025)	loss 242.8951 (224.7541)	grad_norm 36.5393 (36.9693)	mem 14369MB
[2022-12-20 13:02:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8689 (0.8909)	loss 253.8028 (230.2962)	grad_norm 40.0152 (40.8697)	mem 14369MB
[2022-12-20 13:02:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8806 (0.8856)	loss 185.1178 (228.6925)	grad_norm 26.3400 (41.4886)	mem 14369MB
[2022-12-20 13:02:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8682 (0.8822)	loss 208.1736 (230.3364)	grad_norm 45.0894 (41.5539)	mem 14369MB
[2022-12-20 13:02:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8709 (0.8796)	loss 188.1916 (232.0020)	grad_norm 73.3688 (43.8957)	mem 14369MB
[2022-12-20 13:02:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [14/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8679 (0.8785)	loss 250.5460 (232.5907)	grad_norm 39.6969 (43.9575)	mem 14369MB
[2022-12-20 13:02:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 14 training takes 0:01:04
[2022-12-20 13:02:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5095 (1.5095)	loss 217.7280 (217.7280)	grad_norm 54.9224 (54.9224)	mem 14369MB
[2022-12-20 13:03:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8767 (0.9354)	loss 226.4308 (221.1001)	grad_norm 94.1940 (63.9405)	mem 14369MB
[2022-12-20 13:03:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8865 (0.9068)	loss 201.6998 (227.2603)	grad_norm 44.6207 (57.2217)	mem 14369MB
[2022-12-20 13:03:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8700 (0.8961)	loss 246.7169 (230.8075)	grad_norm 40.6043 (56.4893)	mem 14369MB
[2022-12-20 13:03:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8747 (0.8915)	loss 243.7332 (227.9633)	grad_norm 53.8875 (56.5991)	mem 14369MB
[2022-12-20 13:03:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8860 (0.8875)	loss 188.7473 (230.1602)	grad_norm 37.7675 (57.3481)	mem 14369MB
[2022-12-20 13:03:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8648 (0.8843)	loss 257.5155 (231.5577)	grad_norm 104.0132 (62.8138)	mem 14369MB
[2022-12-20 13:03:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [15/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8688 (0.8822)	loss 264.6758 (230.4045)	grad_norm 61.9582 (63.0171)	mem 14369MB
[2022-12-20 13:04:00 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 15 training takes 0:01:05
[2022-12-20 13:04:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5263 (1.5263)	loss 255.8961 (255.8961)	grad_norm 97.8803 (97.8803)	mem 14369MB
[2022-12-20 13:04:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8606 (0.9282)	loss 231.8505 (233.5360)	grad_norm 167.2952 (91.9854)	mem 14369MB
[2022-12-20 13:04:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8682 (0.9000)	loss 163.4734 (227.6602)	grad_norm 63.0835 (96.1977)	mem 14369MB
[2022-12-20 13:04:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8735 (0.8908)	loss 222.3034 (226.3279)	grad_norm 217.4460 (102.9351)	mem 14369MB
[2022-12-20 13:04:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8649 (0.8855)	loss 218.7460 (224.9350)	grad_norm 141.3377 (108.4582)	mem 14369MB
[2022-12-20 13:04:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8726 (0.8822)	loss 153.9428 (224.2138)	grad_norm 173.2384 (113.7491)	mem 14369MB
[2022-12-20 13:04:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8826 (0.8803)	loss 180.8963 (222.3254)	grad_norm 216.3193 (131.2152)	mem 14369MB
[2022-12-20 13:05:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [16/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8766 (0.8784)	loss 161.8390 (221.7800)	grad_norm 249.8550 (139.9927)	mem 14369MB
[2022-12-20 13:05:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 16 training takes 0:01:04
[2022-12-20 13:05:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5195 (1.5195)	loss 206.2415 (206.2415)	grad_norm 229.4078 (229.4078)	mem 14369MB
[2022-12-20 13:05:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8761 (0.9281)	loss 148.9406 (204.0049)	grad_norm 616.3283 (285.8886)	mem 14369MB
[2022-12-20 13:05:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8792 (0.9012)	loss 208.7398 (201.8387)	grad_norm 410.1944 (337.1994)	mem 14369MB
[2022-12-20 13:05:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8785 (0.8938)	loss 152.6578 (193.2608)	grad_norm 1278.0340 (461.7440)	mem 14369MB
[2022-12-20 13:05:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8837 (0.8886)	loss 154.4314 (194.0990)	grad_norm 734.6105 (644.7284)	mem 14369MB
[2022-12-20 13:05:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8652 (0.8855)	loss 159.7240 (189.8756)	grad_norm 2268.2370 (1089.0855)	mem 14369MB
[2022-12-20 13:05:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8721 (0.8836)	loss 166.5424 (181.3349)	grad_norm 5523.5804 (1757.8526)	mem 14369MB
[2022-12-20 13:06:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [17/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8803 (0.8827)	loss 114.7012 (171.6303)	grad_norm 7267.5292 (2118.2800)	mem 14369MB
[2022-12-20 13:06:10 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 17 training takes 0:01:05
[2022-12-20 13:06:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5188 (1.5188)	loss 74.8110 (74.8110)	grad_norm 2617.8765 (2617.8765)	mem 14369MB
[2022-12-20 13:06:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8623 (0.9284)	loss 41.3733 (59.7926)	grad_norm 3331.9717 (4050.7332)	mem 14369MB
[2022-12-20 13:06:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8700 (0.9016)	loss 91.9493 (59.7776)	grad_norm 1380.7578 (4044.4137)	mem 14369MB
[2022-12-20 13:06:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8668 (0.8915)	loss 70.1437 (60.0024)	grad_norm 3645.1508 (3812.7492)	mem 14369MB
[2022-12-20 13:06:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8729 (0.8861)	loss 23.4651 (55.2783)	grad_norm 4102.2478 (3896.2921)	mem 14369MB
[2022-12-20 13:06:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8695 (0.8839)	loss 73.0186 (54.2315)	grad_norm 1605.8655 (3727.8643)	mem 14369MB
[2022-12-20 13:07:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8666 (0.8816)	loss 30.0213 (51.7095)	grad_norm 2759.9649 (3533.6870)	mem 14369MB
[2022-12-20 13:07:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [18/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8652 (0.8806)	loss 15.4422 (52.2006)	grad_norm 2714.9148 (3389.8010)	mem 14369MB
[2022-12-20 13:07:15 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 18 training takes 0:01:05
[2022-12-20 13:07:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][0/74]	eta 0:01:51 lr 0.000007	time 1.5085 (1.5085)	loss 22.9957 (22.9957)	grad_norm 3577.6424 (3577.6424)	mem 14369MB
[2022-12-20 13:07:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8795 (0.9261)	loss 43.0450 (34.7881)	grad_norm 1386.8922 (2835.5011)	mem 14369MB
[2022-12-20 13:07:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8765 (0.8999)	loss 39.6587 (45.3748)	grad_norm 1539.4036 (2578.2745)	mem 14369MB
[2022-12-20 13:07:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8796 (0.8917)	loss 9.7119 (39.5764)	grad_norm 1263.4670 (2305.6064)	mem 14369MB
[2022-12-20 13:07:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8662 (0.8884)	loss 67.9218 (47.6248)	grad_norm 1878.1065 (2180.4390)	mem 14369MB
[2022-12-20 13:08:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8704 (0.8844)	loss 11.1500 (45.9986)	grad_norm 1152.0441 (2150.7448)	mem 14369MB
[2022-12-20 13:08:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8886 (0.8838)	loss 12.7988 (45.6514)	grad_norm 1038.6562 (2039.9335)	mem 14369MB
[2022-12-20 13:08:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [19/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8863 (0.8822)	loss 13.6569 (44.4099)	grad_norm 1134.2902 (2036.7816)	mem 14369MB
[2022-12-20 13:08:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 19 training takes 0:01:05
[2022-12-20 13:08:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][0/74]	eta 0:01:54 lr 0.000008	time 1.5482 (1.5482)	loss 10.0413 (10.0413)	grad_norm 1111.4902 (1111.4902)	mem 14369MB
[2022-12-20 13:08:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8715 (0.9347)	loss 80.0296 (53.4113)	grad_norm 3139.1583 (1727.2318)	mem 14369MB
[2022-12-20 13:08:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8749 (0.9054)	loss 100.4580 (56.2287)	grad_norm 1489.0331 (2099.8823)	mem 14369MB
[2022-12-20 13:08:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8704 (0.8938)	loss 56.0271 (53.0271)	grad_norm 1779.4068 (2068.7541)	mem 14369MB
[2022-12-20 13:08:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8757 (0.8914)	loss 82.3517 (49.2496)	grad_norm 1174.7378 (1948.2727)	mem 14369MB
[2022-12-20 13:09:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8745 (0.8886)	loss 87.4721 (45.5904)	grad_norm 1410.8836 (1960.3791)	mem 14369MB
[2022-12-20 13:09:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8759 (0.8863)	loss 11.1840 (44.1387)	grad_norm 1423.2443 (1940.2181)	mem 14369MB
[2022-12-20 13:09:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [20/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8810 (0.8853)	loss 55.5920 (43.8475)	grad_norm 709.1097 (1884.8389)	mem 14369MB
[2022-12-20 13:09:25 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 20 training takes 0:01:05
[2022-12-20 13:09:25 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_20.pth saving......
[2022-12-20 13:09:27 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_20.pth saved !!!
[2022-12-20 13:09:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][0/74]	eta 0:01:52 lr 0.000008	time 1.5137 (1.5137)	loss 10.3970 (10.3970)	grad_norm 1245.2772 (1245.2772)	mem 14369MB
[2022-12-20 13:09:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8698 (0.9308)	loss 77.4496 (60.3446)	grad_norm 1095.3207 (1430.1482)	mem 14369MB
[2022-12-20 13:09:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8673 (0.9022)	loss 52.8175 (54.4080)	grad_norm 1031.4357 (1405.3941)	mem 14369MB
[2022-12-20 13:09:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8625 (0.8912)	loss 77.8587 (51.4526)	grad_norm 744.4170 (1389.4448)	mem 14369MB
[2022-12-20 13:10:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8538 (0.8850)	loss 11.3242 (47.8691)	grad_norm 1601.9220 (1431.4289)	mem 14369MB
[2022-12-20 13:10:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8695 (0.8824)	loss 17.6836 (42.5742)	grad_norm 1789.4626 (1407.3967)	mem 14369MB
[2022-12-20 13:10:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8710 (0.8800)	loss 12.4215 (42.8157)	grad_norm 722.1056 (1468.0422)	mem 14369MB
[2022-12-20 13:10:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [21/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8739 (0.8798)	loss 57.1486 (43.1497)	grad_norm 719.4827 (1410.4325)	mem 14369MB
[2022-12-20 13:10:32 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 21 training takes 0:01:04
[2022-12-20 13:10:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][0/74]	eta 0:01:52 lr 0.000008	time 1.5186 (1.5186)	loss 9.6407 (9.6407)	grad_norm 803.1709 (803.1709)	mem 14369MB
[2022-12-20 13:10:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8792 (0.9316)	loss 38.8866 (33.8003)	grad_norm 1076.8936 (1157.1912)	mem 14369MB
[2022-12-20 13:10:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8654 (0.9039)	loss 79.4436 (43.9137)	grad_norm 411.8314 (1087.1877)	mem 14369MB
[2022-12-20 13:11:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8776 (0.9001)	loss 32.7380 (40.5451)	grad_norm 1034.2180 (1143.5223)	mem 14369MB
[2022-12-20 13:11:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8868 (0.8940)	loss 91.9193 (44.4457)	grad_norm 646.2618 (1126.8797)	mem 14369MB
[2022-12-20 13:11:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8687 (0.8889)	loss 42.6331 (45.2556)	grad_norm 2158.1177 (1248.0331)	mem 14369MB
[2022-12-20 13:11:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8657 (0.8856)	loss 54.3765 (44.3641)	grad_norm 3275.3753 (1266.0708)	mem 14369MB
[2022-12-20 13:11:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [22/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8673 (0.8843)	loss 86.9747 (43.4136)	grad_norm 2036.5146 (1275.1653)	mem 14369MB
[2022-12-20 13:11:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 22 training takes 0:01:05
[2022-12-20 13:11:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][0/74]	eta 0:01:53 lr 0.000008	time 1.5323 (1.5323)	loss 58.4631 (58.4631)	grad_norm 2291.8146 (2291.8146)	mem 14369MB
[2022-12-20 13:11:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8664 (0.9349)	loss 16.9374 (33.8403)	grad_norm 2026.8893 (1396.3937)	mem 14369MB
[2022-12-20 13:11:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][20/74]	eta 0:00:49 lr 0.000008	time 0.8791 (0.9091)	loss 35.7856 (44.8276)	grad_norm 930.5658 (1254.3058)	mem 14369MB
[2022-12-20 13:12:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8873 (0.8989)	loss 24.6959 (49.4580)	grad_norm 2375.7966 (1263.1413)	mem 14369MB
[2022-12-20 13:12:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8745 (0.8934)	loss 11.7121 (47.7908)	grad_norm 857.8021 (1269.0321)	mem 14369MB
[2022-12-20 13:12:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8743 (0.8902)	loss 9.4398 (44.1862)	grad_norm 1079.8491 (1280.4886)	mem 14369MB
[2022-12-20 13:12:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8664 (0.8869)	loss 43.8165 (44.5847)	grad_norm 933.5572 (1260.7844)	mem 14369MB
[2022-12-20 13:12:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [23/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8687 (0.8845)	loss 75.6470 (43.7305)	grad_norm 1794.1949 (1255.7915)	mem 14369MB
[2022-12-20 13:12:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 23 training takes 0:01:05
[2022-12-20 13:12:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][0/74]	eta 0:01:54 lr 0.000008	time 1.5443 (1.5443)	loss 83.7770 (83.7770)	grad_norm 906.8955 (906.8955)	mem 14369MB
[2022-12-20 13:12:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8681 (0.9340)	loss 8.2550 (28.8063)	grad_norm 905.2766 (1332.0748)	mem 14369MB
[2022-12-20 13:13:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8785 (0.9047)	loss 10.0647 (34.7264)	grad_norm 689.5137 (1297.6284)	mem 14369MB
[2022-12-20 13:13:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8794 (0.8940)	loss 7.2310 (36.3418)	grad_norm 746.3910 (1252.6102)	mem 14369MB
[2022-12-20 13:13:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8652 (0.8889)	loss 70.7860 (41.8946)	grad_norm 1633.2455 (1160.8681)	mem 14369MB
[2022-12-20 13:13:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8733 (0.8866)	loss 18.2227 (44.2570)	grad_norm 1878.0832 (1197.0831)	mem 14369MB
[2022-12-20 13:13:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8846 (0.8853)	loss 56.9498 (43.3351)	grad_norm 873.7392 (1228.8373)	mem 14369MB
[2022-12-20 13:13:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [24/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8704 (0.8841)	loss 53.0098 (42.3922)	grad_norm 716.2635 (1264.5488)	mem 14369MB
[2022-12-20 13:13:48 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 24 training takes 0:01:05
[2022-12-20 13:13:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][0/74]	eta 0:01:52 lr 0.000008	time 1.5166 (1.5166)	loss 11.9343 (11.9343)	grad_norm 1425.2899 (1425.2899)	mem 14369MB
[2022-12-20 13:13:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8901 (0.9370)	loss 18.1073 (29.6845)	grad_norm 1085.7499 (1000.5543)	mem 14369MB
[2022-12-20 13:14:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][20/74]	eta 0:00:49 lr 0.000008	time 0.8707 (0.9096)	loss 19.2998 (41.1381)	grad_norm 2099.8003 (1044.5366)	mem 14369MB
[2022-12-20 13:14:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][30/74]	eta 0:00:40 lr 0.000008	time 0.8757 (0.9224)	loss 14.6760 (40.5933)	grad_norm 901.1383 (1123.6235)	mem 14369MB
[2022-12-20 13:14:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][40/74]	eta 0:00:31 lr 0.000008	time 1.1191 (0.9163)	loss 6.4149 (38.2328)	grad_norm 378.4278 (1127.7754)	mem 14369MB
[2022-12-20 13:14:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8916 (0.9091)	loss 51.5944 (42.9608)	grad_norm 624.6972 (1082.8084)	mem 14369MB
[2022-12-20 13:14:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8682 (0.9027)	loss 19.7591 (40.6753)	grad_norm 2303.1827 (1121.6154)	mem 14369MB
[2022-12-20 13:14:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [25/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8881 (0.8990)	loss 51.0176 (42.0682)	grad_norm 1092.8493 (1124.1524)	mem 14369MB
[2022-12-20 13:14:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 25 training takes 0:01:06
[2022-12-20 13:14:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][0/74]	eta 0:01:52 lr 0.000008	time 1.5173 (1.5173)	loss 59.0454 (59.0454)	grad_norm 921.4084 (921.4084)	mem 14369MB
[2022-12-20 13:15:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8678 (0.9295)	loss 17.0182 (41.1011)	grad_norm 1436.2907 (1126.6160)	mem 14369MB
[2022-12-20 13:15:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8772 (0.9024)	loss 106.1300 (42.0717)	grad_norm 280.0922 (1023.6385)	mem 14369MB
[2022-12-20 13:15:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8687 (0.8927)	loss 10.3176 (44.4872)	grad_norm 734.1769 (939.1073)	mem 14369MB
[2022-12-20 13:15:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8783 (0.8879)	loss 33.1603 (40.4918)	grad_norm 507.5848 (1069.3150)	mem 14369MB
[2022-12-20 13:15:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8692 (0.8846)	loss 64.1067 (39.5192)	grad_norm 1204.6650 (1070.7043)	mem 14369MB
[2022-12-20 13:15:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8739 (0.8827)	loss 39.4438 (39.1879)	grad_norm 911.1912 (1063.7575)	mem 14369MB
[2022-12-20 13:15:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [26/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8783 (0.8821)	loss 88.9015 (41.6098)	grad_norm 947.6223 (1047.6071)	mem 14369MB
[2022-12-20 13:15:59 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 26 training takes 0:01:05
[2022-12-20 13:16:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][0/74]	eta 0:01:53 lr 0.000008	time 1.5285 (1.5285)	loss 45.3322 (45.3322)	grad_norm 468.3842 (468.3842)	mem 14369MB
[2022-12-20 13:16:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8736 (0.9306)	loss 47.6505 (40.9595)	grad_norm 974.6220 (840.5470)	mem 14369MB
[2022-12-20 13:16:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8686 (0.9045)	loss 86.8260 (44.0408)	grad_norm 467.3412 (783.0750)	mem 14369MB
[2022-12-20 13:16:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8675 (0.8929)	loss 131.8375 (41.7950)	grad_norm 952.7071 (858.6504)	mem 14369MB
[2022-12-20 13:16:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8740 (0.8875)	loss 9.6226 (37.3750)	grad_norm 897.3125 (853.4496)	mem 14369MB
[2022-12-20 13:16:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8665 (0.8840)	loss 44.8012 (37.8910)	grad_norm 932.8579 (905.3099)	mem 14369MB
[2022-12-20 13:16:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8676 (0.8829)	loss 18.7021 (36.8654)	grad_norm 1731.5388 (897.8616)	mem 14369MB
[2022-12-20 13:17:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [27/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8726 (0.8809)	loss 69.9958 (39.4415)	grad_norm 593.9145 (905.2034)	mem 14369MB
[2022-12-20 13:17:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 27 training takes 0:01:05
[2022-12-20 13:17:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][0/74]	eta 0:01:52 lr 0.000008	time 1.5256 (1.5256)	loss 29.5680 (29.5680)	grad_norm 452.6310 (452.6310)	mem 14369MB
[2022-12-20 13:17:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8641 (0.9317)	loss 19.6940 (34.4643)	grad_norm 1669.2055 (870.8831)	mem 14369MB
[2022-12-20 13:17:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8694 (0.9049)	loss 15.2308 (40.2384)	grad_norm 1174.5290 (859.2364)	mem 14369MB
[2022-12-20 13:17:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8585 (0.8939)	loss 36.1106 (40.5883)	grad_norm 3842.3385 (895.1619)	mem 14369MB
[2022-12-20 13:17:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8884 (0.8890)	loss 11.7136 (44.6870)	grad_norm 782.4899 (910.5022)	mem 14369MB
[2022-12-20 13:17:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8760 (0.8854)	loss 12.3016 (42.8395)	grad_norm 1153.7371 (911.0264)	mem 14369MB
[2022-12-20 13:17:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8792 (0.8841)	loss 15.1400 (41.4782)	grad_norm 929.9981 (946.8529)	mem 14369MB
[2022-12-20 13:18:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [28/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8858 (0.8834)	loss 17.9396 (41.0540)	grad_norm 483.8692 (924.7124)	mem 14369MB
[2022-12-20 13:18:10 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 28 training takes 0:01:05
[2022-12-20 13:18:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][0/74]	eta 0:01:54 lr 0.000008	time 1.5419 (1.5419)	loss 8.9175 (8.9175)	grad_norm 661.6337 (661.6337)	mem 14369MB
[2022-12-20 13:18:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8677 (0.9349)	loss 14.0050 (44.8821)	grad_norm 1466.8504 (733.0714)	mem 14369MB
[2022-12-20 13:18:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8847 (0.9064)	loss 12.2617 (37.4441)	grad_norm 901.2992 (828.1622)	mem 14369MB
[2022-12-20 13:18:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8945 (0.8990)	loss 41.8954 (34.0131)	grad_norm 462.9190 (788.3370)	mem 14369MB
[2022-12-20 13:18:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8928 (0.8952)	loss 10.1890 (40.0744)	grad_norm 874.6696 (775.3048)	mem 14369MB
[2022-12-20 13:18:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8654 (0.8915)	loss 12.2634 (41.1538)	grad_norm 1057.3223 (811.4569)	mem 14369MB
[2022-12-20 13:19:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8830 (0.8886)	loss 18.8184 (39.7515)	grad_norm 420.3974 (783.9230)	mem 14369MB
[2022-12-20 13:19:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [29/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8690 (0.8858)	loss 30.2037 (39.6216)	grad_norm 642.4933 (788.9544)	mem 14369MB
[2022-12-20 13:19:15 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 29 training takes 0:01:05
[2022-12-20 13:19:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][0/74]	eta 0:01:54 lr 0.000008	time 1.5415 (1.5415)	loss 20.1690 (20.1690)	grad_norm 316.8839 (316.8839)	mem 14369MB
[2022-12-20 13:19:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8695 (0.9355)	loss 11.9665 (41.5813)	grad_norm 1026.2027 (809.5398)	mem 14369MB
[2022-12-20 13:19:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8690 (0.9057)	loss 32.3554 (43.3430)	grad_norm 997.1050 (792.9772)	mem 14369MB
[2022-12-20 13:19:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8778 (0.8967)	loss 20.0474 (40.5501)	grad_norm 518.3401 (757.1465)	mem 14369MB
[2022-12-20 13:19:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8729 (0.8907)	loss 10.6025 (37.4288)	grad_norm 852.3536 (796.0442)	mem 14369MB
[2022-12-20 13:20:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8984 (0.8876)	loss 30.2165 (39.8182)	grad_norm 655.7045 (795.1447)	mem 14369MB
[2022-12-20 13:20:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8801 (0.8860)	loss 55.9959 (38.7697)	grad_norm 1626.6178 (787.7104)	mem 14369MB
[2022-12-20 13:20:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [30/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8676 (0.8849)	loss 14.4686 (39.0300)	grad_norm 1218.1336 (790.8928)	mem 14369MB
[2022-12-20 13:20:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 30 training takes 0:01:05
[2022-12-20 13:20:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][0/74]	eta 0:01:53 lr 0.000008	time 1.5286 (1.5286)	loss 44.9675 (44.9675)	grad_norm 566.1111 (566.1111)	mem 14369MB
[2022-12-20 13:20:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8654 (0.9312)	loss 7.9621 (42.9504)	grad_norm 987.4549 (716.7247)	mem 14369MB
[2022-12-20 13:20:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8802 (0.9043)	loss 36.5932 (39.7907)	grad_norm 190.1252 (726.0722)	mem 14369MB
[2022-12-20 13:20:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8780 (0.8945)	loss 10.4933 (34.3783)	grad_norm 1381.6657 (771.1098)	mem 14369MB
[2022-12-20 13:20:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8779 (0.8926)	loss 12.7713 (39.7188)	grad_norm 1041.7622 (772.2452)	mem 14369MB
[2022-12-20 13:21:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8716 (0.8894)	loss 64.6226 (41.2526)	grad_norm 360.1352 (752.3914)	mem 14369MB
[2022-12-20 13:21:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8723 (0.8867)	loss 48.4450 (38.8971)	grad_norm 519.4806 (769.8957)	mem 14369MB
[2022-12-20 13:21:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [31/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8954 (0.8857)	loss 21.7503 (37.7398)	grad_norm 406.3515 (768.6538)	mem 14369MB
[2022-12-20 13:21:26 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 31 training takes 0:01:05
[2022-12-20 13:21:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][0/74]	eta 0:01:54 lr 0.000008	time 1.5436 (1.5436)	loss 15.2910 (15.2910)	grad_norm 408.1616 (408.1616)	mem 14369MB
[2022-12-20 13:21:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8668 (0.9370)	loss 8.0875 (29.6258)	grad_norm 946.4830 (638.2159)	mem 14369MB
[2022-12-20 13:21:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][20/74]	eta 0:00:49 lr 0.000008	time 0.8736 (0.9076)	loss 24.6714 (32.5932)	grad_norm 1151.1175 (630.9638)	mem 14369MB
[2022-12-20 13:21:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8705 (0.8966)	loss 11.3194 (32.2349)	grad_norm 1281.6664 (658.3566)	mem 14369MB
[2022-12-20 13:22:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8807 (0.8916)	loss 53.6687 (33.1890)	grad_norm 600.8339 (653.1870)	mem 14369MB
[2022-12-20 13:22:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8699 (0.8893)	loss 102.0286 (36.1959)	grad_norm 385.7303 (644.6697)	mem 14369MB
[2022-12-20 13:22:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8741 (0.8863)	loss 11.5977 (36.0567)	grad_norm 933.2259 (675.6483)	mem 14369MB
[2022-12-20 13:22:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [32/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8652 (0.8839)	loss 9.0708 (34.7111)	grad_norm 1172.3153 (751.4761)	mem 14369MB
[2022-12-20 13:22:31 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 32 training takes 0:01:05
[2022-12-20 13:22:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][0/74]	eta 0:01:53 lr 0.000008	time 1.5275 (1.5275)	loss 6.0670 (6.0670)	grad_norm 634.0345 (634.0345)	mem 14369MB
[2022-12-20 13:22:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8782 (0.9307)	loss 72.6385 (23.5661)	grad_norm 613.5450 (854.7784)	mem 14369MB
[2022-12-20 13:22:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8766 (0.9049)	loss 51.8103 (29.4619)	grad_norm 395.1126 (863.5858)	mem 14369MB
[2022-12-20 13:22:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8831 (0.8956)	loss 17.7282 (31.5204)	grad_norm 590.4811 (804.2235)	mem 14369MB
[2022-12-20 13:23:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8794 (0.8917)	loss 13.0343 (32.2346)	grad_norm 1344.6925 (836.3525)	mem 14369MB
[2022-12-20 13:23:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8725 (0.8893)	loss 14.6498 (30.0781)	grad_norm 1088.6743 (811.8752)	mem 14369MB
[2022-12-20 13:23:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8863 (0.8879)	loss 42.9813 (30.3886)	grad_norm 422.7204 (803.6715)	mem 14369MB
[2022-12-20 13:23:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [33/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8755 (0.8876)	loss 15.7091 (31.0990)	grad_norm 1485.4576 (803.4146)	mem 14369MB
[2022-12-20 13:23:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 33 training takes 0:01:05
[2022-12-20 13:23:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][0/74]	eta 0:01:53 lr 0.000008	time 1.5358 (1.5358)	loss 41.8367 (41.8367)	grad_norm 390.6192 (390.6192)	mem 14369MB
[2022-12-20 13:23:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8662 (0.9337)	loss 9.3789 (36.2287)	grad_norm 844.5088 (811.9856)	mem 14369MB
[2022-12-20 13:23:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][20/74]	eta 0:00:48 lr 0.000008	time 0.8795 (0.9070)	loss 17.6731 (34.4102)	grad_norm 1565.6593 (768.4692)	mem 14369MB
[2022-12-20 13:24:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8778 (0.8983)	loss 40.6544 (31.3422)	grad_norm 1084.4373 (809.4341)	mem 14369MB
[2022-12-20 13:24:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8776 (0.8940)	loss 15.1339 (29.5649)	grad_norm 1792.1568 (863.1117)	mem 14369MB
[2022-12-20 13:24:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8780 (0.8917)	loss 84.4218 (29.8932)	grad_norm 701.8492 (840.6355)	mem 14369MB
[2022-12-20 13:24:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8936 (0.8896)	loss 22.1260 (27.5952)	grad_norm 392.7922 (835.2718)	mem 14369MB
[2022-12-20 13:24:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [34/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8820 (0.8899)	loss 37.6228 (27.8869)	grad_norm 1454.4066 (817.0175)	mem 14369MB
[2022-12-20 13:24:43 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 34 training takes 0:01:05
[2022-12-20 13:24:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][0/74]	eta 0:01:55 lr 0.000008	time 1.5621 (1.5621)	loss 13.6036 (13.6036)	grad_norm 1263.3227 (1263.3227)	mem 14369MB
[2022-12-20 13:24:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][10/74]	eta 0:01:00 lr 0.000008	time 0.8744 (0.9383)	loss 29.4254 (17.6196)	grad_norm 690.1519 (832.8664)	mem 14369MB
[2022-12-20 13:25:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][20/74]	eta 0:00:49 lr 0.000008	time 0.8948 (0.9103)	loss 8.2822 (20.5978)	grad_norm 719.0876 (866.4911)	mem 14369MB
[2022-12-20 13:25:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8665 (0.9003)	loss 26.4012 (24.1651)	grad_norm 1386.2945 (888.6067)	mem 14369MB
[2022-12-20 13:25:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8818 (0.8958)	loss 41.9656 (23.9782)	grad_norm 920.6983 (892.1991)	mem 14369MB
[2022-12-20 13:25:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8724 (0.8923)	loss 6.4155 (22.6283)	grad_norm 736.9828 (868.5092)	mem 14369MB
[2022-12-20 13:25:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8738 (0.8898)	loss 31.0297 (21.0604)	grad_norm 260.6746 (839.6859)	mem 14369MB
[2022-12-20 13:25:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [35/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8807 (0.8887)	loss 8.4573 (20.8835)	grad_norm 494.7556 (814.8960)	mem 14369MB
[2022-12-20 13:25:48 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 35 training takes 0:01:05
[2022-12-20 13:25:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][0/74]	eta 0:01:53 lr 0.000008	time 1.5344 (1.5344)	loss 7.4547 (7.4547)	grad_norm 701.4434 (701.4434)	mem 14369MB
[2022-12-20 13:25:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][10/74]	eta 0:01:00 lr 0.000008	time 0.8761 (0.9395)	loss 15.8169 (17.3866)	grad_norm 917.1252 (649.8037)	mem 14369MB
[2022-12-20 13:26:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][20/74]	eta 0:00:49 lr 0.000008	time 0.8683 (0.9210)	loss 8.9651 (15.3469)	grad_norm 1458.8864 (744.9986)	mem 14369MB
[2022-12-20 13:26:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8730 (0.9058)	loss 13.9631 (16.0302)	grad_norm 1316.3129 (810.4954)	mem 14369MB
[2022-12-20 13:26:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8809 (0.8977)	loss 20.6825 (16.4180)	grad_norm 460.5744 (769.8179)	mem 14369MB
[2022-12-20 13:26:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8784 (0.8941)	loss 7.7845 (16.9882)	grad_norm 608.8770 (786.4270)	mem 14369MB
[2022-12-20 13:26:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8905 (0.8920)	loss 16.5765 (15.9610)	grad_norm 1071.1462 (798.8646)	mem 14369MB
[2022-12-20 13:26:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [36/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8879 (0.8914)	loss 6.2396 (15.5174)	grad_norm 314.9485 (808.5775)	mem 14369MB
[2022-12-20 13:26:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 36 training takes 0:01:05
[2022-12-20 13:26:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][0/74]	eta 0:01:54 lr 0.000008	time 1.5435 (1.5435)	loss 15.8885 (15.8885)	grad_norm 642.6913 (642.6913)	mem 14369MB
[2022-12-20 13:27:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][10/74]	eta 0:00:59 lr 0.000008	time 0.8921 (0.9371)	loss 15.0360 (11.3342)	grad_norm 614.5414 (752.8666)	mem 14369MB
[2022-12-20 13:27:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][20/74]	eta 0:00:49 lr 0.000008	time 0.8760 (0.9131)	loss 6.7380 (12.2797)	grad_norm 725.8400 (851.4742)	mem 14369MB
[2022-12-20 13:27:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8974 (0.9038)	loss 9.3975 (12.3133)	grad_norm 455.4701 (871.6299)	mem 14369MB
[2022-12-20 13:27:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][40/74]	eta 0:00:30 lr 0.000008	time 0.8948 (0.8983)	loss 16.5061 (12.3709)	grad_norm 578.3026 (857.0132)	mem 14369MB
[2022-12-20 13:27:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][50/74]	eta 0:00:21 lr 0.000008	time 0.8809 (0.8954)	loss 11.4604 (12.4354)	grad_norm 976.6998 (870.9772)	mem 14369MB
[2022-12-20 13:27:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][60/74]	eta 0:00:12 lr 0.000008	time 0.8827 (0.8926)	loss 12.8796 (12.5460)	grad_norm 504.4126 (845.4984)	mem 14369MB
[2022-12-20 13:27:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [37/300][70/74]	eta 0:00:03 lr 0.000008	time 0.8840 (0.8903)	loss 12.8835 (12.8711)	grad_norm 641.0798 (868.8492)	mem 14369MB
[2022-12-20 13:28:00 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 37 training takes 0:01:05
[2022-12-20 13:28:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][0/74]	eta 0:01:53 lr 0.000008	time 1.5354 (1.5354)	loss 12.9123 (12.9123)	grad_norm 864.8733 (864.8733)	mem 14369MB
[2022-12-20 13:28:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][10/74]	eta 0:01:00 lr 0.000008	time 0.8881 (0.9405)	loss 7.8896 (13.3350)	grad_norm 353.0080 (1032.8554)	mem 14369MB
[2022-12-20 13:28:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][20/74]	eta 0:00:49 lr 0.000008	time 0.8746 (0.9107)	loss 19.3795 (14.4029)	grad_norm 1084.0712 (1071.9304)	mem 14369MB
[2022-12-20 13:28:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][30/74]	eta 0:00:39 lr 0.000008	time 0.8804 (0.8998)	loss 20.3427 (13.2955)	grad_norm 1130.0255 (1002.0254)	mem 14369MB
[2022-12-20 13:28:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8773 (0.8951)	loss 9.3659 (12.5079)	grad_norm 616.6546 (947.7684)	mem 14369MB
[2022-12-20 13:28:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8786 (0.8910)	loss 10.6236 (12.4600)	grad_norm 956.2436 (952.6884)	mem 14369MB
[2022-12-20 13:28:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8807 (0.8888)	loss 13.5629 (12.3059)	grad_norm 1067.6217 (934.6522)	mem 14369MB
[2022-12-20 13:29:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [38/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8785 (0.8875)	loss 11.2232 (12.1096)	grad_norm 1102.8095 (933.2619)	mem 14369MB
[2022-12-20 13:29:05 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 38 training takes 0:01:05
[2022-12-20 13:29:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5361 (1.5361)	loss 15.8673 (15.8673)	grad_norm 1341.1768 (1341.1768)	mem 14369MB
[2022-12-20 13:29:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8755 (0.9410)	loss 7.9981 (10.9448)	grad_norm 668.4871 (897.3956)	mem 14369MB
[2022-12-20 13:29:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8840 (0.9112)	loss 12.2767 (10.4357)	grad_norm 415.7172 (794.3593)	mem 14369MB
[2022-12-20 13:29:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8963 (0.9018)	loss 8.5482 (9.9954)	grad_norm 632.2226 (774.0261)	mem 14369MB
[2022-12-20 13:29:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8815 (0.8959)	loss 11.8708 (10.0167)	grad_norm 737.3151 (780.1489)	mem 14369MB
[2022-12-20 13:29:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8738 (0.8927)	loss 8.1706 (10.2962)	grad_norm 540.0790 (776.3829)	mem 14369MB
[2022-12-20 13:30:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8876 (0.8906)	loss 6.7165 (10.3394)	grad_norm 654.7415 (785.7257)	mem 14369MB
[2022-12-20 13:30:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [39/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8845 (0.8889)	loss 8.9185 (10.4714)	grad_norm 741.6735 (802.1159)	mem 14369MB
[2022-12-20 13:30:11 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 39 training takes 0:01:05
[2022-12-20 13:30:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][0/74]	eta 0:01:55 lr 0.000007	time 1.5541 (1.5541)	loss 12.6716 (12.6716)	grad_norm 781.7887 (781.7887)	mem 14369MB
[2022-12-20 13:30:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8788 (0.9425)	loss 17.2412 (10.3865)	grad_norm 1069.3357 (777.8459)	mem 14369MB
[2022-12-20 13:30:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8803 (0.9109)	loss 7.6170 (11.4047)	grad_norm 327.0963 (917.3035)	mem 14369MB
[2022-12-20 13:30:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8905 (0.9014)	loss 9.1483 (10.6438)	grad_norm 518.3401 (844.4962)	mem 14369MB
[2022-12-20 13:30:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8907 (0.8981)	loss 20.8446 (11.0637)	grad_norm 2497.5058 (897.3725)	mem 14369MB
[2022-12-20 13:30:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8767 (0.8953)	loss 8.3724 (10.8055)	grad_norm 579.8596 (876.4301)	mem 14369MB
[2022-12-20 13:31:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8780 (0.8921)	loss 10.6610 (11.0047)	grad_norm 778.6690 (910.6712)	mem 14369MB
[2022-12-20 13:31:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [40/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8750 (0.8903)	loss 12.2829 (10.8182)	grad_norm 1169.1779 (897.2558)	mem 14369MB
[2022-12-20 13:31:17 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 40 training takes 0:01:05
[2022-12-20 13:31:17 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_40.pth saving......
[2022-12-20 13:31:18 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_40.pth saved !!!
[2022-12-20 13:31:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5247 (1.5247)	loss 14.2133 (14.2133)	grad_norm 852.8118 (852.8118)	mem 14369MB
[2022-12-20 13:31:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8675 (0.9288)	loss 11.5910 (9.0998)	grad_norm 1066.9213 (846.0767)	mem 14369MB
[2022-12-20 13:31:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8808 (0.9035)	loss 7.0835 (8.8487)	grad_norm 330.3668 (798.1845)	mem 14369MB
[2022-12-20 13:31:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8657 (0.8931)	loss 6.5436 (9.0396)	grad_norm 851.9656 (819.5359)	mem 14369MB
[2022-12-20 13:31:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8758 (0.8898)	loss 9.9741 (8.9117)	grad_norm 1027.4289 (800.8154)	mem 14369MB
[2022-12-20 13:32:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8795 (0.8875)	loss 14.5559 (8.8084)	grad_norm 520.9211 (760.7208)	mem 14369MB
[2022-12-20 13:32:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8817 (0.8856)	loss 9.8525 (9.1472)	grad_norm 698.4162 (769.0895)	mem 14369MB
[2022-12-20 13:32:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [41/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8820 (0.8843)	loss 9.1856 (9.3338)	grad_norm 791.0997 (771.8793)	mem 14369MB
[2022-12-20 13:32:23 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 41 training takes 0:01:05
[2022-12-20 13:32:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5199 (1.5199)	loss 6.0737 (6.0737)	grad_norm 909.0410 (909.0410)	mem 14369MB
[2022-12-20 13:32:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8688 (0.9352)	loss 14.1520 (9.4526)	grad_norm 1368.5361 (811.1038)	mem 14369MB
[2022-12-20 13:32:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8621 (0.9057)	loss 13.5004 (9.8404)	grad_norm 1662.9235 (852.6841)	mem 14369MB
[2022-12-20 13:32:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8776 (0.8965)	loss 8.2570 (9.3901)	grad_norm 748.0617 (825.3684)	mem 14369MB
[2022-12-20 13:33:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8891 (0.8935)	loss 5.0124 (9.2345)	grad_norm 422.2026 (791.0342)	mem 14369MB
[2022-12-20 13:33:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8779 (0.8903)	loss 10.9790 (9.2770)	grad_norm 629.7891 (778.7348)	mem 14369MB
[2022-12-20 13:33:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8697 (0.8869)	loss 10.1106 (9.4527)	grad_norm 1056.6324 (814.8833)	mem 14369MB
[2022-12-20 13:33:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [42/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8687 (0.8973)	loss 13.7572 (9.4579)	grad_norm 853.8341 (825.0406)	mem 14369MB
[2022-12-20 13:33:30 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 42 training takes 0:01:06
[2022-12-20 13:33:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5310 (1.5310)	loss 5.5700 (5.5700)	grad_norm 666.8791 (666.8791)	mem 14369MB
[2022-12-20 13:33:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8775 (0.9365)	loss 7.6534 (6.6379)	grad_norm 939.5265 (605.7504)	mem 14369MB
[2022-12-20 13:33:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8706 (0.9059)	loss 6.4698 (7.6863)	grad_norm 914.5586 (674.5140)	mem 14369MB
[2022-12-20 13:33:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8701 (0.8954)	loss 10.2356 (7.7205)	grad_norm 849.6615 (681.2916)	mem 14369MB
[2022-12-20 13:34:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8689 (0.8903)	loss 10.7548 (8.2686)	grad_norm 710.0951 (685.0738)	mem 14369MB
[2022-12-20 13:34:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8690 (0.8868)	loss 13.8894 (8.4456)	grad_norm 1567.3864 (740.5466)	mem 14369MB
[2022-12-20 13:34:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8750 (0.8851)	loss 17.7049 (8.5137)	grad_norm 955.6742 (749.6781)	mem 14369MB
[2022-12-20 13:34:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [43/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8657 (0.8836)	loss 12.7945 (8.5037)	grad_norm 1033.7385 (736.7341)	mem 14369MB
[2022-12-20 13:34:35 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 43 training takes 0:01:05
[2022-12-20 13:34:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5469 (1.5469)	loss 4.7453 (4.7453)	grad_norm 348.0437 (348.0437)	mem 14369MB
[2022-12-20 13:34:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8893 (0.9346)	loss 20.7471 (10.6435)	grad_norm 1541.9455 (900.9983)	mem 14369MB
[2022-12-20 13:34:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8714 (0.9069)	loss 9.6575 (10.0138)	grad_norm 922.0527 (788.2274)	mem 14369MB
[2022-12-20 13:35:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8810 (0.8966)	loss 5.0673 (9.6801)	grad_norm 387.2010 (774.5945)	mem 14369MB
[2022-12-20 13:35:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8743 (0.8909)	loss 8.9266 (9.4773)	grad_norm 932.8709 (789.4165)	mem 14369MB
[2022-12-20 13:35:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8661 (0.8877)	loss 7.0418 (9.6122)	grad_norm 959.6523 (838.3033)	mem 14369MB
[2022-12-20 13:35:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8895 (0.8860)	loss 7.5298 (9.4679)	grad_norm 607.9770 (852.0706)	mem 14369MB
[2022-12-20 13:35:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [44/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8791 (0.8853)	loss 12.1822 (9.3434)	grad_norm 1313.1345 (833.0034)	mem 14369MB
[2022-12-20 13:35:40 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 44 training takes 0:01:05
[2022-12-20 13:35:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5406 (1.5406)	loss 8.3548 (8.3548)	grad_norm 793.8229 (793.8229)	mem 14369MB
[2022-12-20 13:35:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8910 (0.9398)	loss 7.5602 (8.7672)	grad_norm 679.6908 (742.6943)	mem 14369MB
[2022-12-20 13:36:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8799 (0.9167)	loss 5.1874 (8.2536)	grad_norm 750.5751 (727.4998)	mem 14369MB
[2022-12-20 13:36:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8888 (0.9070)	loss 9.5560 (8.3599)	grad_norm 406.9600 (725.5200)	mem 14369MB
[2022-12-20 13:36:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8850 (0.9008)	loss 11.4612 (8.4128)	grad_norm 1188.2275 (752.5490)	mem 14369MB
[2022-12-20 13:36:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8770 (0.8966)	loss 9.2762 (8.5358)	grad_norm 695.1531 (749.3890)	mem 14369MB
[2022-12-20 13:36:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8681 (0.8929)	loss 13.0410 (8.6744)	grad_norm 1369.8133 (764.2126)	mem 14369MB
[2022-12-20 13:36:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [45/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8649 (0.8911)	loss 8.4699 (8.6326)	grad_norm 1338.1473 (766.1922)	mem 14369MB
[2022-12-20 13:36:46 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 45 training takes 0:01:05
[2022-12-20 13:36:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5298 (1.5298)	loss 14.7943 (14.7943)	grad_norm 811.4447 (811.4447)	mem 14369MB
[2022-12-20 13:36:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8738 (0.9362)	loss 5.9441 (8.5229)	grad_norm 917.0131 (742.9747)	mem 14369MB
[2022-12-20 13:37:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8862 (0.9079)	loss 10.2032 (9.1924)	grad_norm 690.3518 (740.5557)	mem 14369MB
[2022-12-20 13:37:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8865 (0.8974)	loss 4.5367 (8.4794)	grad_norm 430.2892 (713.1943)	mem 14369MB
[2022-12-20 13:37:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8649 (0.8923)	loss 5.0362 (8.3264)	grad_norm 840.1623 (686.3712)	mem 14369MB
[2022-12-20 13:37:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8767 (0.8890)	loss 12.0262 (8.6151)	grad_norm 865.1096 (718.9852)	mem 14369MB
[2022-12-20 13:37:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8881 (0.8870)	loss 8.7774 (8.9565)	grad_norm 732.6509 (745.3249)	mem 14369MB
[2022-12-20 13:37:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [46/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8955 (0.8859)	loss 7.3571 (8.7979)	grad_norm 570.9379 (724.2007)	mem 14369MB
[2022-12-20 13:37:52 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 46 training takes 0:01:05
[2022-12-20 13:37:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5436 (1.5436)	loss 4.2679 (4.2679)	grad_norm 611.5521 (611.5521)	mem 14369MB
[2022-12-20 13:38:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8887 (0.9419)	loss 8.2737 (8.5841)	grad_norm 444.0222 (616.8191)	mem 14369MB
[2022-12-20 13:38:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8718 (0.9098)	loss 4.1275 (7.2842)	grad_norm 280.6589 (547.2152)	mem 14369MB
[2022-12-20 13:38:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8820 (0.8982)	loss 16.5287 (8.0202)	grad_norm 585.4894 (630.3551)	mem 14369MB
[2022-12-20 13:38:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8700 (0.8929)	loss 14.7464 (8.7110)	grad_norm 1599.2925 (703.8221)	mem 14369MB
[2022-12-20 13:38:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8747 (0.8895)	loss 11.2702 (8.8182)	grad_norm 1116.1357 (753.8176)	mem 14369MB
[2022-12-20 13:38:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8844 (0.8878)	loss 7.2441 (8.9622)	grad_norm 505.8097 (751.6147)	mem 14369MB
[2022-12-20 13:38:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [47/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8679 (0.8863)	loss 9.6638 (8.7862)	grad_norm 1130.1899 (734.0663)	mem 14369MB
[2022-12-20 13:38:57 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 47 training takes 0:01:05
[2022-12-20 13:38:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5351 (1.5351)	loss 6.9107 (6.9107)	grad_norm 516.5438 (516.5438)	mem 14369MB
[2022-12-20 13:39:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8745 (0.9331)	loss 5.6031 (9.8095)	grad_norm 576.9352 (869.1060)	mem 14369MB
[2022-12-20 13:39:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8865 (0.9053)	loss 7.9252 (8.9327)	grad_norm 684.5419 (801.5179)	mem 14369MB
[2022-12-20 13:39:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8907 (0.8980)	loss 7.7051 (8.5873)	grad_norm 490.5154 (761.2371)	mem 14369MB
[2022-12-20 13:39:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8863 (0.8930)	loss 3.9481 (8.2630)	grad_norm 306.3792 (734.2063)	mem 14369MB
[2022-12-20 13:39:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8820 (0.8900)	loss 14.5557 (8.4070)	grad_norm 369.1288 (687.7051)	mem 14369MB
[2022-12-20 13:39:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8782 (0.8892)	loss 6.5755 (8.5058)	grad_norm 334.9732 (681.3831)	mem 14369MB
[2022-12-20 13:40:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [48/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8901 (0.8879)	loss 8.4889 (8.4852)	grad_norm 562.3675 (673.8675)	mem 14369MB
[2022-12-20 13:40:03 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 48 training takes 0:01:05
[2022-12-20 13:40:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5431 (1.5431)	loss 6.9385 (6.9385)	grad_norm 823.3665 (823.3665)	mem 14369MB
[2022-12-20 13:40:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8791 (0.9399)	loss 5.7272 (7.2485)	grad_norm 438.2245 (623.2860)	mem 14369MB
[2022-12-20 13:40:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8871 (0.9105)	loss 12.0790 (7.1875)	grad_norm 270.4730 (618.4890)	mem 14369MB
[2022-12-20 13:40:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8873 (0.9000)	loss 6.6160 (7.4210)	grad_norm 502.3169 (647.2531)	mem 14369MB
[2022-12-20 13:40:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8776 (0.8958)	loss 8.9402 (7.8503)	grad_norm 707.8675 (665.3262)	mem 14369MB
[2022-12-20 13:40:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8904 (0.8924)	loss 6.8189 (7.8773)	grad_norm 376.7796 (686.5743)	mem 14369MB
[2022-12-20 13:40:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8757 (0.8912)	loss 7.2875 (7.8269)	grad_norm 848.5307 (682.1457)	mem 14369MB
[2022-12-20 13:41:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [49/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8907 (0.8905)	loss 5.2732 (7.8081)	grad_norm 431.2701 (668.5170)	mem 14369MB
[2022-12-20 13:41:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 49 training takes 0:01:05
[2022-12-20 13:41:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5462 (1.5462)	loss 7.3464 (7.3464)	grad_norm 525.8103 (525.8103)	mem 14369MB
[2022-12-20 13:41:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8819 (0.9412)	loss 18.9837 (10.9456)	grad_norm 1088.3309 (754.6257)	mem 14369MB
[2022-12-20 13:41:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8914 (0.9132)	loss 6.0276 (8.7659)	grad_norm 406.7427 (641.5726)	mem 14369MB
[2022-12-20 13:41:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8744 (0.9000)	loss 7.0212 (8.2589)	grad_norm 617.8371 (631.7445)	mem 14369MB
[2022-12-20 13:41:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8882 (0.8956)	loss 10.8924 (8.5697)	grad_norm 521.4337 (614.0237)	mem 14369MB
[2022-12-20 13:41:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8753 (0.8933)	loss 5.9098 (8.2672)	grad_norm 396.5875 (602.5716)	mem 14369MB
[2022-12-20 13:42:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8834 (0.8910)	loss 5.0812 (7.9120)	grad_norm 346.8286 (592.3538)	mem 14369MB
[2022-12-20 13:42:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [50/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8702 (0.8889)	loss 4.9534 (7.8159)	grad_norm 756.3936 (595.3801)	mem 14369MB
[2022-12-20 13:42:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 50 training takes 0:01:05
[2022-12-20 13:42:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5287 (1.5287)	loss 11.2546 (11.2546)	grad_norm 494.8347 (494.8347)	mem 14369MB
[2022-12-20 13:42:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8768 (0.9331)	loss 8.5873 (6.7508)	grad_norm 1126.7579 (556.4112)	mem 14369MB
[2022-12-20 13:42:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8811 (0.9064)	loss 5.4452 (6.6696)	grad_norm 433.2224 (564.2790)	mem 14369MB
[2022-12-20 13:42:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8692 (0.8971)	loss 6.7678 (7.1117)	grad_norm 896.5081 (597.6967)	mem 14369MB
[2022-12-20 13:42:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8773 (0.8931)	loss 6.8672 (7.1609)	grad_norm 940.1960 (582.1663)	mem 14369MB
[2022-12-20 13:43:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8767 (0.8897)	loss 12.9514 (7.1668)	grad_norm 292.5836 (577.4481)	mem 14369MB
[2022-12-20 13:43:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8701 (0.8877)	loss 7.8033 (7.2754)	grad_norm 511.2058 (580.3658)	mem 14369MB
[2022-12-20 13:43:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [51/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8763 (0.8864)	loss 6.0408 (7.4969)	grad_norm 786.4851 (613.0128)	mem 14369MB
[2022-12-20 13:43:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 51 training takes 0:01:05
[2022-12-20 13:43:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][0/74]	eta 0:01:55 lr 0.000007	time 1.5593 (1.5593)	loss 8.0909 (8.0909)	grad_norm 845.6653 (845.6653)	mem 14369MB
[2022-12-20 13:43:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][10/74]	eta 0:01:01 lr 0.000007	time 0.8845 (0.9660)	loss 5.2458 (7.8130)	grad_norm 469.3590 (652.9646)	mem 14369MB
[2022-12-20 13:43:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][20/74]	eta 0:00:50 lr 0.000007	time 0.8769 (0.9268)	loss 6.2107 (7.8875)	grad_norm 311.1341 (622.2748)	mem 14369MB
[2022-12-20 13:43:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][30/74]	eta 0:00:40 lr 0.000007	time 0.8708 (0.9117)	loss 6.5980 (7.7262)	grad_norm 540.7762 (600.9025)	mem 14369MB
[2022-12-20 13:43:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8757 (0.9035)	loss 9.4079 (7.7243)	grad_norm 325.2801 (630.6444)	mem 14369MB
[2022-12-20 13:44:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8753 (0.8987)	loss 7.3386 (7.7187)	grad_norm 410.9337 (614.3000)	mem 14369MB
[2022-12-20 13:44:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8725 (0.8955)	loss 7.9020 (7.6945)	grad_norm 760.9061 (618.5588)	mem 14369MB
[2022-12-20 13:44:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [52/300][70/74]	eta 0:00:03 lr 0.000007	time 0.9014 (0.8943)	loss 9.9072 (7.5417)	grad_norm 417.8873 (609.8403)	mem 14369MB
[2022-12-20 13:44:26 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 52 training takes 0:01:06
[2022-12-20 13:44:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5470 (1.5470)	loss 8.1075 (8.1075)	grad_norm 802.8307 (802.8307)	mem 14369MB
[2022-12-20 13:44:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8926 (0.9379)	loss 4.2606 (7.4653)	grad_norm 280.8576 (548.9160)	mem 14369MB
[2022-12-20 13:44:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8811 (0.9087)	loss 6.5039 (7.1470)	grad_norm 409.1092 (595.0555)	mem 14369MB
[2022-12-20 13:44:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8807 (0.9004)	loss 6.7917 (7.1492)	grad_norm 563.5282 (578.3776)	mem 14369MB
[2022-12-20 13:45:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8781 (0.8946)	loss 9.8441 (7.0123)	grad_norm 606.5042 (580.2545)	mem 14369MB
[2022-12-20 13:45:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][50/74]	eta 0:00:21 lr 0.000007	time 0.9008 (0.8918)	loss 6.4900 (7.0644)	grad_norm 511.0505 (604.6042)	mem 14369MB
[2022-12-20 13:45:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8800 (0.8893)	loss 5.9449 (7.1942)	grad_norm 473.6528 (584.2599)	mem 14369MB
[2022-12-20 13:45:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [53/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8795 (0.8877)	loss 9.4249 (7.3229)	grad_norm 619.5907 (583.1744)	mem 14369MB
[2022-12-20 13:45:32 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 53 training takes 0:01:05
[2022-12-20 13:45:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5475 (1.5475)	loss 10.0992 (10.0992)	grad_norm 440.8829 (440.8829)	mem 14369MB
[2022-12-20 13:45:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8865 (0.9367)	loss 12.6044 (8.8023)	grad_norm 990.0932 (638.6319)	mem 14369MB
[2022-12-20 13:45:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8838 (0.9100)	loss 5.0526 (7.7145)	grad_norm 337.1684 (529.9311)	mem 14369MB
[2022-12-20 13:45:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8685 (0.8989)	loss 7.6904 (7.3963)	grad_norm 1101.1117 (579.9654)	mem 14369MB
[2022-12-20 13:46:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8728 (0.8938)	loss 5.2701 (7.0972)	grad_norm 509.1550 (572.6850)	mem 14369MB
[2022-12-20 13:46:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8873 (0.8907)	loss 7.9588 (7.1407)	grad_norm 614.9702 (578.9715)	mem 14369MB
[2022-12-20 13:46:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8797 (0.8888)	loss 6.8356 (7.0775)	grad_norm 415.2609 (578.1221)	mem 14369MB
[2022-12-20 13:46:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [54/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8935 (0.8876)	loss 10.2027 (7.2422)	grad_norm 613.1043 (609.8190)	mem 14369MB
[2022-12-20 13:46:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 54 training takes 0:01:05
[2022-12-20 13:46:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5453 (1.5453)	loss 7.1901 (7.1901)	grad_norm 249.2813 (249.2813)	mem 14369MB
[2022-12-20 13:46:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8772 (0.9402)	loss 8.6958 (7.2128)	grad_norm 646.6386 (578.6637)	mem 14369MB
[2022-12-20 13:46:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8689 (0.9088)	loss 14.8330 (7.1565)	grad_norm 720.7892 (607.7798)	mem 14369MB
[2022-12-20 13:47:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8769 (0.8983)	loss 7.7976 (7.0668)	grad_norm 706.1240 (628.1984)	mem 14369MB
[2022-12-20 13:47:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8733 (0.8935)	loss 4.9196 (7.0642)	grad_norm 553.0821 (590.7269)	mem 14369MB
[2022-12-20 13:47:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8744 (0.8907)	loss 4.9280 (6.9928)	grad_norm 445.3878 (579.4540)	mem 14369MB
[2022-12-20 13:47:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8916 (0.8884)	loss 5.4413 (6.9888)	grad_norm 454.8402 (563.4835)	mem 14369MB
[2022-12-20 13:47:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [55/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8820 (0.8870)	loss 4.6033 (6.9921)	grad_norm 444.4482 (562.1557)	mem 14369MB
[2022-12-20 13:47:43 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 55 training takes 0:01:05
[2022-12-20 13:47:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5532 (1.5532)	loss 10.3121 (10.3121)	grad_norm 889.2779 (889.2779)	mem 14369MB
[2022-12-20 13:47:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8835 (0.9401)	loss 6.2398 (6.4020)	grad_norm 394.2163 (557.7283)	mem 14369MB
[2022-12-20 13:48:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8840 (0.9120)	loss 6.9549 (6.4521)	grad_norm 467.7911 (577.9027)	mem 14369MB
[2022-12-20 13:48:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8956 (0.9015)	loss 3.8677 (6.6971)	grad_norm 172.0898 (599.3630)	mem 14369MB
[2022-12-20 13:48:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8789 (0.8958)	loss 5.6652 (6.9564)	grad_norm 617.4571 (588.2084)	mem 14369MB
[2022-12-20 13:48:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8718 (0.8928)	loss 10.6023 (7.3152)	grad_norm 1268.6763 (599.9183)	mem 14369MB
[2022-12-20 13:48:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8851 (0.8903)	loss 5.6160 (7.6587)	grad_norm 519.6194 (631.8839)	mem 14369MB
[2022-12-20 13:48:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [56/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8764 (0.8891)	loss 4.1076 (7.3125)	grad_norm 366.9160 (599.4102)	mem 14369MB
[2022-12-20 13:48:48 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 56 training takes 0:01:05
[2022-12-20 13:48:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5436 (1.5436)	loss 6.8349 (6.8349)	grad_norm 867.5346 (867.5346)	mem 14369MB
[2022-12-20 13:48:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8724 (0.9369)	loss 5.8318 (8.0327)	grad_norm 642.6112 (724.2002)	mem 14369MB
[2022-12-20 13:49:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8805 (0.9085)	loss 6.2497 (7.8762)	grad_norm 514.0623 (692.8874)	mem 14369MB
[2022-12-20 13:49:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8876 (0.8987)	loss 13.1645 (7.5398)	grad_norm 973.6119 (691.3248)	mem 14369MB
[2022-12-20 13:49:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8693 (0.8937)	loss 5.8424 (7.2254)	grad_norm 917.1019 (686.2387)	mem 14369MB
[2022-12-20 13:49:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8705 (0.8906)	loss 5.8963 (7.2771)	grad_norm 957.9705 (670.0312)	mem 14369MB
[2022-12-20 13:49:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8790 (0.8891)	loss 5.7022 (7.3652)	grad_norm 379.8118 (660.5178)	mem 14369MB
[2022-12-20 13:49:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [57/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8742 (0.8876)	loss 9.9576 (7.5693)	grad_norm 1019.3759 (675.4616)	mem 14369MB
[2022-12-20 13:49:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 57 training takes 0:01:05
[2022-12-20 13:49:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5407 (1.5407)	loss 7.8021 (7.8021)	grad_norm 845.9553 (845.9553)	mem 14369MB
[2022-12-20 13:50:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8712 (0.9350)	loss 4.9396 (6.5476)	grad_norm 706.4953 (662.4744)	mem 14369MB
[2022-12-20 13:50:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8768 (0.9107)	loss 9.2100 (6.5483)	grad_norm 661.9924 (620.8547)	mem 14369MB
[2022-12-20 13:50:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8831 (0.8992)	loss 10.0558 (6.6715)	grad_norm 413.2959 (642.4020)	mem 14369MB
[2022-12-20 13:50:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8836 (0.8944)	loss 6.8013 (6.6756)	grad_norm 645.5490 (618.5826)	mem 14369MB
[2022-12-20 13:50:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8904 (0.8914)	loss 9.7656 (7.0656)	grad_norm 504.3718 (620.1831)	mem 14369MB
[2022-12-20 13:50:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8847 (0.8887)	loss 6.1382 (7.1073)	grad_norm 411.5254 (612.6031)	mem 14369MB
[2022-12-20 13:50:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [58/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8891 (0.8882)	loss 4.7541 (7.1127)	grad_norm 333.4604 (610.3658)	mem 14369MB
[2022-12-20 13:51:00 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 58 training takes 0:01:05
[2022-12-20 13:51:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][0/74]	eta 0:01:55 lr 0.000007	time 1.5579 (1.5579)	loss 7.5528 (7.5528)	grad_norm 380.5208 (380.5208)	mem 14369MB
[2022-12-20 13:51:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8798 (0.9379)	loss 6.5249 (7.5276)	grad_norm 466.1774 (445.7658)	mem 14369MB
[2022-12-20 13:51:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8818 (0.9105)	loss 5.2893 (7.2026)	grad_norm 447.7083 (436.7144)	mem 14369MB
[2022-12-20 13:51:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8682 (0.8999)	loss 7.3075 (7.0110)	grad_norm 1055.5222 (499.4204)	mem 14369MB
[2022-12-20 13:51:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8711 (0.8933)	loss 4.9964 (6.9031)	grad_norm 598.6062 (515.2117)	mem 14369MB
[2022-12-20 13:51:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8843 (0.8902)	loss 5.5159 (6.8899)	grad_norm 617.3103 (533.4072)	mem 14369MB
[2022-12-20 13:51:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8949 (0.8884)	loss 12.2853 (7.0801)	grad_norm 868.6916 (552.3290)	mem 14369MB
[2022-12-20 13:52:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [59/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8738 (0.8867)	loss 9.4658 (6.8633)	grad_norm 896.8310 (547.7085)	mem 14369MB
[2022-12-20 13:52:05 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 59 training takes 0:01:05
[2022-12-20 13:52:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5287 (1.5287)	loss 5.2882 (5.2882)	grad_norm 648.8271 (648.8271)	mem 14369MB
[2022-12-20 13:52:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8721 (0.9394)	loss 6.9572 (6.2807)	grad_norm 574.2414 (507.9438)	mem 14369MB
[2022-12-20 13:52:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8792 (0.9113)	loss 6.7129 (6.8986)	grad_norm 575.2473 (509.7549)	mem 14369MB
[2022-12-20 13:52:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8813 (0.9005)	loss 5.4727 (6.8628)	grad_norm 336.7328 (519.8010)	mem 14369MB
[2022-12-20 13:52:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8794 (0.8942)	loss 6.7909 (6.8736)	grad_norm 800.0978 (543.4434)	mem 14369MB
[2022-12-20 13:52:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8730 (0.8914)	loss 5.7579 (6.7684)	grad_norm 364.6617 (549.7457)	mem 14369MB
[2022-12-20 13:53:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8810 (0.8893)	loss 5.7938 (7.1004)	grad_norm 339.8206 (558.0823)	mem 14369MB
[2022-12-20 13:53:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [60/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8780 (0.8880)	loss 5.8125 (6.9330)	grad_norm 412.3034 (545.1330)	mem 14369MB
[2022-12-20 13:53:11 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 60 training takes 0:01:05
[2022-12-20 13:53:11 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_60.pth saving......
[2022-12-20 13:53:12 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_60.pth saved !!!
[2022-12-20 13:53:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][0/74]	eta 0:01:51 lr 0.000007	time 1.5034 (1.5034)	loss 6.7576 (6.7576)	grad_norm 431.6255 (431.6255)	mem 14369MB
[2022-12-20 13:53:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8703 (0.9269)	loss 5.0476 (5.9155)	grad_norm 291.2573 (456.5321)	mem 14369MB
[2022-12-20 13:53:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8584 (0.8980)	loss 3.9475 (6.0498)	grad_norm 580.3389 (517.7387)	mem 14369MB
[2022-12-20 13:53:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8689 (0.8881)	loss 7.7018 (5.9630)	grad_norm 717.4742 (504.4464)	mem 14369MB
[2022-12-20 13:53:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8706 (0.8830)	loss 4.6345 (6.2951)	grad_norm 489.2380 (524.0441)	mem 14369MB
[2022-12-20 13:53:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8965 (0.8841)	loss 4.7543 (6.4507)	grad_norm 343.2095 (499.6719)	mem 14369MB
[2022-12-20 13:54:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8872 (0.8835)	loss 6.5387 (6.5022)	grad_norm 360.8008 (511.4863)	mem 14369MB
[2022-12-20 13:54:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [61/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8694 (0.8819)	loss 5.1685 (6.5030)	grad_norm 637.6608 (520.9047)	mem 14369MB
[2022-12-20 13:54:17 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 61 training takes 0:01:05
[2022-12-20 13:54:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5157 (1.5157)	loss 6.6797 (6.6797)	grad_norm 824.5472 (824.5472)	mem 14369MB
[2022-12-20 13:54:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8833 (0.9322)	loss 7.0157 (6.1692)	grad_norm 804.3056 (675.6964)	mem 14369MB
[2022-12-20 13:54:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8664 (0.9045)	loss 7.2374 (6.1519)	grad_norm 509.7595 (608.0193)	mem 14369MB
[2022-12-20 13:54:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8751 (0.8940)	loss 6.7668 (6.0369)	grad_norm 484.5428 (565.5470)	mem 14369MB
[2022-12-20 13:54:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8714 (0.8878)	loss 6.7166 (6.4815)	grad_norm 788.3275 (580.9186)	mem 14369MB
[2022-12-20 13:55:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8687 (0.8852)	loss 7.1823 (6.5700)	grad_norm 939.2867 (579.2935)	mem 14369MB
[2022-12-20 13:55:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8777 (0.8846)	loss 7.5352 (6.6490)	grad_norm 788.4761 (572.6075)	mem 14369MB
[2022-12-20 13:55:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [62/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8742 (0.8837)	loss 5.6481 (6.5443)	grad_norm 457.7748 (554.2901)	mem 14369MB
[2022-12-20 13:55:23 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 62 training takes 0:01:05
[2022-12-20 13:55:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5204 (1.5204)	loss 6.2904 (6.2904)	grad_norm 257.3798 (257.3798)	mem 14369MB
[2022-12-20 13:55:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8872 (0.9322)	loss 5.0231 (6.3400)	grad_norm 395.2673 (469.5207)	mem 14369MB
[2022-12-20 13:55:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8857 (0.9061)	loss 4.2210 (5.8488)	grad_norm 322.0559 (449.0352)	mem 14369MB
[2022-12-20 13:55:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8705 (0.8957)	loss 5.3383 (5.6826)	grad_norm 502.5841 (461.4410)	mem 14369MB
[2022-12-20 13:55:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8735 (0.8908)	loss 6.8640 (5.7573)	grad_norm 535.1762 (473.0507)	mem 14369MB
[2022-12-20 13:56:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8585 (0.8877)	loss 3.9306 (5.7696)	grad_norm 625.8877 (468.7481)	mem 14369MB
[2022-12-20 13:56:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8640 (0.8857)	loss 4.5411 (5.7046)	grad_norm 459.4698 (457.5555)	mem 14369MB
[2022-12-20 13:56:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [63/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8779 (0.8837)	loss 5.3442 (5.8555)	grad_norm 329.4797 (462.0005)	mem 14369MB
[2022-12-20 13:56:28 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 63 training takes 0:01:05
[2022-12-20 13:56:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][0/74]	eta 0:01:51 lr 0.000007	time 1.5079 (1.5079)	loss 5.7781 (5.7781)	grad_norm 412.4589 (412.4589)	mem 14369MB
[2022-12-20 13:56:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8646 (0.9292)	loss 5.2026 (6.1581)	grad_norm 487.4706 (425.8642)	mem 14369MB
[2022-12-20 13:56:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8711 (0.9021)	loss 5.1804 (5.9140)	grad_norm 472.0373 (451.9120)	mem 14369MB
[2022-12-20 13:56:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8813 (0.8933)	loss 6.8261 (5.9535)	grad_norm 569.2684 (459.2939)	mem 14369MB
[2022-12-20 13:57:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8820 (0.8897)	loss 6.9354 (5.6618)	grad_norm 322.8866 (439.8392)	mem 14369MB
[2022-12-20 13:57:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8677 (0.8878)	loss 5.1608 (5.7703)	grad_norm 454.9773 (449.7385)	mem 14369MB
[2022-12-20 13:57:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8767 (0.8853)	loss 10.3157 (5.7383)	grad_norm 669.8924 (443.4495)	mem 14369MB
[2022-12-20 13:57:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [64/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8744 (0.8840)	loss 5.3976 (5.7472)	grad_norm 377.7498 (441.3254)	mem 14369MB
[2022-12-20 13:57:33 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 64 training takes 0:01:05
[2022-12-20 13:57:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5220 (1.5220)	loss 8.2514 (8.2514)	grad_norm 658.2873 (658.2873)	mem 14369MB
[2022-12-20 13:57:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8991 (0.9314)	loss 8.9379 (6.1075)	grad_norm 375.7105 (450.6990)	mem 14369MB
[2022-12-20 13:57:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8755 (0.9025)	loss 7.7922 (6.2208)	grad_norm 486.7576 (509.2346)	mem 14369MB
[2022-12-20 13:58:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8722 (0.8926)	loss 3.9834 (6.4428)	grad_norm 328.7165 (485.8212)	mem 14369MB
[2022-12-20 13:58:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8744 (0.8878)	loss 5.7226 (6.2703)	grad_norm 351.0750 (469.6018)	mem 14369MB
[2022-12-20 13:58:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8713 (0.8841)	loss 4.6494 (6.1137)	grad_norm 451.1630 (467.3417)	mem 14369MB
[2022-12-20 13:58:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8906 (0.8831)	loss 4.5679 (6.0126)	grad_norm 298.2934 (454.2855)	mem 14369MB
[2022-12-20 13:58:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [65/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8684 (0.8820)	loss 3.1992 (5.8103)	grad_norm 332.8554 (454.8921)	mem 14369MB
[2022-12-20 13:58:38 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 65 training takes 0:01:05
[2022-12-20 13:58:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5242 (1.5242)	loss 3.8751 (3.8751)	grad_norm 250.4163 (250.4163)	mem 14369MB
[2022-12-20 13:58:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8763 (0.9376)	loss 7.9088 (6.9382)	grad_norm 440.6470 (529.3303)	mem 14369MB
[2022-12-20 13:58:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8911 (0.9076)	loss 8.8880 (6.5615)	grad_norm 482.0235 (518.7529)	mem 14369MB
[2022-12-20 13:59:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8641 (0.8968)	loss 6.8423 (6.3250)	grad_norm 366.2354 (500.3959)	mem 14369MB
[2022-12-20 13:59:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8743 (0.8899)	loss 3.7553 (6.2130)	grad_norm 273.3324 (492.0794)	mem 14369MB
[2022-12-20 13:59:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8921 (0.8863)	loss 5.1960 (6.0996)	grad_norm 353.9539 (481.3798)	mem 14369MB
[2022-12-20 13:59:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8620 (0.8832)	loss 5.8338 (5.9592)	grad_norm 330.7855 (472.7885)	mem 14369MB
[2022-12-20 13:59:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [66/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8739 (0.8831)	loss 5.4601 (5.9976)	grad_norm 758.7626 (475.4044)	mem 14369MB
[2022-12-20 13:59:44 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 66 training takes 0:01:05
[2022-12-20 13:59:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5153 (1.5153)	loss 3.7992 (3.7992)	grad_norm 408.1628 (408.1628)	mem 14369MB
[2022-12-20 13:59:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][10/74]	eta 0:01:00 lr 0.000007	time 0.8709 (0.9378)	loss 7.4226 (6.2454)	grad_norm 450.5738 (411.1660)	mem 14369MB
[2022-12-20 14:00:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8708 (0.9060)	loss 4.3115 (5.7694)	grad_norm 469.1486 (404.2730)	mem 14369MB
[2022-12-20 14:00:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8651 (0.8960)	loss 5.7799 (5.7513)	grad_norm 758.9196 (425.4552)	mem 14369MB
[2022-12-20 14:00:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8750 (0.8897)	loss 6.1652 (5.9583)	grad_norm 571.1572 (457.8231)	mem 14369MB
[2022-12-20 14:00:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8747 (0.8863)	loss 4.8932 (5.8078)	grad_norm 444.7635 (453.2098)	mem 14369MB
[2022-12-20 14:00:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8741 (0.8840)	loss 3.4292 (5.7272)	grad_norm 349.1086 (428.0150)	mem 14369MB
[2022-12-20 14:00:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [67/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8771 (0.8832)	loss 4.7505 (5.7364)	grad_norm 326.2718 (422.5663)	mem 14369MB
[2022-12-20 14:00:49 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 67 training takes 0:01:05
[2022-12-20 14:00:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][0/74]	eta 0:01:51 lr 0.000007	time 1.5116 (1.5116)	loss 3.1796 (3.1796)	grad_norm 332.6296 (332.6296)	mem 14369MB
[2022-12-20 14:00:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8792 (0.9274)	loss 7.5717 (5.6269)	grad_norm 581.1503 (487.2503)	mem 14369MB
[2022-12-20 14:01:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8591 (0.9005)	loss 5.7771 (5.6935)	grad_norm 632.7810 (474.3441)	mem 14369MB
[2022-12-20 14:01:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8738 (0.8911)	loss 9.0195 (5.6689)	grad_norm 613.9199 (447.0176)	mem 14369MB
[2022-12-20 14:01:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8683 (0.8864)	loss 3.8667 (5.4536)	grad_norm 314.8898 (433.5133)	mem 14369MB
[2022-12-20 14:01:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8706 (0.8847)	loss 3.6655 (5.3180)	grad_norm 189.8346 (418.3383)	mem 14369MB
[2022-12-20 14:01:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8698 (0.8823)	loss 7.4818 (5.2981)	grad_norm 431.7341 (407.0993)	mem 14369MB
[2022-12-20 14:01:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [68/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8705 (0.8804)	loss 8.2970 (5.4601)	grad_norm 515.2902 (420.5977)	mem 14369MB
[2022-12-20 14:01:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 68 training takes 0:01:05
[2022-12-20 14:01:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5241 (1.5241)	loss 6.2797 (6.2797)	grad_norm 438.0847 (438.0847)	mem 14369MB
[2022-12-20 14:02:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8658 (0.9292)	loss 4.0416 (5.1006)	grad_norm 390.4000 (431.9110)	mem 14369MB
[2022-12-20 14:02:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8699 (0.9005)	loss 4.7819 (5.3622)	grad_norm 382.2584 (411.9869)	mem 14369MB
[2022-12-20 14:02:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8698 (0.8916)	loss 4.2649 (5.2395)	grad_norm 387.6388 (395.8718)	mem 14369MB
[2022-12-20 14:02:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8660 (0.8868)	loss 4.9886 (5.3769)	grad_norm 612.1891 (422.2292)	mem 14369MB
[2022-12-20 14:02:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8602 (0.8838)	loss 3.6036 (5.3362)	grad_norm 273.0245 (415.6265)	mem 14369MB
[2022-12-20 14:02:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8604 (0.8821)	loss 4.4512 (5.4285)	grad_norm 560.3468 (434.7532)	mem 14369MB
[2022-12-20 14:02:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [69/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8864 (0.8814)	loss 6.6720 (5.5020)	grad_norm 467.7941 (443.6283)	mem 14369MB
[2022-12-20 14:02:59 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 69 training takes 0:01:05
[2022-12-20 14:03:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5343 (1.5343)	loss 3.9172 (3.9172)	grad_norm 288.7184 (288.7184)	mem 14369MB
[2022-12-20 14:03:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8673 (0.9303)	loss 4.9269 (4.9513)	grad_norm 277.4285 (354.8704)	mem 14369MB
[2022-12-20 14:03:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8815 (0.9036)	loss 5.0317 (4.9925)	grad_norm 330.7455 (391.6299)	mem 14369MB
[2022-12-20 14:03:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8688 (0.8954)	loss 6.3952 (5.0468)	grad_norm 724.9246 (408.0587)	mem 14369MB
[2022-12-20 14:03:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8786 (0.8915)	loss 4.9794 (4.9921)	grad_norm 228.3009 (393.3725)	mem 14369MB
[2022-12-20 14:03:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8868 (0.8884)	loss 4.6378 (5.1153)	grad_norm 474.5371 (404.8144)	mem 14369MB
[2022-12-20 14:03:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8667 (0.8861)	loss 5.8704 (5.2386)	grad_norm 453.2934 (425.4935)	mem 14369MB
[2022-12-20 14:04:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [70/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8724 (0.8838)	loss 3.2677 (5.2640)	grad_norm 341.3605 (427.6354)	mem 14369MB
[2022-12-20 14:04:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 70 training takes 0:01:05
[2022-12-20 14:04:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5188 (1.5188)	loss 3.6693 (3.6693)	grad_norm 291.8117 (291.8117)	mem 14369MB
[2022-12-20 14:04:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8885 (0.9339)	loss 7.3149 (5.3218)	grad_norm 473.8314 (448.8708)	mem 14369MB
[2022-12-20 14:04:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][20/74]	eta 0:00:49 lr 0.000007	time 0.8821 (0.9080)	loss 5.3019 (4.9265)	grad_norm 292.5379 (397.4514)	mem 14369MB
[2022-12-20 14:04:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8678 (0.8968)	loss 4.8529 (4.9474)	grad_norm 541.4922 (423.4654)	mem 14369MB
[2022-12-20 14:04:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8746 (0.8921)	loss 4.6455 (5.2967)	grad_norm 487.6604 (422.8675)	mem 14369MB
[2022-12-20 14:04:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8835 (0.8888)	loss 3.7887 (5.3492)	grad_norm 149.0352 (412.5693)	mem 14369MB
[2022-12-20 14:04:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8704 (0.8868)	loss 3.5524 (5.6101)	grad_norm 264.3280 (417.7459)	mem 14369MB
[2022-12-20 14:05:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [71/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8649 (0.8843)	loss 4.0572 (5.5259)	grad_norm 160.3985 (416.6804)	mem 14369MB
[2022-12-20 14:05:10 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 71 training takes 0:01:05
[2022-12-20 14:05:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5245 (1.5245)	loss 4.9375 (4.9375)	grad_norm 384.7489 (384.7489)	mem 14369MB
[2022-12-20 14:05:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8694 (0.9316)	loss 3.4770 (5.0326)	grad_norm 240.1979 (360.5115)	mem 14369MB
[2022-12-20 14:05:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8701 (0.9018)	loss 5.3967 (4.8532)	grad_norm 492.7630 (399.3963)	mem 14369MB
[2022-12-20 14:05:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8617 (0.8914)	loss 4.1274 (5.2274)	grad_norm 450.8921 (413.7422)	mem 14369MB
[2022-12-20 14:05:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8783 (0.8874)	loss 7.3008 (5.2163)	grad_norm 584.5216 (408.3449)	mem 14369MB
[2022-12-20 14:05:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8656 (0.8860)	loss 3.1698 (5.1117)	grad_norm 365.2683 (406.3565)	mem 14369MB
[2022-12-20 14:06:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8779 (0.8840)	loss 3.6188 (5.1120)	grad_norm 283.3530 (399.5029)	mem 14369MB
[2022-12-20 14:06:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [72/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8706 (0.8824)	loss 5.2898 (5.1094)	grad_norm 292.2761 (392.4927)	mem 14369MB
[2022-12-20 14:06:15 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 72 training takes 0:01:05
[2022-12-20 14:06:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][0/74]	eta 0:01:54 lr 0.000007	time 1.5457 (1.5457)	loss 3.5290 (3.5290)	grad_norm 213.3939 (213.3939)	mem 14369MB
[2022-12-20 14:06:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8848 (0.9342)	loss 3.9574 (4.4404)	grad_norm 304.5787 (319.7863)	mem 14369MB
[2022-12-20 14:06:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8630 (0.9042)	loss 6.6605 (4.6797)	grad_norm 774.3154 (353.1240)	mem 14369MB
[2022-12-20 14:06:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8779 (0.8943)	loss 5.7700 (4.7174)	grad_norm 221.2559 (350.3692)	mem 14369MB
[2022-12-20 14:06:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8684 (0.8896)	loss 3.4522 (4.8997)	grad_norm 372.2861 (369.7177)	mem 14369MB
[2022-12-20 14:07:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8754 (0.8863)	loss 3.7616 (4.8983)	grad_norm 346.7943 (361.3555)	mem 14369MB
[2022-12-20 14:07:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8681 (0.8839)	loss 4.9206 (4.8955)	grad_norm 420.5368 (364.2543)	mem 14369MB
[2022-12-20 14:07:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [73/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8745 (0.8822)	loss 4.8524 (4.9891)	grad_norm 146.1877 (368.8620)	mem 14369MB
[2022-12-20 14:07:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 73 training takes 0:01:05
[2022-12-20 14:07:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5163 (1.5163)	loss 3.9048 (3.9048)	grad_norm 244.8136 (244.8136)	mem 14369MB
[2022-12-20 14:07:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8680 (0.9296)	loss 5.5088 (5.2743)	grad_norm 335.6061 (380.2644)	mem 14369MB
[2022-12-20 14:07:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8730 (0.9050)	loss 5.6451 (5.2024)	grad_norm 644.4074 (426.5547)	mem 14369MB
[2022-12-20 14:07:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8780 (0.8974)	loss 4.5030 (5.0158)	grad_norm 373.9381 (407.0868)	mem 14369MB
[2022-12-20 14:07:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8865 (0.8931)	loss 4.2171 (4.9850)	grad_norm 281.7349 (405.1622)	mem 14369MB
[2022-12-20 14:08:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8704 (0.8905)	loss 9.5224 (5.0427)	grad_norm 582.9481 (395.9799)	mem 14369MB
[2022-12-20 14:08:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8925 (0.8881)	loss 4.5170 (5.0220)	grad_norm 246.7859 (386.1710)	mem 14369MB
[2022-12-20 14:08:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [74/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8758 (0.8872)	loss 3.9246 (5.0485)	grad_norm 358.5137 (391.3004)	mem 14369MB
[2022-12-20 14:08:26 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 74 training takes 0:01:05
[2022-12-20 14:08:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5379 (1.5379)	loss 7.0624 (7.0624)	grad_norm 396.0617 (396.0617)	mem 14369MB
[2022-12-20 14:08:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8605 (0.9301)	loss 8.1810 (5.6294)	grad_norm 712.8757 (419.1306)	mem 14369MB
[2022-12-20 14:08:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8667 (0.9004)	loss 6.5225 (5.3320)	grad_norm 277.0568 (404.6139)	mem 14369MB
[2022-12-20 14:08:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][30/74]	eta 0:00:39 lr 0.000007	time 0.9396 (0.8956)	loss 3.6845 (5.3372)	grad_norm 232.8478 (412.1972)	mem 14369MB
[2022-12-20 14:09:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8865 (0.8899)	loss 3.7313 (5.3027)	grad_norm 260.3911 (391.4864)	mem 14369MB
[2022-12-20 14:09:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8781 (0.8863)	loss 6.2406 (5.4022)	grad_norm 314.0568 (403.8078)	mem 14369MB
[2022-12-20 14:09:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8778 (0.8841)	loss 4.1545 (5.3622)	grad_norm 285.1506 (415.1638)	mem 14369MB
[2022-12-20 14:09:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [75/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8711 (0.8824)	loss 4.9137 (5.3262)	grad_norm 343.2308 (408.9737)	mem 14369MB
[2022-12-20 14:09:31 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 75 training takes 0:01:05
[2022-12-20 14:09:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5151 (1.5151)	loss 12.8961 (12.8961)	grad_norm 753.2434 (753.2434)	mem 14369MB
[2022-12-20 14:09:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8685 (0.9270)	loss 4.7003 (5.4887)	grad_norm 328.8558 (411.9503)	mem 14369MB
[2022-12-20 14:09:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8827 (0.9023)	loss 4.7836 (5.1951)	grad_norm 261.4941 (374.5515)	mem 14369MB
[2022-12-20 14:09:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8738 (0.8921)	loss 3.8212 (5.0244)	grad_norm 250.1352 (352.2560)	mem 14369MB
[2022-12-20 14:10:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8668 (0.8884)	loss 4.3421 (5.0159)	grad_norm 558.4071 (369.4343)	mem 14369MB
[2022-12-20 14:10:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8733 (0.8859)	loss 4.3142 (5.0876)	grad_norm 302.9413 (369.8675)	mem 14369MB
[2022-12-20 14:10:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8772 (0.8841)	loss 4.2033 (5.0608)	grad_norm 291.7490 (366.8415)	mem 14369MB
[2022-12-20 14:10:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [76/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8661 (0.8823)	loss 4.6434 (4.9594)	grad_norm 631.0878 (371.5415)	mem 14369MB
[2022-12-20 14:10:36 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 76 training takes 0:01:05
[2022-12-20 14:10:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5275 (1.5275)	loss 4.8948 (4.8948)	grad_norm 328.5231 (328.5231)	mem 14369MB
[2022-12-20 14:10:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8680 (0.9328)	loss 4.0943 (4.5761)	grad_norm 347.8499 (336.5782)	mem 14369MB
[2022-12-20 14:10:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8694 (0.9036)	loss 5.0353 (4.6787)	grad_norm 275.3844 (352.5942)	mem 14369MB
[2022-12-20 14:11:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8857 (0.8940)	loss 3.0458 (4.7791)	grad_norm 174.1807 (357.5962)	mem 14369MB
[2022-12-20 14:11:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8840 (0.8882)	loss 5.4920 (4.9460)	grad_norm 449.6679 (375.4618)	mem 14369MB
[2022-12-20 14:11:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8682 (0.8854)	loss 5.7187 (4.8852)	grad_norm 267.5509 (367.1251)	mem 14369MB
[2022-12-20 14:11:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8758 (0.8837)	loss 5.5902 (4.9311)	grad_norm 280.1161 (367.7373)	mem 14369MB
[2022-12-20 14:11:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [77/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8833 (0.8828)	loss 4.8841 (4.8844)	grad_norm 236.8210 (373.8833)	mem 14369MB
[2022-12-20 14:11:41 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 77 training takes 0:01:05
[2022-12-20 14:11:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5255 (1.5255)	loss 3.5882 (3.5882)	grad_norm 148.1503 (148.1503)	mem 14369MB
[2022-12-20 14:11:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8711 (0.9279)	loss 3.5852 (4.0859)	grad_norm 373.8395 (352.4891)	mem 14369MB
[2022-12-20 14:12:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8728 (0.9032)	loss 4.7523 (4.4900)	grad_norm 269.0508 (346.5099)	mem 14369MB
[2022-12-20 14:12:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8650 (0.8940)	loss 3.5824 (4.4495)	grad_norm 91.6753 (322.2956)	mem 14369MB
[2022-12-20 14:12:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8780 (0.8894)	loss 5.2248 (4.4522)	grad_norm 338.9464 (322.2370)	mem 14369MB
[2022-12-20 14:12:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8756 (0.8857)	loss 4.7949 (4.4097)	grad_norm 436.0839 (319.6438)	mem 14369MB
[2022-12-20 14:12:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8765 (0.8839)	loss 4.1313 (4.6005)	grad_norm 272.0506 (328.5663)	mem 14369MB
[2022-12-20 14:12:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [78/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8792 (0.8824)	loss 6.8988 (4.7227)	grad_norm 210.3354 (334.6768)	mem 14369MB
[2022-12-20 14:12:47 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 78 training takes 0:01:05
[2022-12-20 14:12:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][0/74]	eta 0:01:53 lr 0.000007	time 1.5281 (1.5281)	loss 3.6530 (3.6530)	grad_norm 265.8963 (265.8963)	mem 14369MB
[2022-12-20 14:12:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][10/74]	eta 0:00:59 lr 0.000007	time 0.8688 (0.9277)	loss 3.4731 (4.1979)	grad_norm 486.4699 (350.7700)	mem 14369MB
[2022-12-20 14:13:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][20/74]	eta 0:00:48 lr 0.000007	time 0.8677 (0.8994)	loss 4.3598 (4.6666)	grad_norm 375.4688 (343.1237)	mem 14369MB
[2022-12-20 14:13:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][30/74]	eta 0:00:39 lr 0.000007	time 0.8864 (0.8906)	loss 3.8715 (4.4791)	grad_norm 218.8960 (314.7231)	mem 14369MB
[2022-12-20 14:13:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8767 (0.8875)	loss 4.2705 (4.5634)	grad_norm 231.4723 (328.0824)	mem 14369MB
[2022-12-20 14:13:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][50/74]	eta 0:00:21 lr 0.000007	time 0.8788 (0.8858)	loss 4.0382 (4.6445)	grad_norm 308.5388 (330.5631)	mem 14369MB
[2022-12-20 14:13:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][60/74]	eta 0:00:12 lr 0.000007	time 0.8651 (0.8858)	loss 8.2241 (4.7510)	grad_norm 386.1736 (340.3694)	mem 14369MB
[2022-12-20 14:13:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [79/300][70/74]	eta 0:00:03 lr 0.000007	time 0.8705 (0.8836)	loss 5.4159 (4.7571)	grad_norm 479.3962 (344.7477)	mem 14369MB
[2022-12-20 14:13:52 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 79 training takes 0:01:05
[2022-12-20 14:13:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][0/74]	eta 0:01:52 lr 0.000007	time 1.5223 (1.5223)	loss 5.6101 (5.6101)	grad_norm 319.8416 (319.8416)	mem 14369MB
[2022-12-20 14:14:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][10/74]	eta 0:01:02 lr 0.000007	time 0.8701 (0.9829)	loss 4.8197 (4.7738)	grad_norm 222.6242 (357.5090)	mem 14369MB
[2022-12-20 14:14:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][20/74]	eta 0:00:50 lr 0.000007	time 0.8619 (0.9294)	loss 8.9886 (4.7513)	grad_norm 448.2671 (366.5994)	mem 14369MB
[2022-12-20 14:14:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][30/74]	eta 0:00:40 lr 0.000007	time 0.8850 (0.9109)	loss 3.3864 (4.7227)	grad_norm 194.4822 (361.1607)	mem 14369MB
[2022-12-20 14:14:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][40/74]	eta 0:00:30 lr 0.000007	time 0.8928 (0.9012)	loss 5.0711 (4.6692)	grad_norm 225.3217 (345.8918)	mem 14369MB
[2022-12-20 14:14:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8731 (0.8957)	loss 5.5524 (4.6161)	grad_norm 364.5997 (350.6959)	mem 14369MB
[2022-12-20 14:14:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8638 (0.8919)	loss 8.6388 (4.6901)	grad_norm 313.2021 (351.8036)	mem 14369MB
[2022-12-20 14:14:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [80/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8722 (0.8898)	loss 5.0152 (4.7623)	grad_norm 360.9541 (359.1830)	mem 14369MB
[2022-12-20 14:14:58 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 80 training takes 0:01:05
[2022-12-20 14:14:58 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_80.pth saving......
[2022-12-20 14:14:59 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_80.pth saved !!!
[2022-12-20 14:15:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5139 (1.5139)	loss 3.3977 (3.3977)	grad_norm 229.8018 (229.8018)	mem 14369MB
[2022-12-20 14:15:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8584 (0.9259)	loss 6.0344 (4.1816)	grad_norm 873.9991 (351.1901)	mem 14369MB
[2022-12-20 14:15:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8684 (0.8998)	loss 6.1539 (4.5950)	grad_norm 571.4869 (338.0493)	mem 14369MB
[2022-12-20 14:15:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8738 (0.8921)	loss 5.2131 (4.8289)	grad_norm 473.1436 (344.1426)	mem 14369MB
[2022-12-20 14:15:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8621 (0.8865)	loss 5.1033 (4.7305)	grad_norm 697.7312 (351.3591)	mem 14369MB
[2022-12-20 14:15:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8897 (0.8833)	loss 4.5937 (4.7202)	grad_norm 185.3408 (352.9299)	mem 14369MB
[2022-12-20 14:15:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8673 (0.8818)	loss 4.0548 (4.7081)	grad_norm 235.6126 (346.5041)	mem 14369MB
[2022-12-20 14:16:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [81/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8769 (0.8808)	loss 4.9976 (4.6814)	grad_norm 230.7073 (341.3442)	mem 14369MB
[2022-12-20 14:16:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 81 training takes 0:01:05
[2022-12-20 14:16:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5073 (1.5073)	loss 4.5223 (4.5223)	grad_norm 295.0878 (295.0878)	mem 14369MB
[2022-12-20 14:16:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8673 (0.9265)	loss 6.7624 (5.1779)	grad_norm 1003.5083 (343.0085)	mem 14369MB
[2022-12-20 14:16:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8728 (0.9006)	loss 4.9956 (5.0652)	grad_norm 314.3462 (379.6693)	mem 14369MB
[2022-12-20 14:16:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8640 (0.8918)	loss 5.9316 (4.9149)	grad_norm 599.4788 (376.9365)	mem 14369MB
[2022-12-20 14:16:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8694 (0.8865)	loss 4.1175 (4.8195)	grad_norm 313.1169 (366.1102)	mem 14369MB
[2022-12-20 14:16:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8781 (0.8833)	loss 3.4179 (4.6617)	grad_norm 202.7888 (349.3578)	mem 14369MB
[2022-12-20 14:16:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8611 (0.8815)	loss 6.7185 (4.8799)	grad_norm 638.4214 (362.8647)	mem 14369MB
[2022-12-20 14:17:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [82/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8861 (0.8798)	loss 5.0349 (4.8880)	grad_norm 252.7380 (353.3894)	mem 14369MB
[2022-12-20 14:17:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 82 training takes 0:01:04
[2022-12-20 14:17:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5112 (1.5112)	loss 5.4328 (5.4328)	grad_norm 329.8218 (329.8218)	mem 14369MB
[2022-12-20 14:17:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8737 (0.9293)	loss 4.5956 (5.0504)	grad_norm 373.8590 (277.0624)	mem 14369MB
[2022-12-20 14:17:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8747 (0.9020)	loss 5.1076 (4.7268)	grad_norm 184.8120 (257.7646)	mem 14369MB
[2022-12-20 14:17:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8687 (0.8915)	loss 5.6162 (4.6825)	grad_norm 427.4369 (272.7171)	mem 14369MB
[2022-12-20 14:17:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8865 (0.8866)	loss 3.7313 (4.5714)	grad_norm 280.3382 (290.8874)	mem 14369MB
[2022-12-20 14:17:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8725 (0.8848)	loss 5.7855 (4.5674)	grad_norm 508.8313 (299.0343)	mem 14369MB
[2022-12-20 14:18:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8705 (0.8833)	loss 4.2460 (4.5468)	grad_norm 433.6728 (309.2077)	mem 14369MB
[2022-12-20 14:18:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [83/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8657 (0.8815)	loss 4.9207 (4.5344)	grad_norm 634.7860 (317.4968)	mem 14369MB
[2022-12-20 14:18:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 83 training takes 0:01:05
[2022-12-20 14:18:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5215 (1.5215)	loss 3.2747 (3.2747)	grad_norm 163.7996 (163.7996)	mem 14369MB
[2022-12-20 14:18:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8690 (0.9345)	loss 4.1986 (3.9302)	grad_norm 254.3332 (304.7782)	mem 14369MB
[2022-12-20 14:18:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8638 (0.9054)	loss 4.7605 (4.0513)	grad_norm 287.8360 (317.0624)	mem 14369MB
[2022-12-20 14:18:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8785 (0.8943)	loss 4.6660 (4.2826)	grad_norm 407.8117 (327.4288)	mem 14369MB
[2022-12-20 14:18:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8656 (0.8881)	loss 8.3512 (4.4472)	grad_norm 715.5137 (353.0901)	mem 14369MB
[2022-12-20 14:18:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8667 (0.8847)	loss 7.4585 (4.4666)	grad_norm 127.0862 (336.8395)	mem 14369MB
[2022-12-20 14:19:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8634 (0.8834)	loss 4.0935 (4.5668)	grad_norm 468.6457 (332.4470)	mem 14369MB
[2022-12-20 14:19:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [84/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8684 (0.8816)	loss 4.5802 (4.5444)	grad_norm 323.3028 (345.4926)	mem 14369MB
[2022-12-20 14:19:19 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 84 training takes 0:01:05
[2022-12-20 14:19:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5103 (1.5103)	loss 4.5618 (4.5618)	grad_norm 308.0412 (308.0412)	mem 14369MB
[2022-12-20 14:19:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8676 (0.9248)	loss 3.8383 (4.5074)	grad_norm 229.7318 (310.8505)	mem 14369MB
[2022-12-20 14:19:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8786 (0.9000)	loss 3.1301 (4.4426)	grad_norm 150.9829 (331.9227)	mem 14369MB
[2022-12-20 14:19:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8737 (0.8910)	loss 4.0980 (4.3067)	grad_norm 261.9587 (335.9996)	mem 14369MB
[2022-12-20 14:19:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8779 (0.8880)	loss 4.5981 (4.4346)	grad_norm 246.8849 (338.6829)	mem 14369MB
[2022-12-20 14:20:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8841 (0.8857)	loss 3.8419 (4.4496)	grad_norm 247.7821 (350.2569)	mem 14369MB
[2022-12-20 14:20:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8717 (0.8838)	loss 4.3474 (4.5421)	grad_norm 321.4271 (343.2767)	mem 14369MB
[2022-12-20 14:20:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [85/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8761 (0.8822)	loss 5.3752 (4.5361)	grad_norm 320.8005 (340.4237)	mem 14369MB
[2022-12-20 14:20:24 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 85 training takes 0:01:05
[2022-12-20 14:20:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5251 (1.5251)	loss 4.2813 (4.2813)	grad_norm 476.3121 (476.3121)	mem 14369MB
[2022-12-20 14:20:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8749 (0.9307)	loss 5.6989 (4.5624)	grad_norm 191.7266 (364.3539)	mem 14369MB
[2022-12-20 14:20:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8684 (0.9032)	loss 4.5604 (4.4422)	grad_norm 494.0705 (324.2060)	mem 14369MB
[2022-12-20 14:20:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8722 (0.8930)	loss 3.2779 (4.7094)	grad_norm 356.2386 (330.8572)	mem 14369MB
[2022-12-20 14:21:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8699 (0.8904)	loss 6.1839 (4.7655)	grad_norm 432.2430 (336.6363)	mem 14369MB
[2022-12-20 14:21:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8838 (0.8876)	loss 4.6360 (4.6899)	grad_norm 183.4549 (328.5568)	mem 14369MB
[2022-12-20 14:21:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8690 (0.8845)	loss 4.5936 (4.6055)	grad_norm 302.8808 (332.7091)	mem 14369MB
[2022-12-20 14:21:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [86/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8774 (0.8820)	loss 3.6613 (4.5419)	grad_norm 298.6655 (335.7080)	mem 14369MB
[2022-12-20 14:21:29 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 86 training takes 0:01:05
[2022-12-20 14:21:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5078 (1.5078)	loss 3.6107 (3.6107)	grad_norm 480.2475 (480.2475)	mem 14369MB
[2022-12-20 14:21:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8627 (0.9257)	loss 3.8466 (4.2417)	grad_norm 559.2714 (377.0052)	mem 14369MB
[2022-12-20 14:21:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8672 (0.8996)	loss 3.6184 (4.8843)	grad_norm 340.2652 (387.0778)	mem 14369MB
[2022-12-20 14:21:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8645 (0.8889)	loss 3.3733 (4.9094)	grad_norm 349.8560 (381.3014)	mem 14369MB
[2022-12-20 14:22:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8745 (0.8852)	loss 4.4835 (4.8253)	grad_norm 382.7817 (370.0074)	mem 14369MB
[2022-12-20 14:22:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8887 (0.8826)	loss 8.8901 (4.7568)	grad_norm 585.4092 (354.2717)	mem 14369MB
[2022-12-20 14:22:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8633 (0.8808)	loss 3.4148 (4.7805)	grad_norm 290.5059 (363.4926)	mem 14369MB
[2022-12-20 14:22:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [87/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8659 (0.8796)	loss 3.5643 (4.7926)	grad_norm 303.0900 (366.2506)	mem 14369MB
[2022-12-20 14:22:34 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 87 training takes 0:01:04
[2022-12-20 14:22:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5099 (1.5099)	loss 2.8106 (2.8106)	grad_norm 236.8585 (236.8585)	mem 14369MB
[2022-12-20 14:22:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8686 (0.9300)	loss 3.2322 (5.3439)	grad_norm 207.1239 (305.4268)	mem 14369MB
[2022-12-20 14:22:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8651 (0.9009)	loss 4.1426 (4.9992)	grad_norm 416.7070 (350.8385)	mem 14369MB
[2022-12-20 14:23:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8826 (0.8904)	loss 3.4268 (4.7229)	grad_norm 202.1757 (348.3189)	mem 14369MB
[2022-12-20 14:23:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8665 (0.8855)	loss 7.0518 (4.7348)	grad_norm 353.3350 (344.8154)	mem 14369MB
[2022-12-20 14:23:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8695 (0.8830)	loss 4.1585 (4.6301)	grad_norm 508.5805 (337.1832)	mem 14369MB
[2022-12-20 14:23:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8784 (0.8817)	loss 4.1563 (4.6397)	grad_norm 199.1562 (329.3487)	mem 14369MB
[2022-12-20 14:23:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [88/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8691 (0.8803)	loss 4.2781 (4.5976)	grad_norm 257.1985 (335.4779)	mem 14369MB
[2022-12-20 14:23:39 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 88 training takes 0:01:05
[2022-12-20 14:23:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5212 (1.5212)	loss 4.2954 (4.2954)	grad_norm 344.1753 (344.1753)	mem 14369MB
[2022-12-20 14:23:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][10/74]	eta 0:01:00 lr 0.000006	time 0.8662 (0.9504)	loss 4.6712 (4.3683)	grad_norm 456.4921 (398.5373)	mem 14369MB
[2022-12-20 14:23:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][20/74]	eta 0:00:49 lr 0.000006	time 0.8681 (0.9128)	loss 3.8315 (4.1472)	grad_norm 295.8688 (350.3242)	mem 14369MB
[2022-12-20 14:24:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8656 (0.8993)	loss 3.9997 (4.2270)	grad_norm 313.2588 (342.2954)	mem 14369MB
[2022-12-20 14:24:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8674 (0.8925)	loss 4.5908 (4.2572)	grad_norm 243.6781 (343.9749)	mem 14369MB
[2022-12-20 14:24:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8702 (0.8891)	loss 3.8649 (4.3566)	grad_norm 238.0284 (320.9959)	mem 14369MB
[2022-12-20 14:24:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8753 (0.8868)	loss 3.3505 (4.3241)	grad_norm 300.1654 (315.4693)	mem 14369MB
[2022-12-20 14:24:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [89/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8674 (0.8844)	loss 4.3203 (4.3811)	grad_norm 315.7765 (312.8636)	mem 14369MB
[2022-12-20 14:24:45 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 89 training takes 0:01:05
[2022-12-20 14:24:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5243 (1.5243)	loss 2.8338 (2.8338)	grad_norm 320.9119 (320.9119)	mem 14369MB
[2022-12-20 14:24:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8787 (0.9358)	loss 3.5843 (4.4836)	grad_norm 247.2023 (319.1969)	mem 14369MB
[2022-12-20 14:25:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][20/74]	eta 0:00:49 lr 0.000006	time 0.9010 (0.9089)	loss 3.6003 (4.6282)	grad_norm 190.1469 (310.5908)	mem 14369MB
[2022-12-20 14:25:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8742 (0.8984)	loss 4.1211 (4.5182)	grad_norm 201.0328 (300.4322)	mem 14369MB
[2022-12-20 14:25:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8841 (0.8924)	loss 4.7852 (4.5307)	grad_norm 340.4934 (305.6689)	mem 14369MB
[2022-12-20 14:25:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8876 (0.8894)	loss 4.2277 (4.3581)	grad_norm 197.0826 (296.1553)	mem 14369MB
[2022-12-20 14:25:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8749 (0.8871)	loss 3.6452 (4.4120)	grad_norm 385.7986 (303.2543)	mem 14369MB
[2022-12-20 14:25:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [90/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8785 (0.8861)	loss 3.2842 (4.3280)	grad_norm 307.6250 (293.1959)	mem 14369MB
[2022-12-20 14:25:50 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 90 training takes 0:01:05
[2022-12-20 14:25:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5187 (1.5187)	loss 3.6733 (3.6733)	grad_norm 140.5758 (140.5758)	mem 14369MB
[2022-12-20 14:26:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][10/74]	eta 0:01:00 lr 0.000006	time 0.8705 (0.9378)	loss 5.1596 (4.6621)	grad_norm 561.5311 (337.3338)	mem 14369MB
[2022-12-20 14:26:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][20/74]	eta 0:00:49 lr 0.000006	time 0.8829 (0.9096)	loss 3.5661 (4.7533)	grad_norm 161.1661 (359.0019)	mem 14369MB
[2022-12-20 14:26:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8862 (0.8980)	loss 4.3582 (4.6478)	grad_norm 247.6970 (352.5291)	mem 14369MB
[2022-12-20 14:26:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8771 (0.8920)	loss 6.3281 (4.5569)	grad_norm 348.2670 (338.9782)	mem 14369MB
[2022-12-20 14:26:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8698 (0.8873)	loss 4.9743 (4.6743)	grad_norm 246.4888 (343.7348)	mem 14369MB
[2022-12-20 14:26:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8635 (0.8847)	loss 4.3535 (4.5995)	grad_norm 689.8019 (347.1582)	mem 14369MB
[2022-12-20 14:26:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [91/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8764 (0.8833)	loss 3.3714 (4.5716)	grad_norm 236.2010 (350.4613)	mem 14369MB
[2022-12-20 14:26:55 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 91 training takes 0:01:05
[2022-12-20 14:26:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5259 (1.5259)	loss 4.0961 (4.0961)	grad_norm 170.4808 (170.4808)	mem 14369MB
[2022-12-20 14:27:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8676 (0.9281)	loss 4.8997 (4.1248)	grad_norm 253.4919 (340.1463)	mem 14369MB
[2022-12-20 14:27:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8749 (0.8994)	loss 3.9257 (3.9850)	grad_norm 335.4477 (348.6777)	mem 14369MB
[2022-12-20 14:27:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8673 (0.8908)	loss 3.5180 (4.0330)	grad_norm 249.6685 (324.4820)	mem 14369MB
[2022-12-20 14:27:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8889 (0.8861)	loss 3.4497 (4.1841)	grad_norm 158.5691 (302.6645)	mem 14369MB
[2022-12-20 14:27:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8807 (0.8842)	loss 5.7931 (4.2008)	grad_norm 405.6735 (309.1446)	mem 14369MB
[2022-12-20 14:27:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8789 (0.8821)	loss 4.5502 (4.2619)	grad_norm 199.7383 (310.0014)	mem 14369MB
[2022-12-20 14:27:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [92/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8722 (0.8802)	loss 4.3494 (4.3260)	grad_norm 207.0247 (312.5415)	mem 14369MB
[2022-12-20 14:28:01 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 92 training takes 0:01:05
[2022-12-20 14:28:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5182 (1.5182)	loss 4.5463 (4.5463)	grad_norm 594.3562 (594.3562)	mem 14369MB
[2022-12-20 14:28:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8860 (0.9290)	loss 4.5318 (4.5337)	grad_norm 337.4122 (385.4530)	mem 14369MB
[2022-12-20 14:28:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8781 (0.8995)	loss 4.8459 (4.8667)	grad_norm 144.6425 (370.3434)	mem 14369MB
[2022-12-20 14:28:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8586 (0.8901)	loss 3.2960 (4.6743)	grad_norm 293.9634 (347.3433)	mem 14369MB
[2022-12-20 14:28:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8749 (0.8873)	loss 8.4090 (4.6390)	grad_norm 136.0252 (335.3085)	mem 14369MB
[2022-12-20 14:28:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8617 (0.8855)	loss 9.5870 (4.6044)	grad_norm 226.1286 (321.0035)	mem 14369MB
[2022-12-20 14:28:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8736 (0.8834)	loss 6.3396 (4.5210)	grad_norm 633.5326 (322.7943)	mem 14369MB
[2022-12-20 14:29:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [93/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8852 (0.8820)	loss 4.3303 (4.4740)	grad_norm 224.7183 (325.1431)	mem 14369MB
[2022-12-20 14:29:06 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 93 training takes 0:01:05
[2022-12-20 14:29:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][0/74]	eta 0:01:50 lr 0.000006	time 1.4989 (1.4989)	loss 3.6536 (3.6536)	grad_norm 322.1593 (322.1593)	mem 14369MB
[2022-12-20 14:29:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8714 (0.9270)	loss 3.2560 (4.0272)	grad_norm 175.1884 (303.0893)	mem 14369MB
[2022-12-20 14:29:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8702 (0.8988)	loss 4.2163 (4.3316)	grad_norm 325.4308 (287.6976)	mem 14369MB
[2022-12-20 14:29:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8630 (0.8900)	loss 3.1629 (4.2756)	grad_norm 305.4988 (291.5721)	mem 14369MB
[2022-12-20 14:29:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8752 (0.8856)	loss 5.6419 (4.2168)	grad_norm 347.7536 (286.8409)	mem 14369MB
[2022-12-20 14:29:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8805 (0.8833)	loss 4.2569 (4.3322)	grad_norm 215.4280 (285.0292)	mem 14369MB
[2022-12-20 14:30:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8606 (0.8819)	loss 2.6939 (4.3190)	grad_norm 367.4492 (289.9360)	mem 14369MB
[2022-12-20 14:30:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [94/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8743 (0.8808)	loss 3.8844 (4.2443)	grad_norm 290.8062 (291.4423)	mem 14369MB
[2022-12-20 14:30:11 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 94 training takes 0:01:05
[2022-12-20 14:30:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5178 (1.5178)	loss 3.9638 (3.9638)	grad_norm 276.8112 (276.8112)	mem 14369MB
[2022-12-20 14:30:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8872 (0.9321)	loss 5.1389 (4.1151)	grad_norm 368.9314 (271.9665)	mem 14369MB
[2022-12-20 14:30:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][20/74]	eta 0:00:49 lr 0.000006	time 0.8896 (0.9076)	loss 3.5356 (3.8935)	grad_norm 249.1539 (258.8093)	mem 14369MB
[2022-12-20 14:30:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8711 (0.8983)	loss 3.8897 (4.0107)	grad_norm 260.9613 (255.4776)	mem 14369MB
[2022-12-20 14:30:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8736 (0.8924)	loss 3.4214 (4.1035)	grad_norm 351.4157 (268.6889)	mem 14369MB
[2022-12-20 14:30:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8727 (0.8880)	loss 4.0117 (4.1594)	grad_norm 174.6853 (274.3142)	mem 14369MB
[2022-12-20 14:31:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8684 (0.8855)	loss 2.9574 (4.2042)	grad_norm 154.5099 (279.8594)	mem 14369MB
[2022-12-20 14:31:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [95/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8883 (0.8837)	loss 4.1002 (4.2440)	grad_norm 266.3194 (292.5066)	mem 14369MB
[2022-12-20 14:31:16 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 95 training takes 0:01:05
[2022-12-20 14:31:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5200 (1.5200)	loss 4.8190 (4.8190)	grad_norm 243.4008 (243.4008)	mem 14369MB
[2022-12-20 14:31:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8769 (0.9337)	loss 3.9574 (4.1963)	grad_norm 332.5223 (337.4153)	mem 14369MB
[2022-12-20 14:31:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][20/74]	eta 0:00:49 lr 0.000006	time 0.8873 (0.9083)	loss 2.7742 (4.0447)	grad_norm 168.9355 (312.2238)	mem 14369MB
[2022-12-20 14:31:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8734 (0.8982)	loss 3.7169 (4.0357)	grad_norm 179.5531 (297.7610)	mem 14369MB
[2022-12-20 14:31:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8714 (0.8904)	loss 4.3005 (4.1205)	grad_norm 194.2124 (294.4344)	mem 14369MB
[2022-12-20 14:32:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8860 (0.8873)	loss 5.1444 (4.1503)	grad_norm 273.3556 (295.4315)	mem 14369MB
[2022-12-20 14:32:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8733 (0.8846)	loss 4.3750 (4.1645)	grad_norm 260.3041 (293.3909)	mem 14369MB
[2022-12-20 14:32:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [96/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8839 (0.8834)	loss 3.2166 (4.1431)	grad_norm 195.7412 (286.6521)	mem 14369MB
[2022-12-20 14:32:21 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 96 training takes 0:01:05
[2022-12-20 14:32:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5039 (1.5039)	loss 3.4256 (3.4256)	grad_norm 345.5357 (345.5357)	mem 14369MB
[2022-12-20 14:32:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8779 (0.9272)	loss 4.0284 (4.9243)	grad_norm 225.1942 (333.3533)	mem 14369MB
[2022-12-20 14:32:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8649 (0.9034)	loss 3.8282 (4.4829)	grad_norm 76.4464 (300.0488)	mem 14369MB
[2022-12-20 14:32:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8796 (0.8949)	loss 3.3810 (4.3212)	grad_norm 240.5158 (277.6494)	mem 14369MB
[2022-12-20 14:32:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8739 (0.8906)	loss 3.7924 (4.2996)	grad_norm 280.5858 (278.9881)	mem 14369MB
[2022-12-20 14:33:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8648 (0.8868)	loss 3.3426 (4.2684)	grad_norm 310.0659 (290.2513)	mem 14369MB
[2022-12-20 14:33:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8703 (0.8841)	loss 4.6649 (4.1735)	grad_norm 556.6803 (293.6060)	mem 14369MB
[2022-12-20 14:33:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [97/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8775 (0.8824)	loss 3.7979 (4.1605)	grad_norm 139.9188 (293.6892)	mem 14369MB
[2022-12-20 14:33:27 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 97 training takes 0:01:05
[2022-12-20 14:33:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5000 (1.5000)	loss 4.5375 (4.5375)	grad_norm 437.2925 (437.2925)	mem 14369MB
[2022-12-20 14:33:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8774 (0.9347)	loss 3.9428 (3.7130)	grad_norm 424.5032 (310.1265)	mem 14369MB
[2022-12-20 14:33:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8629 (0.9060)	loss 5.1682 (4.3326)	grad_norm 518.4433 (326.2055)	mem 14369MB
[2022-12-20 14:33:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8685 (0.8942)	loss 3.6461 (4.1563)	grad_norm 199.9301 (297.6855)	mem 14369MB
[2022-12-20 14:34:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8906 (0.8889)	loss 4.3731 (4.1181)	grad_norm 318.7417 (300.1412)	mem 14369MB
[2022-12-20 14:34:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8715 (0.8863)	loss 3.2978 (4.1445)	grad_norm 343.1921 (314.1087)	mem 14369MB
[2022-12-20 14:34:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8759 (0.8851)	loss 5.1276 (4.2689)	grad_norm 258.0328 (310.9104)	mem 14369MB
[2022-12-20 14:34:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [98/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8633 (0.8842)	loss 3.9385 (4.2195)	grad_norm 374.2473 (300.2177)	mem 14369MB
[2022-12-20 14:34:32 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 98 training takes 0:01:05
[2022-12-20 14:34:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5123 (1.5123)	loss 3.8275 (3.8275)	grad_norm 270.4970 (270.4970)	mem 14369MB
[2022-12-20 14:34:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8649 (0.9303)	loss 2.3302 (3.7903)	grad_norm 172.8145 (256.4494)	mem 14369MB
[2022-12-20 14:34:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8677 (0.9007)	loss 3.6609 (4.2095)	grad_norm 357.7641 (296.2970)	mem 14369MB
[2022-12-20 14:35:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8781 (0.8918)	loss 4.0865 (4.2394)	grad_norm 334.9406 (314.0753)	mem 14369MB
[2022-12-20 14:35:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8670 (0.8863)	loss 3.7319 (4.1011)	grad_norm 257.5734 (290.2996)	mem 14369MB
[2022-12-20 14:35:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8706 (0.8835)	loss 3.1742 (4.1627)	grad_norm 199.9528 (280.0291)	mem 14369MB
[2022-12-20 14:35:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8679 (0.8811)	loss 4.2407 (4.1758)	grad_norm 286.4671 (294.5315)	mem 14369MB
[2022-12-20 14:35:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [99/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8684 (0.8801)	loss 3.6041 (4.1964)	grad_norm 291.3371 (293.4281)	mem 14369MB
[2022-12-20 14:35:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 99 training takes 0:01:05
[2022-12-20 14:35:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5243 (1.5243)	loss 8.1488 (8.1488)	grad_norm 314.3243 (314.3243)	mem 14369MB
[2022-12-20 14:35:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][10/74]	eta 0:01:00 lr 0.000006	time 0.8813 (0.9380)	loss 3.8397 (4.6124)	grad_norm 149.4460 (378.6645)	mem 14369MB
[2022-12-20 14:35:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][20/74]	eta 0:00:49 lr 0.000006	time 0.8643 (0.9079)	loss 3.5174 (4.3833)	grad_norm 311.1351 (318.9086)	mem 14369MB
[2022-12-20 14:36:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8746 (0.8963)	loss 4.2006 (4.2501)	grad_norm 480.2291 (315.0611)	mem 14369MB
[2022-12-20 14:36:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8680 (0.8906)	loss 3.7787 (4.1623)	grad_norm 242.9261 (307.3511)	mem 14369MB
[2022-12-20 14:36:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8684 (0.8872)	loss 4.7781 (4.1179)	grad_norm 385.4998 (312.9026)	mem 14369MB
[2022-12-20 14:36:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8626 (0.8855)	loss 5.9781 (4.1062)	grad_norm 668.2450 (306.0675)	mem 14369MB
[2022-12-20 14:36:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [100/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8771 (0.8833)	loss 3.9994 (4.1267)	grad_norm 186.7987 (300.9702)	mem 14369MB
[2022-12-20 14:36:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 100 training takes 0:01:05
[2022-12-20 14:36:42 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_100.pth saving......
[2022-12-20 14:36:43 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_100.pth saved !!!
[2022-12-20 14:36:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5056 (1.5056)	loss 3.6256 (3.6256)	grad_norm 298.4715 (298.4715)	mem 14369MB
[2022-12-20 14:36:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8770 (0.9286)	loss 4.1732 (3.8632)	grad_norm 298.0505 (278.5777)	mem 14369MB
[2022-12-20 14:37:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8605 (0.9025)	loss 3.4937 (3.8625)	grad_norm 170.0113 (274.3756)	mem 14369MB
[2022-12-20 14:37:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8573 (0.8916)	loss 2.8463 (3.8460)	grad_norm 164.6284 (260.6150)	mem 14369MB
[2022-12-20 14:37:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8752 (0.8873)	loss 4.8496 (4.0345)	grad_norm 273.8338 (246.4459)	mem 14369MB
[2022-12-20 14:37:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8659 (0.8846)	loss 2.6409 (4.1225)	grad_norm 249.4599 (259.6673)	mem 14369MB
[2022-12-20 14:37:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8674 (0.8828)	loss 5.7748 (4.1992)	grad_norm 653.9690 (278.4197)	mem 14369MB
[2022-12-20 14:37:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [101/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8727 (0.8810)	loss 4.8563 (4.1450)	grad_norm 235.7095 (275.2747)	mem 14369MB
[2022-12-20 14:37:48 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 101 training takes 0:01:05
[2022-12-20 14:37:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5052 (1.5052)	loss 4.1526 (4.1526)	grad_norm 488.1085 (488.1085)	mem 14369MB
[2022-12-20 14:37:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8620 (0.9294)	loss 3.1618 (4.2529)	grad_norm 356.2801 (338.0769)	mem 14369MB
[2022-12-20 14:38:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8756 (0.9012)	loss 4.5296 (4.9389)	grad_norm 279.6390 (406.8831)	mem 14369MB
[2022-12-20 14:38:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8686 (0.8921)	loss 5.6218 (4.8888)	grad_norm 125.7002 (355.0586)	mem 14369MB
[2022-12-20 14:38:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8649 (0.8860)	loss 3.1020 (4.5555)	grad_norm 267.7411 (333.8626)	mem 14369MB
[2022-12-20 14:38:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8793 (0.8824)	loss 3.6653 (4.4262)	grad_norm 216.7428 (330.2121)	mem 14369MB
[2022-12-20 14:38:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8818 (0.8810)	loss 3.1181 (4.3499)	grad_norm 185.6354 (334.4150)	mem 14369MB
[2022-12-20 14:38:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [102/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8936 (0.8807)	loss 3.3506 (4.3132)	grad_norm 245.2097 (322.6190)	mem 14369MB
[2022-12-20 14:38:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 102 training takes 0:01:05
[2022-12-20 14:38:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5011 (1.5011)	loss 4.8060 (4.8060)	grad_norm 340.6242 (340.6242)	mem 14369MB
[2022-12-20 14:39:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8718 (0.9271)	loss 3.0576 (3.7576)	grad_norm 245.5778 (250.9288)	mem 14369MB
[2022-12-20 14:39:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8659 (0.8983)	loss 3.1444 (3.8040)	grad_norm 241.7986 (266.4195)	mem 14369MB
[2022-12-20 14:39:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8638 (0.8880)	loss 5.4186 (3.9338)	grad_norm 289.5645 (283.6000)	mem 14369MB
[2022-12-20 14:39:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8758 (0.8844)	loss 3.4315 (3.9525)	grad_norm 339.6541 (284.2861)	mem 14369MB
[2022-12-20 14:39:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8855 (0.8835)	loss 3.0123 (3.9857)	grad_norm 269.1682 (283.9604)	mem 14369MB
[2022-12-20 14:39:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8890 (0.8833)	loss 3.6040 (4.0236)	grad_norm 186.7846 (285.2754)	mem 14369MB
[2022-12-20 14:39:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [103/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8701 (0.8821)	loss 3.2274 (4.0878)	grad_norm 166.6387 (286.8377)	mem 14369MB
[2022-12-20 14:39:59 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 103 training takes 0:01:05
[2022-12-20 14:40:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5137 (1.5137)	loss 3.9201 (3.9201)	grad_norm 342.3454 (342.3454)	mem 14369MB
[2022-12-20 14:40:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8781 (0.9358)	loss 5.0331 (4.0617)	grad_norm 191.7032 (261.3673)	mem 14369MB
[2022-12-20 14:40:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][20/74]	eta 0:00:49 lr 0.000006	time 0.8804 (0.9076)	loss 4.6927 (4.0155)	grad_norm 226.2032 (262.0685)	mem 14369MB
[2022-12-20 14:40:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8727 (0.8977)	loss 4.6460 (4.3185)	grad_norm 378.4735 (274.0931)	mem 14369MB
[2022-12-20 14:40:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8712 (0.8914)	loss 4.2597 (4.1415)	grad_norm 271.4800 (260.9589)	mem 14369MB
[2022-12-20 14:40:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8882 (0.8874)	loss 3.6081 (4.1573)	grad_norm 207.1463 (257.6461)	mem 14369MB
[2022-12-20 14:40:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8605 (0.8842)	loss 3.5315 (4.0446)	grad_norm 388.4707 (250.9526)	mem 14369MB
[2022-12-20 14:41:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [104/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8651 (0.8821)	loss 4.5054 (3.9772)	grad_norm 249.6543 (249.0624)	mem 14369MB
[2022-12-20 14:41:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 104 training takes 0:01:05
[2022-12-20 14:41:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5160 (1.5160)	loss 4.2077 (4.2077)	grad_norm 233.9387 (233.9387)	mem 14369MB
[2022-12-20 14:41:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8874 (0.9345)	loss 3.1400 (3.7782)	grad_norm 149.3044 (251.7567)	mem 14369MB
[2022-12-20 14:41:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][20/74]	eta 0:00:49 lr 0.000006	time 0.8758 (0.9075)	loss 3.9780 (4.1906)	grad_norm 260.1574 (258.2485)	mem 14369MB
[2022-12-20 14:41:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8708 (0.8974)	loss 3.2391 (4.0243)	grad_norm 153.2267 (252.3321)	mem 14369MB
[2022-12-20 14:41:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8603 (0.8924)	loss 5.3378 (3.9038)	grad_norm 539.2557 (252.3956)	mem 14369MB
[2022-12-20 14:41:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8747 (0.8886)	loss 4.7196 (3.9169)	grad_norm 258.3721 (261.8312)	mem 14369MB
[2022-12-20 14:41:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8696 (0.8867)	loss 4.3390 (3.9942)	grad_norm 282.1610 (265.2108)	mem 14369MB
[2022-12-20 14:42:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [105/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8870 (0.8858)	loss 6.1579 (4.0275)	grad_norm 148.9563 (265.2156)	mem 14369MB
[2022-12-20 14:42:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 105 training takes 0:01:05
[2022-12-20 14:42:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][0/74]	eta 0:01:52 lr 0.000006	time 1.5178 (1.5178)	loss 4.7382 (4.7382)	grad_norm 352.6159 (352.6159)	mem 14369MB
[2022-12-20 14:42:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8617 (0.9316)	loss 3.0591 (3.9735)	grad_norm 334.0018 (267.0038)	mem 14369MB
[2022-12-20 14:42:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8695 (0.9031)	loss 3.9069 (3.8511)	grad_norm 170.4627 (262.9599)	mem 14369MB
[2022-12-20 14:42:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8664 (0.8928)	loss 4.1860 (4.0010)	grad_norm 354.9466 (272.3156)	mem 14369MB
[2022-12-20 14:42:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8662 (0.8878)	loss 4.6915 (4.0628)	grad_norm 436.7839 (279.0154)	mem 14369MB
[2022-12-20 14:42:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8665 (0.8848)	loss 3.8315 (4.0373)	grad_norm 307.0866 (275.3144)	mem 14369MB
[2022-12-20 14:43:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8667 (0.8828)	loss 3.4853 (3.9985)	grad_norm 339.1987 (273.0932)	mem 14369MB
[2022-12-20 14:43:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [106/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8700 (0.8809)	loss 3.0599 (4.0907)	grad_norm 197.9562 (281.1649)	mem 14369MB
[2022-12-20 14:43:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 106 training takes 0:01:05
[2022-12-20 14:43:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5074 (1.5074)	loss 3.8710 (3.8710)	grad_norm 426.1976 (426.1976)	mem 14369MB
[2022-12-20 14:43:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8810 (0.9318)	loss 3.1133 (3.7551)	grad_norm 176.3170 (252.3136)	mem 14369MB
[2022-12-20 14:43:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8840 (0.9047)	loss 3.2917 (3.8238)	grad_norm 173.5744 (236.9083)	mem 14369MB
[2022-12-20 14:43:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8872 (0.8952)	loss 2.7147 (3.9048)	grad_norm 132.1451 (248.2937)	mem 14369MB
[2022-12-20 14:43:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8669 (0.8888)	loss 3.3534 (3.9585)	grad_norm 130.6762 (257.0145)	mem 14369MB
[2022-12-20 14:44:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8821 (0.8855)	loss 3.3982 (3.9646)	grad_norm 156.6414 (248.6500)	mem 14369MB
[2022-12-20 14:44:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8816 (0.8837)	loss 5.3197 (3.9849)	grad_norm 234.6875 (246.3740)	mem 14369MB
[2022-12-20 14:44:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [107/300][70/74]	eta 0:00:03 lr 0.000006	time 0.9039 (0.8824)	loss 3.8025 (3.9793)	grad_norm 157.0760 (251.4923)	mem 14369MB
[2022-12-20 14:44:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 107 training takes 0:01:05
[2022-12-20 14:44:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][0/74]	eta 0:01:51 lr 0.000006	time 1.5119 (1.5119)	loss 3.5241 (3.5241)	grad_norm 210.8098 (210.8098)	mem 14369MB
[2022-12-20 14:44:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8672 (0.9241)	loss 3.9174 (4.4892)	grad_norm 327.2867 (258.3410)	mem 14369MB
[2022-12-20 14:44:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8708 (0.8973)	loss 3.9672 (4.1944)	grad_norm 250.9889 (241.6121)	mem 14369MB
[2022-12-20 14:44:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8696 (0.8889)	loss 5.1829 (4.0179)	grad_norm 256.8598 (238.7537)	mem 14369MB
[2022-12-20 14:44:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8748 (0.8848)	loss 7.0398 (4.0019)	grad_norm 171.7983 (240.0164)	mem 14369MB
[2022-12-20 14:45:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8687 (0.8827)	loss 5.3628 (4.0525)	grad_norm 387.3218 (255.9628)	mem 14369MB
[2022-12-20 14:45:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8705 (0.8821)	loss 2.8356 (4.0388)	grad_norm 144.7340 (257.9026)	mem 14369MB
[2022-12-20 14:45:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [108/300][70/74]	eta 0:00:03 lr 0.000006	time 0.8654 (0.8803)	loss 3.3955 (3.9781)	grad_norm 424.7829 (267.7991)	mem 14369MB
[2022-12-20 14:45:25 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 108 training takes 0:01:04
[2022-12-20 14:45:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][0/74]	eta 0:01:50 lr 0.000006	time 1.4981 (1.4981)	loss 2.7694 (2.7694)	grad_norm 339.3610 (339.3610)	mem 14369MB
[2022-12-20 14:45:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][10/74]	eta 0:00:59 lr 0.000006	time 0.8625 (0.9248)	loss 6.0225 (4.3438)	grad_norm 242.6623 (272.1796)	mem 14369MB
[2022-12-20 14:45:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][20/74]	eta 0:00:48 lr 0.000006	time 0.8656 (0.8978)	loss 4.9528 (4.2072)	grad_norm 278.6978 (285.5663)	mem 14369MB
[2022-12-20 14:45:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][30/74]	eta 0:00:39 lr 0.000006	time 0.8750 (0.8897)	loss 3.3948 (4.1446)	grad_norm 379.1286 (267.1999)	mem 14369MB
[2022-12-20 14:46:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][40/74]	eta 0:00:30 lr 0.000006	time 0.8711 (0.8855)	loss 4.8533 (4.0604)	grad_norm 180.0355 (260.8360)	mem 14369MB
[2022-12-20 14:46:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][50/74]	eta 0:00:21 lr 0.000006	time 0.8647 (0.8828)	loss 4.6296 (4.1183)	grad_norm 333.1537 (255.1967)	mem 14369MB
[2022-12-20 14:46:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][60/74]	eta 0:00:12 lr 0.000006	time 0.8689 (0.8810)	loss 5.6755 (4.0897)	grad_norm 628.4731 (263.6378)	mem 14369MB
[2022-12-20 14:46:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [109/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8662 (0.8803)	loss 5.1834 (4.0237)	grad_norm 407.6170 (258.9995)	mem 14369MB
[2022-12-20 14:46:30 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 109 training takes 0:01:05
[2022-12-20 14:46:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5238 (1.5238)	loss 3.1564 (3.1564)	grad_norm 139.2618 (139.2618)	mem 14369MB
[2022-12-20 14:46:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8808 (0.9290)	loss 4.0202 (3.7428)	grad_norm 262.5444 (247.8854)	mem 14369MB
[2022-12-20 14:46:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8775 (0.9028)	loss 3.3457 (4.3497)	grad_norm 200.8478 (281.8739)	mem 14369MB
[2022-12-20 14:46:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8628 (0.8926)	loss 3.5801 (4.2426)	grad_norm 174.5329 (284.2144)	mem 14369MB
[2022-12-20 14:47:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][40/74]	eta 0:00:30 lr 0.000005	time 0.9037 (0.8880)	loss 5.7695 (4.1358)	grad_norm 300.4072 (273.4070)	mem 14369MB
[2022-12-20 14:47:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8602 (0.8839)	loss 3.3942 (4.0556)	grad_norm 311.7806 (274.4037)	mem 14369MB
[2022-12-20 14:47:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8685 (0.8824)	loss 5.1425 (4.2652)	grad_norm 400.9942 (276.7526)	mem 14369MB
[2022-12-20 14:47:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [110/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8784 (0.8812)	loss 4.7603 (4.1844)	grad_norm 250.1759 (276.9360)	mem 14369MB
[2022-12-20 14:47:35 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 110 training takes 0:01:05
[2022-12-20 14:47:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5148 (1.5148)	loss 2.9600 (2.9600)	grad_norm 382.4293 (382.4293)	mem 14369MB
[2022-12-20 14:47:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8877 (0.9373)	loss 3.4200 (3.5432)	grad_norm 161.2495 (225.7955)	mem 14369MB
[2022-12-20 14:47:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][20/74]	eta 0:00:49 lr 0.000005	time 0.8780 (0.9094)	loss 3.3589 (3.6137)	grad_norm 224.6111 (227.9084)	mem 14369MB
[2022-12-20 14:48:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8793 (0.8965)	loss 3.8658 (3.7844)	grad_norm 206.0152 (244.8463)	mem 14369MB
[2022-12-20 14:48:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8693 (0.8906)	loss 6.2023 (3.8425)	grad_norm 449.7511 (237.7186)	mem 14369MB
[2022-12-20 14:48:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8876 (0.8878)	loss 3.1566 (3.7480)	grad_norm 171.7527 (231.0413)	mem 14369MB
[2022-12-20 14:48:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8755 (0.8849)	loss 3.2749 (3.7404)	grad_norm 202.8366 (227.6812)	mem 14369MB
[2022-12-20 14:48:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [111/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8901 (0.8827)	loss 6.6461 (3.8390)	grad_norm 455.8707 (233.6644)	mem 14369MB
[2022-12-20 14:48:40 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 111 training takes 0:01:05
[2022-12-20 14:48:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][0/74]	eta 0:01:51 lr 0.000005	time 1.5068 (1.5068)	loss 4.0205 (4.0205)	grad_norm 308.8836 (308.8836)	mem 14369MB
[2022-12-20 14:48:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8734 (0.9288)	loss 5.0481 (3.8854)	grad_norm 244.0798 (254.8710)	mem 14369MB
[2022-12-20 14:48:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8615 (0.9005)	loss 5.1552 (3.9916)	grad_norm 161.4246 (273.7326)	mem 14369MB
[2022-12-20 14:49:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8708 (0.8909)	loss 3.5366 (3.9257)	grad_norm 279.6235 (270.3698)	mem 14369MB
[2022-12-20 14:49:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8841 (0.8878)	loss 2.7669 (3.8811)	grad_norm 130.6218 (257.3528)	mem 14369MB
[2022-12-20 15:36:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][50/74]	eta 0:22:40 lr 0.000005	time 0.8651 (56.6815)	loss 3.3075 (3.9512)	grad_norm 177.5417 (255.5056)	mem 14369MB
[2022-12-20 15:37:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][60/74]	eta 0:11:05 lr 0.000005	time 0.8611 (47.5312)	loss 2.6430 (3.8395)	grad_norm 193.2830 (244.2426)	mem 14369MB
[2022-12-20 15:37:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [112/300][70/74]	eta 0:02:43 lr 0.000005	time 0.8686 (40.9593)	loss 3.9078 (3.8768)	grad_norm 367.6798 (246.2631)	mem 14369MB
[2022-12-20 15:37:11 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 112 training takes 0:48:30
[2022-12-20 15:37:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][0/74]	eta 0:01:51 lr 0.000005	time 1.5124 (1.5124)	loss 3.2485 (3.2485)	grad_norm 168.7905 (168.7905)	mem 14369MB
[2022-12-20 15:37:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][10/74]	eta 0:00:58 lr 0.000005	time 0.8608 (0.9218)	loss 5.6650 (3.5638)	grad_norm 157.3481 (237.2992)	mem 14369MB
[2022-12-20 15:37:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8665 (0.8960)	loss 3.6832 (3.7270)	grad_norm 246.4331 (256.0891)	mem 14369MB
[2022-12-20 15:37:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][30/74]	eta 0:00:38 lr 0.000005	time 0.8580 (0.8856)	loss 3.4726 (3.6791)	grad_norm 429.1959 (252.9613)	mem 14369MB
[2022-12-20 15:37:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][40/74]	eta 0:00:29 lr 0.000005	time 0.8611 (0.8800)	loss 3.6896 (3.8142)	grad_norm 258.3738 (252.3259)	mem 14369MB
[2022-12-20 15:37:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][50/74]	eta 0:00:21 lr 0.000005	time 0.9048 (0.8787)	loss 3.4130 (3.7987)	grad_norm 160.4837 (242.7792)	mem 14369MB
[2022-12-20 15:38:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8727 (0.8768)	loss 3.9437 (3.9017)	grad_norm 250.4528 (239.9739)	mem 14369MB
[2022-12-20 15:38:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [113/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8661 (0.8752)	loss 4.0086 (3.8951)	grad_norm 189.9458 (237.0148)	mem 14369MB
[2022-12-20 15:38:15 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 113 training takes 0:01:04
[2022-12-20 15:38:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5145 (1.5145)	loss 4.2852 (4.2852)	grad_norm 264.7116 (264.7116)	mem 14369MB
[2022-12-20 15:38:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8861 (0.9267)	loss 3.8702 (4.1141)	grad_norm 206.7825 (241.5811)	mem 14369MB
[2022-12-20 15:38:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8763 (0.9018)	loss 3.2250 (3.7703)	grad_norm 207.1151 (214.3753)	mem 14369MB
[2022-12-20 15:38:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8848 (0.8926)	loss 3.7798 (3.7510)	grad_norm 228.1187 (204.8668)	mem 14369MB
[2022-12-20 15:38:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8900 (0.8883)	loss 3.3800 (3.7083)	grad_norm 201.1299 (203.8316)	mem 14369MB
[2022-12-20 15:39:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8786 (0.8860)	loss 5.0217 (3.8484)	grad_norm 331.3375 (219.7953)	mem 14369MB
[2022-12-20 15:39:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8894 (0.8847)	loss 4.2953 (3.8274)	grad_norm 251.3570 (218.2909)	mem 14369MB
[2022-12-20 15:39:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [114/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8758 (0.8832)	loss 2.8186 (3.7850)	grad_norm 248.8753 (221.8168)	mem 14369MB
[2022-12-20 15:39:21 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 114 training takes 0:01:05
[2022-12-20 15:39:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][0/74]	eta 0:01:54 lr 0.000005	time 1.5461 (1.5461)	loss 2.7429 (2.7429)	grad_norm 150.8067 (150.8067)	mem 14369MB
[2022-12-20 15:39:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8614 (0.9296)	loss 5.2732 (3.6742)	grad_norm 564.4526 (237.3255)	mem 14369MB
[2022-12-20 15:39:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8711 (0.9009)	loss 4.2265 (3.6140)	grad_norm 265.7477 (247.1108)	mem 14369MB
[2022-12-20 15:39:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8726 (0.8913)	loss 3.2923 (3.7220)	grad_norm 281.8842 (246.6702)	mem 14369MB
[2022-12-20 15:39:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8670 (0.8865)	loss 3.0511 (3.6476)	grad_norm 242.0251 (236.9440)	mem 14369MB
[2022-12-20 15:40:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8702 (0.8838)	loss 3.5410 (3.6901)	grad_norm 134.9137 (233.6224)	mem 14369MB
[2022-12-20 15:40:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8771 (0.8823)	loss 2.6993 (3.7100)	grad_norm 163.5997 (232.7708)	mem 14369MB
[2022-12-20 15:40:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [115/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8646 (0.8805)	loss 4.0276 (3.7542)	grad_norm 585.9059 (235.3626)	mem 14369MB
[2022-12-20 15:40:26 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 115 training takes 0:01:05
[2022-12-20 15:40:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5203 (1.5203)	loss 3.6992 (3.6992)	grad_norm 249.7646 (249.7646)	mem 14369MB
[2022-12-20 15:40:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8645 (0.9293)	loss 5.6036 (4.2490)	grad_norm 281.8531 (237.3525)	mem 14369MB
[2022-12-20 15:40:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8787 (0.9030)	loss 2.5491 (4.2074)	grad_norm 196.5307 (258.3485)	mem 14369MB
[2022-12-20 15:40:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8722 (0.8932)	loss 3.3932 (4.0045)	grad_norm 156.1692 (247.8248)	mem 14369MB
[2022-12-20 15:41:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8688 (0.8881)	loss 3.2168 (3.9104)	grad_norm 198.5374 (247.8097)	mem 14369MB
[2022-12-20 15:41:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8652 (0.8845)	loss 3.5172 (3.8413)	grad_norm 310.2751 (244.5018)	mem 14369MB
[2022-12-20 15:41:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8628 (0.8831)	loss 2.9514 (3.7520)	grad_norm 330.6989 (239.4678)	mem 14369MB
[2022-12-20 15:41:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [116/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8737 (0.8821)	loss 7.4041 (3.7947)	grad_norm 241.7047 (236.7370)	mem 14369MB
[2022-12-20 15:41:31 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 116 training takes 0:01:05
[2022-12-20 15:41:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5236 (1.5236)	loss 3.6982 (3.6982)	grad_norm 248.3300 (248.3300)	mem 14369MB
[2022-12-20 15:41:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8651 (0.9313)	loss 3.3143 (3.5123)	grad_norm 236.3260 (230.3247)	mem 14369MB
[2022-12-20 15:41:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8631 (0.9026)	loss 3.2118 (3.7247)	grad_norm 276.1573 (242.1205)	mem 14369MB
[2022-12-20 15:41:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8757 (0.8966)	loss 2.9582 (3.6792)	grad_norm 277.8981 (240.3842)	mem 14369MB
[2022-12-20 15:42:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8768 (0.8922)	loss 3.4286 (3.6359)	grad_norm 161.1917 (239.4772)	mem 14369MB
[2022-12-20 15:42:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8838 (0.8887)	loss 2.9932 (3.6955)	grad_norm 215.2360 (233.9213)	mem 14369MB
[2022-12-20 15:42:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8746 (0.8859)	loss 4.2564 (3.7987)	grad_norm 239.7320 (232.2155)	mem 14369MB
[2022-12-20 15:42:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [117/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8663 (0.8844)	loss 3.0812 (3.7847)	grad_norm 220.3200 (230.7969)	mem 14369MB
[2022-12-20 15:42:36 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 117 training takes 0:01:05
[2022-12-20 15:42:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5322 (1.5322)	loss 3.0468 (3.0468)	grad_norm 189.5436 (189.5436)	mem 14369MB
[2022-12-20 15:42:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8848 (0.9342)	loss 3.3918 (3.8124)	grad_norm 233.6391 (235.5797)	mem 14369MB
[2022-12-20 15:42:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8690 (0.9058)	loss 4.8563 (3.9526)	grad_norm 201.4306 (243.6614)	mem 14369MB
[2022-12-20 15:43:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8662 (0.8941)	loss 3.0431 (3.9074)	grad_norm 299.2160 (250.8891)	mem 14369MB
[2022-12-20 15:43:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8675 (0.8891)	loss 4.0654 (3.9122)	grad_norm 159.3401 (248.8087)	mem 14369MB
[2022-12-20 15:43:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8649 (0.8859)	loss 3.1838 (3.8943)	grad_norm 237.0896 (242.1815)	mem 14369MB
[2022-12-20 15:43:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8820 (0.8842)	loss 3.1656 (3.8669)	grad_norm 174.9809 (239.3472)	mem 14369MB
[2022-12-20 15:43:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [118/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8694 (0.8829)	loss 2.5305 (3.8211)	grad_norm 88.0440 (236.6724)	mem 14369MB
[2022-12-20 15:43:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 118 training takes 0:01:05
[2022-12-20 15:43:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5332 (1.5332)	loss 3.5083 (3.5083)	grad_norm 304.9127 (304.9127)	mem 14369MB
[2022-12-20 15:43:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8836 (0.9369)	loss 4.1231 (3.3315)	grad_norm 210.3236 (230.3980)	mem 14369MB
[2022-12-20 15:44:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8674 (0.9058)	loss 3.4956 (3.9021)	grad_norm 245.7982 (230.4453)	mem 14369MB
[2022-12-20 15:44:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8834 (0.8964)	loss 5.1924 (3.9096)	grad_norm 304.2414 (239.6723)	mem 14369MB
[2022-12-20 15:44:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8705 (0.8914)	loss 4.1567 (3.8279)	grad_norm 167.3419 (235.0999)	mem 14369MB
[2022-12-20 15:44:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8929 (0.8888)	loss 3.2565 (3.7122)	grad_norm 167.4214 (229.1436)	mem 14369MB
[2022-12-20 15:44:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8844 (0.8880)	loss 4.2806 (3.7105)	grad_norm 322.2769 (224.9321)	mem 14369MB
[2022-12-20 15:44:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [119/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8901 (0.8865)	loss 4.5829 (3.7353)	grad_norm 288.4580 (235.4213)	mem 14369MB
[2022-12-20 15:44:47 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 119 training takes 0:01:05
[2022-12-20 15:44:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5335 (1.5335)	loss 3.6777 (3.6777)	grad_norm 142.2291 (142.2291)	mem 14369MB
[2022-12-20 15:44:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8714 (0.9367)	loss 4.2685 (3.8529)	grad_norm 232.8170 (214.9870)	mem 14369MB
[2022-12-20 15:45:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][20/74]	eta 0:00:49 lr 0.000005	time 0.8775 (0.9085)	loss 3.0034 (3.6745)	grad_norm 103.0496 (218.1465)	mem 14369MB
[2022-12-20 15:45:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8771 (0.8975)	loss 2.6141 (3.7343)	grad_norm 191.4804 (228.2061)	mem 14369MB
[2022-12-20 15:45:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8844 (0.8919)	loss 4.2922 (3.7559)	grad_norm 227.2912 (233.3005)	mem 14369MB
[2022-12-20 15:45:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8720 (0.8883)	loss 3.5517 (3.7302)	grad_norm 248.7968 (231.3619)	mem 14369MB
[2022-12-20 15:45:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8753 (0.8860)	loss 3.3491 (3.7488)	grad_norm 216.9415 (233.9018)	mem 14369MB
[2022-12-20 15:45:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [120/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8802 (0.8851)	loss 3.1405 (3.7849)	grad_norm 159.5973 (230.1969)	mem 14369MB
[2022-12-20 15:45:52 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 120 training takes 0:01:05
[2022-12-20 15:45:52 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_120.pth saving......
[2022-12-20 15:45:54 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_120.pth saved !!!
[2022-12-20 15:45:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5262 (1.5262)	loss 3.9949 (3.9949)	grad_norm 180.1038 (180.1038)	mem 14369MB
[2022-12-20 15:46:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8626 (0.9319)	loss 4.9723 (3.5117)	grad_norm 452.7411 (212.4566)	mem 14369MB
[2022-12-20 15:46:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8825 (0.9031)	loss 3.0608 (3.5520)	grad_norm 148.4628 (222.8429)	mem 14369MB
[2022-12-20 15:46:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8754 (0.8924)	loss 2.4595 (3.5891)	grad_norm 121.6783 (217.5838)	mem 14369MB
[2022-12-20 15:46:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8717 (0.8868)	loss 3.8054 (3.5799)	grad_norm 263.5435 (216.3357)	mem 14369MB
[2022-12-20 15:46:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8647 (0.8838)	loss 2.9935 (3.6074)	grad_norm 216.7661 (211.4896)	mem 14369MB
[2022-12-20 15:46:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8793 (0.8819)	loss 3.0159 (3.6160)	grad_norm 128.9229 (213.4765)	mem 14369MB
[2022-12-20 15:46:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [121/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8637 (0.8808)	loss 3.2200 (3.6874)	grad_norm 187.7918 (217.0258)	mem 14369MB
[2022-12-20 15:46:59 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 121 training takes 0:01:05
[2022-12-20 15:47:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5135 (1.5135)	loss 2.5163 (2.5163)	grad_norm 200.5642 (200.5642)	mem 14369MB
[2022-12-20 15:47:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8715 (0.9275)	loss 3.7897 (3.5114)	grad_norm 147.9132 (229.4928)	mem 14369MB
[2022-12-20 15:47:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8744 (0.9008)	loss 4.4072 (3.7833)	grad_norm 192.9078 (208.0857)	mem 14369MB
[2022-12-20 15:47:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8694 (0.8904)	loss 3.0903 (3.7536)	grad_norm 285.4780 (220.1191)	mem 14369MB
[2022-12-20 15:47:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8696 (0.8857)	loss 2.5198 (3.7175)	grad_norm 192.9999 (219.0383)	mem 14369MB
[2022-12-20 15:47:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8676 (0.8832)	loss 2.8469 (3.6634)	grad_norm 255.2949 (212.5674)	mem 14369MB
[2022-12-20 15:47:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8840 (0.8815)	loss 5.2140 (3.6902)	grad_norm 189.5279 (211.4878)	mem 14369MB
[2022-12-20 15:48:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [122/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8851 (0.8804)	loss 5.7844 (3.6645)	grad_norm 567.0699 (213.2845)	mem 14369MB
[2022-12-20 15:48:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 122 training takes 0:01:05
[2022-12-20 15:48:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5303 (1.5303)	loss 3.8554 (3.8554)	grad_norm 205.9499 (205.9499)	mem 14369MB
[2022-12-20 15:48:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8784 (0.9352)	loss 2.7458 (3.5917)	grad_norm 198.6985 (255.6883)	mem 14369MB
[2022-12-20 15:48:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8665 (0.9037)	loss 3.0449 (3.8126)	grad_norm 213.7324 (237.0865)	mem 14369MB
[2022-12-20 15:48:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8634 (0.8955)	loss 3.6736 (3.8274)	grad_norm 252.2291 (229.7225)	mem 14369MB
[2022-12-20 15:48:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8634 (0.8897)	loss 3.3894 (3.7190)	grad_norm 231.6551 (228.0301)	mem 14369MB
[2022-12-20 15:48:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8732 (0.8869)	loss 2.9480 (3.6992)	grad_norm 173.3520 (223.5932)	mem 14369MB
[2022-12-20 15:48:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8724 (0.8844)	loss 6.4862 (3.7088)	grad_norm 204.8995 (220.8833)	mem 14369MB
[2022-12-20 15:49:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [123/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8618 (0.8823)	loss 3.2654 (3.6957)	grad_norm 372.5536 (229.3876)	mem 14369MB
[2022-12-20 15:49:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 123 training takes 0:01:05
[2022-12-20 15:49:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5172 (1.5172)	loss 2.4001 (2.4001)	grad_norm 147.6556 (147.6556)	mem 14369MB
[2022-12-20 15:49:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8884 (0.9301)	loss 3.8866 (3.5504)	grad_norm 180.8589 (227.6645)	mem 14369MB
[2022-12-20 15:49:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8793 (0.9021)	loss 3.8787 (3.5321)	grad_norm 185.5097 (212.6867)	mem 14369MB
[2022-12-20 15:49:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][30/74]	eta 0:00:39 lr 0.000005	time 0.9025 (0.8945)	loss 5.6620 (3.6831)	grad_norm 345.0478 (218.5611)	mem 14369MB
[2022-12-20 15:49:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8609 (0.8883)	loss 4.0360 (3.6900)	grad_norm 115.0958 (231.7302)	mem 14369MB
[2022-12-20 15:49:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8783 (0.8852)	loss 2.8435 (3.6968)	grad_norm 167.4663 (229.1809)	mem 14369MB
[2022-12-20 15:50:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8618 (0.8828)	loss 2.6833 (3.6167)	grad_norm 196.1229 (224.0496)	mem 14369MB
[2022-12-20 15:50:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [124/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8908 (0.8811)	loss 4.0602 (3.6090)	grad_norm 171.4760 (224.1445)	mem 14369MB
[2022-12-20 15:50:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 124 training takes 0:01:05
[2022-12-20 15:50:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5288 (1.5288)	loss 2.9369 (2.9369)	grad_norm 119.3695 (119.3695)	mem 14369MB
[2022-12-20 15:50:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8666 (0.9302)	loss 4.9190 (3.8067)	grad_norm 110.4591 (221.4525)	mem 14369MB
[2022-12-20 15:50:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8656 (0.9014)	loss 2.6208 (3.5674)	grad_norm 234.7945 (229.9504)	mem 14369MB
[2022-12-20 15:50:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8646 (0.8914)	loss 3.7742 (3.5091)	grad_norm 626.2668 (244.3050)	mem 14369MB
[2022-12-20 15:50:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8944 (0.8878)	loss 3.3137 (3.6340)	grad_norm 253.3975 (237.5121)	mem 14369MB
[2022-12-20 15:50:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8791 (0.8854)	loss 3.8946 (3.6828)	grad_norm 180.4388 (230.6958)	mem 14369MB
[2022-12-20 15:51:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8754 (0.8836)	loss 3.1281 (3.6528)	grad_norm 151.5513 (226.3940)	mem 14369MB
[2022-12-20 15:51:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [125/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8793 (0.8826)	loss 5.7571 (3.6631)	grad_norm 261.5949 (227.2720)	mem 14369MB
[2022-12-20 15:51:19 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 125 training takes 0:01:05
[2022-12-20 15:51:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][0/74]	eta 0:01:51 lr 0.000005	time 1.5118 (1.5118)	loss 3.1841 (3.1841)	grad_norm 349.4446 (349.4446)	mem 14369MB
[2022-12-20 15:51:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8799 (0.9278)	loss 2.9362 (3.4311)	grad_norm 190.9849 (236.3927)	mem 14369MB
[2022-12-20 15:51:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8686 (0.9014)	loss 3.4205 (3.6344)	grad_norm 203.9188 (216.3037)	mem 14369MB
[2022-12-20 15:51:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8664 (0.8929)	loss 3.3557 (3.5886)	grad_norm 347.3670 (224.9337)	mem 14369MB
[2022-12-20 15:51:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8764 (0.8877)	loss 6.0236 (3.6551)	grad_norm 290.4460 (225.5122)	mem 14369MB
[2022-12-20 15:52:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8749 (0.8847)	loss 3.5439 (3.5789)	grad_norm 209.9796 (225.6407)	mem 14369MB
[2022-12-20 15:52:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8687 (0.8826)	loss 3.7709 (3.6223)	grad_norm 100.6140 (224.9981)	mem 14369MB
[2022-12-20 15:52:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [126/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8707 (0.8808)	loss 3.3887 (3.6851)	grad_norm 143.2601 (223.2752)	mem 14369MB
[2022-12-20 15:52:24 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 126 training takes 0:01:05
[2022-12-20 15:52:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5284 (1.5284)	loss 3.3994 (3.3994)	grad_norm 131.0569 (131.0569)	mem 14369MB
[2022-12-20 15:52:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8757 (0.9335)	loss 3.3904 (3.4691)	grad_norm 159.1897 (212.3591)	mem 14369MB
[2022-12-20 15:52:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8723 (0.9045)	loss 2.3058 (3.4873)	grad_norm 142.6031 (187.3628)	mem 14369MB
[2022-12-20 15:52:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8780 (0.8957)	loss 3.6088 (3.5133)	grad_norm 177.0716 (191.7772)	mem 14369MB
[2022-12-20 15:53:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8679 (0.8891)	loss 3.4429 (3.7054)	grad_norm 232.7572 (199.9676)	mem 14369MB
[2022-12-20 15:53:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8724 (0.8854)	loss 3.8240 (3.7360)	grad_norm 212.6837 (200.0990)	mem 14369MB
[2022-12-20 15:53:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8931 (0.8842)	loss 3.3722 (3.6838)	grad_norm 233.3278 (209.0881)	mem 14369MB
[2022-12-20 15:53:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [127/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8678 (0.8826)	loss 2.5182 (3.6244)	grad_norm 311.7790 (209.0840)	mem 14369MB
[2022-12-20 15:53:30 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 127 training takes 0:01:05
[2022-12-20 15:53:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5190 (1.5190)	loss 2.7222 (2.7222)	grad_norm 232.6148 (232.6148)	mem 14369MB
[2022-12-20 15:53:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8668 (0.9272)	loss 3.6925 (4.2739)	grad_norm 153.0241 (220.7283)	mem 14369MB
[2022-12-20 15:53:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8772 (0.9005)	loss 3.3681 (4.0627)	grad_norm 191.0414 (219.4268)	mem 14369MB
[2022-12-20 15:53:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8628 (0.8923)	loss 4.0614 (3.9771)	grad_norm 301.6079 (226.4183)	mem 14369MB
[2022-12-20 15:54:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8794 (0.8871)	loss 5.2018 (3.8873)	grad_norm 374.5626 (235.0932)	mem 14369MB
[2022-12-20 15:54:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8745 (0.8854)	loss 2.8566 (3.9207)	grad_norm 188.1290 (226.1645)	mem 14369MB
[2022-12-20 15:54:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8704 (0.8831)	loss 2.5575 (3.8550)	grad_norm 282.7327 (225.6384)	mem 14369MB
[2022-12-20 15:54:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [128/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8720 (0.8815)	loss 3.2593 (3.7603)	grad_norm 153.6110 (220.6384)	mem 14369MB
[2022-12-20 15:54:35 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 128 training takes 0:01:05
[2022-12-20 15:54:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5167 (1.5167)	loss 5.0157 (5.0157)	grad_norm 186.4502 (186.4502)	mem 14369MB
[2022-12-20 15:54:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8711 (0.9334)	loss 2.7805 (3.6938)	grad_norm 227.9977 (198.1714)	mem 14369MB
[2022-12-20 15:54:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8733 (0.9053)	loss 4.1615 (3.5711)	grad_norm 224.5801 (197.3209)	mem 14369MB
[2022-12-20 15:55:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8684 (0.8953)	loss 4.1691 (3.4260)	grad_norm 144.3458 (195.8577)	mem 14369MB
[2022-12-20 15:55:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8689 (0.8892)	loss 3.2446 (3.4026)	grad_norm 148.5230 (190.9033)	mem 14369MB
[2022-12-20 15:55:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8697 (0.8853)	loss 3.0405 (3.4985)	grad_norm 188.8917 (192.3465)	mem 14369MB
[2022-12-20 15:55:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8728 (0.8827)	loss 3.4705 (3.5678)	grad_norm 231.4448 (198.2251)	mem 14369MB
[2022-12-20 15:55:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [129/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8620 (0.8816)	loss 2.8366 (3.5583)	grad_norm 268.5809 (204.2402)	mem 14369MB
[2022-12-20 15:55:40 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 129 training takes 0:01:05
[2022-12-20 15:55:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5262 (1.5262)	loss 4.0928 (4.0928)	grad_norm 404.4916 (404.4916)	mem 14369MB
[2022-12-20 15:55:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8675 (0.9297)	loss 5.2477 (3.7114)	grad_norm 215.2819 (282.6319)	mem 14369MB
[2022-12-20 15:55:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8814 (0.9011)	loss 3.3308 (3.4643)	grad_norm 158.9285 (251.0919)	mem 14369MB
[2022-12-20 15:56:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8751 (0.8908)	loss 3.4864 (3.5914)	grad_norm 132.3301 (239.8313)	mem 14369MB
[2022-12-20 15:56:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8819 (0.8858)	loss 3.8553 (3.7035)	grad_norm 190.4813 (232.8262)	mem 14369MB
[2022-12-20 15:56:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8717 (0.8833)	loss 3.6757 (3.6712)	grad_norm 217.8797 (231.8076)	mem 14369MB
[2022-12-20 15:56:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8697 (0.8818)	loss 2.7542 (3.6397)	grad_norm 129.5942 (224.0956)	mem 14369MB
[2022-12-20 15:56:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [130/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8869 (0.8805)	loss 3.2545 (3.6016)	grad_norm 140.3336 (223.5570)	mem 14369MB
[2022-12-20 15:56:45 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 130 training takes 0:01:05
[2022-12-20 15:56:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5265 (1.5265)	loss 4.1267 (4.1267)	grad_norm 202.3767 (202.3767)	mem 14369MB
[2022-12-20 15:56:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][10/74]	eta 0:01:00 lr 0.000005	time 0.8739 (0.9404)	loss 4.1392 (3.4625)	grad_norm 184.8643 (211.3623)	mem 14369MB
[2022-12-20 15:57:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][20/74]	eta 0:00:49 lr 0.000005	time 0.8751 (0.9100)	loss 3.5624 (3.6581)	grad_norm 118.4743 (199.8102)	mem 14369MB
[2022-12-20 15:57:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8711 (0.9012)	loss 3.1935 (3.5330)	grad_norm 230.7534 (192.9381)	mem 14369MB
[2022-12-20 15:57:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8656 (0.8935)	loss 3.4033 (3.5907)	grad_norm 125.3597 (189.3974)	mem 14369MB
[2022-12-20 15:57:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8710 (0.8894)	loss 3.7008 (3.6048)	grad_norm 141.2070 (190.3291)	mem 14369MB
[2022-12-20 15:57:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8717 (0.8869)	loss 3.9651 (3.5708)	grad_norm 152.1101 (191.5616)	mem 14369MB
[2022-12-20 15:57:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [131/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8735 (0.8856)	loss 3.5565 (3.6079)	grad_norm 508.5089 (194.3691)	mem 14369MB
[2022-12-20 15:57:50 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 131 training takes 0:01:05
[2022-12-20 15:57:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5293 (1.5293)	loss 2.4763 (2.4763)	grad_norm 156.1769 (156.1769)	mem 14369MB
[2022-12-20 15:58:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8761 (0.9360)	loss 3.0799 (3.4539)	grad_norm 107.1896 (222.5396)	mem 14369MB
[2022-12-20 15:58:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][20/74]	eta 0:00:49 lr 0.000005	time 0.8667 (0.9075)	loss 5.0170 (3.8485)	grad_norm 320.1891 (219.0802)	mem 14369MB
[2022-12-20 15:58:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8660 (0.8954)	loss 7.0046 (3.8345)	grad_norm 175.9587 (205.2161)	mem 14369MB
[2022-12-20 15:58:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8716 (0.8895)	loss 3.9253 (3.7365)	grad_norm 182.2231 (204.0346)	mem 14369MB
[2022-12-20 15:58:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8754 (0.8856)	loss 3.7326 (3.7125)	grad_norm 177.8288 (201.0135)	mem 14369MB
[2022-12-20 15:58:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8713 (0.8828)	loss 3.5095 (3.6433)	grad_norm 128.2689 (194.2176)	mem 14369MB
[2022-12-20 15:58:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [132/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8770 (0.8809)	loss 2.8370 (3.6506)	grad_norm 117.8576 (200.9052)	mem 14369MB
[2022-12-20 15:58:55 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 132 training takes 0:01:05
[2022-12-20 15:58:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][0/74]	eta 0:01:51 lr 0.000005	time 1.5102 (1.5102)	loss 3.8041 (3.8041)	grad_norm 159.0140 (159.0140)	mem 14369MB
[2022-12-20 15:59:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8714 (0.9257)	loss 3.7458 (3.5758)	grad_norm 301.1409 (241.1695)	mem 14369MB
[2022-12-20 15:59:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8650 (0.8983)	loss 2.8962 (3.6812)	grad_norm 222.1469 (226.4807)	mem 14369MB
[2022-12-20 15:59:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8746 (0.8909)	loss 3.2710 (3.6243)	grad_norm 129.7388 (202.7003)	mem 14369MB
[2022-12-20 15:59:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8755 (0.8861)	loss 2.9695 (3.5102)	grad_norm 115.8939 (202.8514)	mem 14369MB
[2022-12-20 15:59:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8776 (0.8833)	loss 4.2563 (3.5509)	grad_norm 225.3041 (202.4794)	mem 14369MB
[2022-12-20 15:59:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8777 (0.8812)	loss 3.5684 (3.5685)	grad_norm 163.3259 (202.1653)	mem 14369MB
[2022-12-20 15:59:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [133/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8909 (0.8809)	loss 3.7047 (3.6324)	grad_norm 168.4616 (204.3761)	mem 14369MB
[2022-12-20 16:00:01 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 133 training takes 0:01:05
[2022-12-20 16:00:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][0/74]	eta 0:01:52 lr 0.000005	time 1.5242 (1.5242)	loss 5.4239 (5.4239)	grad_norm 196.9028 (196.9028)	mem 14369MB
[2022-12-20 16:00:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8711 (0.9281)	loss 2.7847 (3.4795)	grad_norm 319.7435 (246.0533)	mem 14369MB
[2022-12-20 16:00:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8718 (0.9018)	loss 3.2350 (3.3601)	grad_norm 161.0888 (197.2512)	mem 14369MB
[2022-12-20 16:00:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8651 (0.8921)	loss 2.7809 (3.3674)	grad_norm 156.0841 (188.5418)	mem 14369MB
[2022-12-20 16:00:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][40/74]	eta 0:00:30 lr 0.000005	time 0.8703 (0.8870)	loss 3.2520 (3.4252)	grad_norm 151.5208 (190.5126)	mem 14369MB
[2022-12-20 16:00:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][50/74]	eta 0:00:21 lr 0.000005	time 0.8704 (0.8841)	loss 4.2465 (3.5489)	grad_norm 158.8612 (197.4204)	mem 14369MB
[2022-12-20 16:00:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][60/74]	eta 0:00:12 lr 0.000005	time 0.8674 (0.8820)	loss 3.2142 (3.5690)	grad_norm 331.4991 (203.3073)	mem 14369MB
[2022-12-20 16:01:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [134/300][70/74]	eta 0:00:03 lr 0.000005	time 0.8705 (0.8806)	loss 3.8252 (3.5896)	grad_norm 169.2457 (200.3972)	mem 14369MB
[2022-12-20 16:01:06 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 134 training takes 0:01:05
[2022-12-20 16:01:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][0/74]	eta 0:01:53 lr 0.000005	time 1.5362 (1.5362)	loss 3.8603 (3.8603)	grad_norm 342.6213 (342.6213)	mem 14369MB
[2022-12-20 16:01:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][10/74]	eta 0:00:59 lr 0.000005	time 0.8846 (0.9321)	loss 4.0265 (3.4386)	grad_norm 170.2685 (238.2162)	mem 14369MB
[2022-12-20 16:01:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][20/74]	eta 0:00:48 lr 0.000005	time 0.8848 (0.9045)	loss 3.6058 (3.8161)	grad_norm 325.2382 (233.4646)	mem 14369MB
[2022-12-20 16:01:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][30/74]	eta 0:00:39 lr 0.000005	time 0.8730 (0.8943)	loss 3.3638 (3.6694)	grad_norm 227.0135 (215.6108)	mem 14369MB
[2022-12-20 16:01:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8819 (0.8891)	loss 4.2337 (3.6002)	grad_norm 170.8028 (208.4272)	mem 14369MB
[2022-12-20 16:01:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8619 (0.8862)	loss 2.7269 (3.5627)	grad_norm 175.7476 (213.4375)	mem 14369MB
[2022-12-20 16:02:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8763 (0.8844)	loss 3.4576 (3.6429)	grad_norm 253.6026 (207.6362)	mem 14369MB
[2022-12-20 16:02:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [135/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8638 (0.8825)	loss 3.3662 (3.6038)	grad_norm 199.1393 (210.4057)	mem 14369MB
[2022-12-20 16:02:11 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 135 training takes 0:01:05
[2022-12-20 16:02:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5150 (1.5150)	loss 4.0849 (4.0849)	grad_norm 227.5887 (227.5887)	mem 14369MB
[2022-12-20 16:02:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8701 (0.9304)	loss 2.8241 (3.8332)	grad_norm 125.1905 (222.6318)	mem 14369MB
[2022-12-20 16:02:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8721 (0.9008)	loss 4.0003 (3.6666)	grad_norm 185.4670 (217.2441)	mem 14369MB
[2022-12-20 16:02:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8738 (0.8942)	loss 3.9288 (3.7488)	grad_norm 376.3934 (218.8278)	mem 14369MB
[2022-12-20 16:02:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8781 (0.8906)	loss 3.0713 (3.7230)	grad_norm 187.4160 (220.1506)	mem 14369MB
[2022-12-20 16:02:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8779 (0.8885)	loss 2.7946 (3.6593)	grad_norm 129.8577 (216.0220)	mem 14369MB
[2022-12-20 16:03:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8766 (0.8857)	loss 3.5547 (3.6728)	grad_norm 279.6513 (211.5697)	mem 14369MB
[2022-12-20 16:03:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [136/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8815 (0.8845)	loss 2.9924 (3.5943)	grad_norm 89.0887 (205.4220)	mem 14369MB
[2022-12-20 16:03:16 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 136 training takes 0:01:05
[2022-12-20 16:03:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][0/74]	eta 0:01:51 lr 0.000004	time 1.5104 (1.5104)	loss 2.7336 (2.7336)	grad_norm 311.6869 (311.6869)	mem 14369MB
[2022-12-20 16:03:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8762 (0.9364)	loss 3.1303 (3.0919)	grad_norm 295.4820 (200.5680)	mem 14369MB
[2022-12-20 16:03:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8655 (0.9055)	loss 3.8118 (3.1332)	grad_norm 282.2115 (183.2020)	mem 14369MB
[2022-12-20 16:03:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8864 (0.8955)	loss 3.7295 (3.3962)	grad_norm 173.8585 (183.6449)	mem 14369MB
[2022-12-20 16:03:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8816 (0.8913)	loss 2.7458 (3.4572)	grad_norm 53.3679 (179.9763)	mem 14369MB
[2022-12-20 16:04:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8722 (0.8884)	loss 3.4836 (3.5312)	grad_norm 362.1554 (183.6337)	mem 14369MB
[2022-12-20 16:04:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8882 (0.8864)	loss 4.2087 (3.5425)	grad_norm 172.2822 (189.7724)	mem 14369MB
[2022-12-20 16:04:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [137/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8725 (0.8845)	loss 2.9398 (3.5391)	grad_norm 166.1937 (189.2318)	mem 14369MB
[2022-12-20 16:04:22 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 137 training takes 0:01:05
[2022-12-20 16:04:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5226 (1.5226)	loss 2.6127 (2.6127)	grad_norm 136.7223 (136.7223)	mem 14369MB
[2022-12-20 16:04:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8721 (0.9354)	loss 2.9208 (3.5906)	grad_norm 183.0412 (229.2771)	mem 14369MB
[2022-12-20 16:04:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8678 (0.9048)	loss 3.4369 (3.7127)	grad_norm 134.6776 (213.0177)	mem 14369MB
[2022-12-20 16:04:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8751 (0.8937)	loss 2.7763 (3.7000)	grad_norm 199.7137 (222.9361)	mem 14369MB
[2022-12-20 16:04:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8691 (0.8894)	loss 3.9894 (3.7452)	grad_norm 327.4638 (222.0775)	mem 14369MB
[2022-12-20 16:05:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8686 (0.8851)	loss 3.2803 (3.7551)	grad_norm 234.4377 (222.8941)	mem 14369MB
[2022-12-20 16:05:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8778 (0.8830)	loss 4.2848 (3.6726)	grad_norm 356.4112 (220.7269)	mem 14369MB
[2022-12-20 16:05:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [138/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8709 (0.8816)	loss 2.5799 (3.6625)	grad_norm 147.3848 (211.7624)	mem 14369MB
[2022-12-20 16:05:27 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 138 training takes 0:01:05
[2022-12-20 16:05:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5142 (1.5142)	loss 4.3686 (4.3686)	grad_norm 315.3512 (315.3512)	mem 14369MB
[2022-12-20 16:05:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8755 (0.9289)	loss 3.1222 (3.3940)	grad_norm 181.8689 (258.9401)	mem 14369MB
[2022-12-20 16:05:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8700 (0.9016)	loss 2.9171 (3.3179)	grad_norm 158.9934 (223.5024)	mem 14369MB
[2022-12-20 16:05:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8833 (0.8946)	loss 3.1677 (3.3146)	grad_norm 81.5120 (209.5050)	mem 14369MB
[2022-12-20 16:06:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8773 (0.8910)	loss 2.7136 (3.3226)	grad_norm 174.7599 (203.4107)	mem 14369MB
[2022-12-20 16:06:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8758 (0.8890)	loss 3.8168 (3.3667)	grad_norm 162.9538 (200.3206)	mem 14369MB
[2022-12-20 16:06:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8751 (0.8867)	loss 3.5791 (3.6029)	grad_norm 187.1038 (203.6238)	mem 14369MB
[2022-12-20 16:06:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [139/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8699 (0.8849)	loss 2.7776 (3.5870)	grad_norm 214.9858 (209.7773)	mem 14369MB
[2022-12-20 16:06:32 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 139 training takes 0:01:05
[2022-12-20 16:06:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5160 (1.5160)	loss 2.9471 (2.9471)	grad_norm 353.4795 (353.4795)	mem 14369MB
[2022-12-20 16:06:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8768 (0.9320)	loss 3.2950 (3.1589)	grad_norm 241.4106 (182.5201)	mem 14369MB
[2022-12-20 16:06:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8690 (0.9030)	loss 4.8606 (3.2273)	grad_norm 132.0810 (170.7896)	mem 14369MB
[2022-12-20 16:07:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8777 (0.8924)	loss 3.5482 (3.5083)	grad_norm 125.6203 (176.1363)	mem 14369MB
[2022-12-20 16:07:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8751 (0.8872)	loss 5.3553 (3.6556)	grad_norm 370.0459 (190.9946)	mem 14369MB
[2022-12-20 16:07:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8666 (0.8843)	loss 2.7712 (3.5975)	grad_norm 228.6961 (214.7015)	mem 14369MB
[2022-12-20 16:07:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8668 (0.8822)	loss 3.3000 (3.6365)	grad_norm 476.6288 (213.2721)	mem 14369MB
[2022-12-20 16:07:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [140/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8705 (0.8813)	loss 5.0590 (3.6915)	grad_norm 201.5284 (219.4775)	mem 14369MB
[2022-12-20 16:07:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 140 training takes 0:01:05
[2022-12-20 16:07:37 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_140.pth saving......
[2022-12-20 16:07:38 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_140.pth saved !!!
[2022-12-20 16:07:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][0/74]	eta 0:01:51 lr 0.000004	time 1.5095 (1.5095)	loss 3.9095 (3.9095)	grad_norm 260.6110 (260.6110)	mem 14369MB
[2022-12-20 16:07:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8737 (0.9253)	loss 3.7021 (3.5164)	grad_norm 90.0369 (196.1114)	mem 14369MB
[2022-12-20 16:07:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8600 (0.9003)	loss 2.6055 (3.5900)	grad_norm 334.2859 (214.9430)	mem 14369MB
[2022-12-20 16:08:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8686 (0.8903)	loss 3.5702 (3.4562)	grad_norm 193.9223 (207.3652)	mem 14369MB
[2022-12-20 16:08:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8686 (0.8867)	loss 2.7938 (3.4730)	grad_norm 173.7979 (206.5408)	mem 14369MB
[2022-12-20 16:08:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8661 (0.8835)	loss 3.4142 (3.5242)	grad_norm 384.2396 (203.7401)	mem 14369MB
[2022-12-20 16:08:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8842 (0.8814)	loss 2.6600 (3.5631)	grad_norm 149.9836 (205.1393)	mem 14369MB
[2022-12-20 16:08:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [141/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8754 (0.8808)	loss 4.4455 (3.5358)	grad_norm 179.3141 (202.4753)	mem 14369MB
[2022-12-20 16:08:43 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 141 training takes 0:01:05
[2022-12-20 16:08:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][0/74]	eta 0:01:51 lr 0.000004	time 1.5054 (1.5054)	loss 3.1244 (3.1244)	grad_norm 303.0457 (303.0457)	mem 14369MB
[2022-12-20 16:08:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8919 (0.9297)	loss 2.8607 (3.3934)	grad_norm 123.4164 (195.1978)	mem 14369MB
[2022-12-20 16:09:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8812 (0.9045)	loss 3.2205 (3.3972)	grad_norm 171.3605 (176.3042)	mem 14369MB
[2022-12-20 16:09:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8729 (0.8945)	loss 3.6639 (3.6717)	grad_norm 112.5177 (171.6915)	mem 14369MB
[2022-12-20 16:09:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8768 (0.8901)	loss 4.2595 (3.6508)	grad_norm 230.9553 (177.1938)	mem 14369MB
[2022-12-20 16:09:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8874 (0.8876)	loss 5.0099 (3.6067)	grad_norm 344.4943 (180.6450)	mem 14369MB
[2022-12-20 16:09:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8697 (0.8850)	loss 3.7876 (3.5546)	grad_norm 339.8303 (179.6904)	mem 14369MB
[2022-12-20 16:09:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [142/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8647 (0.8834)	loss 3.4329 (3.5448)	grad_norm 228.5210 (177.6166)	mem 14369MB
[2022-12-20 16:09:49 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 142 training takes 0:01:05
[2022-12-20 16:09:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][0/74]	eta 0:01:53 lr 0.000004	time 1.5297 (1.5297)	loss 4.6030 (4.6030)	grad_norm 187.0769 (187.0769)	mem 14369MB
[2022-12-20 16:09:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8645 (0.9288)	loss 2.9106 (3.7272)	grad_norm 275.4987 (174.6889)	mem 14369MB
[2022-12-20 16:10:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8618 (0.9011)	loss 2.9110 (3.6966)	grad_norm 290.8991 (199.9001)	mem 14369MB
[2022-12-20 16:10:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8910 (0.8917)	loss 4.4604 (3.6164)	grad_norm 175.1817 (196.2381)	mem 14369MB
[2022-12-20 16:10:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8812 (0.8889)	loss 3.5113 (3.4608)	grad_norm 74.0042 (187.8540)	mem 14369MB
[2022-12-20 16:10:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8678 (0.8852)	loss 5.0470 (3.4729)	grad_norm 668.8377 (203.3742)	mem 14369MB
[2022-12-20 16:10:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8653 (0.8830)	loss 3.3435 (3.4710)	grad_norm 367.9836 (202.9446)	mem 14369MB
[2022-12-20 16:10:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [143/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8767 (0.8820)	loss 3.2594 (3.4750)	grad_norm 171.7292 (195.3030)	mem 14369MB
[2022-12-20 16:10:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 143 training takes 0:01:05
[2022-12-20 16:10:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5188 (1.5188)	loss 2.8382 (2.8382)	grad_norm 200.3299 (200.3299)	mem 14369MB
[2022-12-20 16:11:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8627 (0.9283)	loss 3.0509 (3.7132)	grad_norm 86.6701 (198.5794)	mem 14369MB
[2022-12-20 16:11:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8674 (0.9006)	loss 3.2071 (3.5521)	grad_norm 174.1799 (189.6761)	mem 14369MB
[2022-12-20 16:11:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8726 (0.8918)	loss 4.0703 (3.5384)	grad_norm 269.8216 (186.0266)	mem 14369MB
[2022-12-20 16:11:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8865 (0.8874)	loss 3.9258 (3.4487)	grad_norm 174.4948 (179.1949)	mem 14369MB
[2022-12-20 16:11:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8611 (0.8841)	loss 4.1429 (3.5144)	grad_norm 156.8036 (179.5434)	mem 14369MB
[2022-12-20 16:11:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8738 (0.8824)	loss 3.8594 (3.4848)	grad_norm 159.7444 (182.5341)	mem 14369MB
[2022-12-20 16:11:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [144/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8787 (0.8811)	loss 3.6140 (3.4927)	grad_norm 160.7166 (182.4819)	mem 14369MB
[2022-12-20 16:11:59 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 144 training takes 0:01:05
[2022-12-20 16:12:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5223 (1.5223)	loss 3.8474 (3.8474)	grad_norm 154.8757 (154.8757)	mem 14369MB
[2022-12-20 16:12:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8790 (0.9361)	loss 2.5626 (3.8881)	grad_norm 126.9160 (181.4745)	mem 14369MB
[2022-12-20 16:12:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8856 (0.9044)	loss 3.6044 (3.5644)	grad_norm 236.6265 (197.3240)	mem 14369MB
[2022-12-20 16:12:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8678 (0.8940)	loss 2.5945 (3.3832)	grad_norm 140.2008 (197.0959)	mem 14369MB
[2022-12-20 16:12:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8690 (0.8896)	loss 2.6648 (3.4273)	grad_norm 180.8250 (187.4096)	mem 14369MB
[2022-12-20 16:12:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8672 (0.8862)	loss 3.2609 (3.3938)	grad_norm 198.6044 (191.8346)	mem 14369MB
[2022-12-20 16:12:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8676 (0.8837)	loss 3.2261 (3.4535)	grad_norm 351.4391 (193.7744)	mem 14369MB
[2022-12-20 16:13:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [145/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8785 (0.8828)	loss 2.9648 (3.4641)	grad_norm 122.9659 (185.8599)	mem 14369MB
[2022-12-20 16:13:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 145 training takes 0:01:05
[2022-12-20 16:13:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5245 (1.5245)	loss 3.3722 (3.3722)	grad_norm 238.3639 (238.3639)	mem 14369MB
[2022-12-20 16:13:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8755 (0.9304)	loss 3.8375 (3.0796)	grad_norm 178.7710 (180.2447)	mem 14369MB
[2022-12-20 16:13:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8711 (0.9033)	loss 3.0089 (3.3822)	grad_norm 90.4373 (180.0910)	mem 14369MB
[2022-12-20 16:13:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8684 (0.8933)	loss 3.2441 (3.4870)	grad_norm 151.3297 (178.4485)	mem 14369MB
[2022-12-20 16:13:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8810 (0.8883)	loss 3.5076 (3.6234)	grad_norm 185.9813 (190.6539)	mem 14369MB
[2022-12-20 16:13:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8844 (0.8851)	loss 2.7799 (3.6091)	grad_norm 123.1642 (195.7955)	mem 14369MB
[2022-12-20 16:13:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8738 (0.8824)	loss 2.5017 (3.5504)	grad_norm 133.9147 (193.3544)	mem 14369MB
[2022-12-20 16:14:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [146/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8720 (0.8816)	loss 2.8502 (3.5385)	grad_norm 154.6976 (192.3352)	mem 14369MB
[2022-12-20 16:14:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 146 training takes 0:01:05
[2022-12-20 16:14:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5234 (1.5234)	loss 3.9571 (3.9571)	grad_norm 166.8822 (166.8822)	mem 14369MB
[2022-12-20 16:14:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8731 (0.9285)	loss 2.6288 (3.2802)	grad_norm 138.5485 (203.8696)	mem 14369MB
[2022-12-20 16:14:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8693 (0.9021)	loss 2.5330 (3.5956)	grad_norm 321.0853 (195.0575)	mem 14369MB
[2022-12-20 16:14:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8802 (0.8935)	loss 3.0467 (3.4553)	grad_norm 192.4051 (199.1320)	mem 14369MB
[2022-12-20 16:14:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8781 (0.8894)	loss 3.5181 (3.4313)	grad_norm 100.3780 (202.1013)	mem 14369MB
[2022-12-20 16:14:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8781 (0.8877)	loss 2.9091 (3.3664)	grad_norm 93.9110 (199.1080)	mem 14369MB
[2022-12-20 16:15:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8712 (0.8854)	loss 3.7847 (3.3910)	grad_norm 234.7407 (195.9144)	mem 14369MB
[2022-12-20 16:15:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [147/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8733 (0.8846)	loss 4.4965 (3.5561)	grad_norm 435.6980 (196.0897)	mem 14369MB
[2022-12-20 16:15:15 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 147 training takes 0:01:05
[2022-12-20 16:15:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][0/74]	eta 0:01:51 lr 0.000004	time 1.5079 (1.5079)	loss 3.0658 (3.0658)	grad_norm 227.0608 (227.0608)	mem 14369MB
[2022-12-20 16:15:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8680 (0.9313)	loss 4.1568 (3.1771)	grad_norm 223.2387 (200.9604)	mem 14369MB
[2022-12-20 16:15:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8720 (0.9052)	loss 3.2310 (3.1204)	grad_norm 157.1869 (171.1923)	mem 14369MB
[2022-12-20 16:15:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8762 (0.8948)	loss 4.0317 (3.2436)	grad_norm 154.8752 (172.5600)	mem 14369MB
[2022-12-20 16:15:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8910 (0.8901)	loss 3.2447 (3.2267)	grad_norm 117.4013 (174.6680)	mem 14369MB
[2022-12-20 16:16:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8659 (0.8875)	loss 3.5594 (3.2465)	grad_norm 166.3932 (176.5204)	mem 14369MB
[2022-12-20 16:16:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8892 (0.8866)	loss 4.1561 (3.3212)	grad_norm 184.0905 (175.8146)	mem 14369MB
[2022-12-20 16:16:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [148/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8717 (0.8850)	loss 2.8400 (3.4740)	grad_norm 168.7041 (178.8932)	mem 14369MB
[2022-12-20 16:16:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 148 training takes 0:01:05
[2022-12-20 16:16:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5244 (1.5244)	loss 4.0785 (4.0785)	grad_norm 230.1702 (230.1702)	mem 14369MB
[2022-12-20 16:16:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8849 (0.9311)	loss 4.9262 (3.7195)	grad_norm 281.2187 (199.4249)	mem 14369MB
[2022-12-20 16:16:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8713 (0.9052)	loss 3.6238 (3.5689)	grad_norm 200.8134 (179.3655)	mem 14369MB
[2022-12-20 16:16:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8665 (0.8954)	loss 3.3445 (3.4738)	grad_norm 263.7300 (188.3547)	mem 14369MB
[2022-12-20 16:16:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8707 (0.8900)	loss 3.6079 (3.3700)	grad_norm 120.8773 (174.9332)	mem 14369MB
[2022-12-20 16:17:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8783 (0.8873)	loss 3.4063 (3.3909)	grad_norm 146.7261 (173.9815)	mem 14369MB
[2022-12-20 16:17:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8797 (0.8853)	loss 4.1748 (3.5133)	grad_norm 109.1284 (174.6333)	mem 14369MB
[2022-12-20 16:17:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [149/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8828 (0.8910)	loss 3.1042 (3.5083)	grad_norm 175.4919 (175.2613)	mem 14369MB
[2022-12-20 16:17:26 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 149 training takes 0:01:05
[2022-12-20 16:17:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5236 (1.5236)	loss 3.5101 (3.5101)	grad_norm 135.3236 (135.3236)	mem 14369MB
[2022-12-20 16:17:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8644 (0.9300)	loss 3.4196 (3.1454)	grad_norm 176.6643 (187.7244)	mem 14369MB
[2022-12-20 16:17:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8726 (0.9009)	loss 2.9654 (3.3032)	grad_norm 180.7017 (182.7249)	mem 14369MB
[2022-12-20 16:17:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8741 (0.8934)	loss 4.0228 (3.3205)	grad_norm 188.0415 (184.8319)	mem 14369MB
[2022-12-20 16:18:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8812 (0.8906)	loss 3.0826 (3.2220)	grad_norm 129.6656 (177.2529)	mem 14369MB
[2022-12-20 16:18:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8923 (0.8876)	loss 2.8705 (3.3834)	grad_norm 97.7161 (175.6394)	mem 14369MB
[2022-12-20 16:18:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8842 (0.8860)	loss 3.1444 (3.3812)	grad_norm 133.2429 (175.6657)	mem 14369MB
[2022-12-20 16:18:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [150/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8813 (0.8847)	loss 3.8349 (3.4332)	grad_norm 253.8950 (174.7190)	mem 14369MB
[2022-12-20 16:18:31 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 150 training takes 0:01:05
[2022-12-20 16:18:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][0/74]	eta 0:01:53 lr 0.000004	time 1.5335 (1.5335)	loss 3.3302 (3.3302)	grad_norm 195.2928 (195.2928)	mem 14369MB
[2022-12-20 16:18:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][10/74]	eta 0:01:00 lr 0.000004	time 0.8758 (0.9384)	loss 3.7496 (3.0619)	grad_norm 186.5594 (180.9583)	mem 14369MB
[2022-12-20 16:18:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][20/74]	eta 0:00:49 lr 0.000004	time 0.8753 (0.9104)	loss 3.2540 (3.4410)	grad_norm 196.3413 (174.8490)	mem 14369MB
[2022-12-20 16:18:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8844 (0.8985)	loss 3.0546 (3.5145)	grad_norm 116.0619 (178.2616)	mem 14369MB
[2022-12-20 16:19:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8868 (0.8922)	loss 3.2739 (3.4114)	grad_norm 102.6857 (169.9698)	mem 14369MB
[2022-12-20 16:19:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8694 (0.8873)	loss 3.5364 (3.3640)	grad_norm 181.9897 (171.5501)	mem 14369MB
[2022-12-20 16:19:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8822 (0.8858)	loss 3.1676 (3.4725)	grad_norm 189.3249 (175.1827)	mem 14369MB
[2022-12-20 16:19:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [151/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8668 (0.8845)	loss 2.6589 (3.4429)	grad_norm 177.7844 (174.5040)	mem 14369MB
[2022-12-20 16:19:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 151 training takes 0:01:05
[2022-12-20 16:19:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5222 (1.5222)	loss 3.0378 (3.0378)	grad_norm 155.2483 (155.2483)	mem 14369MB
[2022-12-20 16:19:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8718 (0.9312)	loss 3.7113 (3.3958)	grad_norm 206.9614 (190.2818)	mem 14369MB
[2022-12-20 16:19:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8703 (0.9065)	loss 2.7691 (3.4693)	grad_norm 210.1457 (189.0591)	mem 14369MB
[2022-12-20 16:20:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8869 (0.8973)	loss 3.6116 (3.5208)	grad_norm 123.3754 (185.8248)	mem 14369MB
[2022-12-20 16:20:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8861 (0.8928)	loss 3.6554 (3.5575)	grad_norm 237.3057 (181.0640)	mem 14369MB
[2022-12-20 16:20:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8830 (0.8887)	loss 3.3199 (3.6218)	grad_norm 219.5442 (186.4274)	mem 14369MB
[2022-12-20 16:20:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8698 (0.8862)	loss 2.7003 (3.5833)	grad_norm 111.8457 (180.8667)	mem 14369MB
[2022-12-20 16:20:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [152/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8708 (0.8846)	loss 3.4694 (3.4882)	grad_norm 169.4969 (178.7637)	mem 14369MB
[2022-12-20 16:20:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 152 training takes 0:01:05
[2022-12-20 16:20:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5151 (1.5151)	loss 2.7197 (2.7197)	grad_norm 119.7170 (119.7170)	mem 14369MB
[2022-12-20 16:20:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8665 (0.9313)	loss 4.3886 (3.5064)	grad_norm 254.8923 (128.2425)	mem 14369MB
[2022-12-20 16:21:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8787 (0.9050)	loss 4.8945 (3.4748)	grad_norm 122.0266 (148.6827)	mem 14369MB
[2022-12-20 16:21:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8760 (0.8948)	loss 3.6110 (3.2931)	grad_norm 180.2165 (145.6596)	mem 14369MB
[2022-12-20 16:21:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8703 (0.8899)	loss 3.8446 (3.3053)	grad_norm 192.9333 (148.6311)	mem 14369MB
[2022-12-20 16:21:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8651 (0.8866)	loss 3.5351 (3.3940)	grad_norm 129.6357 (162.5905)	mem 14369MB
[2022-12-20 16:21:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8772 (0.8865)	loss 3.8234 (3.3425)	grad_norm 323.4190 (167.4961)	mem 14369MB
[2022-12-20 16:21:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [153/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8890 (0.8854)	loss 3.1225 (3.4672)	grad_norm 151.3717 (168.4548)	mem 14369MB
[2022-12-20 16:21:47 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 153 training takes 0:01:05
[2022-12-20 16:21:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5197 (1.5197)	loss 3.6080 (3.6080)	grad_norm 186.8887 (186.8887)	mem 14369MB
[2022-12-20 16:21:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8679 (0.9311)	loss 3.9442 (3.5359)	grad_norm 329.4532 (179.9705)	mem 14369MB
[2022-12-20 16:22:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8665 (0.9023)	loss 3.8693 (3.3243)	grad_norm 55.7619 (180.8176)	mem 14369MB
[2022-12-20 16:22:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8673 (0.8925)	loss 3.2616 (3.3882)	grad_norm 217.3755 (182.3260)	mem 14369MB
[2022-12-20 16:22:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8798 (0.8881)	loss 3.0256 (3.3573)	grad_norm 214.6940 (180.5104)	mem 14369MB
[2022-12-20 16:22:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8771 (0.8853)	loss 5.5137 (3.4400)	grad_norm 91.8960 (182.6045)	mem 14369MB
[2022-12-20 16:22:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8855 (0.8843)	loss 2.6714 (3.4605)	grad_norm 167.1029 (189.7851)	mem 14369MB
[2022-12-20 16:22:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [154/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8915 (0.8836)	loss 4.3107 (3.4715)	grad_norm 305.5848 (187.8250)	mem 14369MB
[2022-12-20 16:22:53 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 154 training takes 0:01:05
[2022-12-20 16:22:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][0/74]	eta 0:01:53 lr 0.000004	time 1.5294 (1.5294)	loss 3.5830 (3.5830)	grad_norm 129.1012 (129.1012)	mem 14369MB
[2022-12-20 16:23:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8729 (0.9345)	loss 3.3517 (3.2415)	grad_norm 234.3009 (170.7473)	mem 14369MB
[2022-12-20 16:23:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8737 (0.9057)	loss 3.1293 (3.2404)	grad_norm 180.2029 (173.5127)	mem 14369MB
[2022-12-20 16:23:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8729 (0.8956)	loss 2.6862 (3.2983)	grad_norm 68.5138 (164.5156)	mem 14369MB
[2022-12-20 16:23:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8674 (0.8896)	loss 3.3875 (3.2719)	grad_norm 171.9701 (172.1959)	mem 14369MB
[2022-12-20 16:23:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8754 (0.8868)	loss 3.4903 (3.2829)	grad_norm 135.2003 (173.4456)	mem 14369MB
[2022-12-20 16:23:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8857 (0.8860)	loss 2.7460 (3.3465)	grad_norm 140.3145 (172.3190)	mem 14369MB
[2022-12-20 16:23:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [155/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8710 (0.8847)	loss 3.6686 (3.4067)	grad_norm 94.0469 (171.7252)	mem 14369MB
[2022-12-20 16:23:58 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 155 training takes 0:01:05
[2022-12-20 16:24:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][0/74]	eta 0:01:53 lr 0.000004	time 1.5349 (1.5349)	loss 3.4157 (3.4157)	grad_norm 167.4209 (167.4209)	mem 14369MB
[2022-12-20 16:24:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8744 (0.9372)	loss 3.1971 (3.4688)	grad_norm 167.1781 (149.2478)	mem 14369MB
[2022-12-20 16:24:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][20/74]	eta 0:00:49 lr 0.000004	time 0.8700 (0.9077)	loss 2.5989 (3.3309)	grad_norm 165.0666 (155.5329)	mem 14369MB
[2022-12-20 16:24:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8668 (0.8956)	loss 2.3971 (3.2522)	grad_norm 106.7024 (163.8747)	mem 14369MB
[2022-12-20 16:24:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8772 (0.8905)	loss 3.5427 (3.4019)	grad_norm 200.6533 (168.9453)	mem 14369MB
[2022-12-20 16:24:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8754 (0.8878)	loss 2.5898 (3.3767)	grad_norm 265.4871 (164.9845)	mem 14369MB
[2022-12-20 16:24:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8775 (0.8861)	loss 3.2340 (3.4359)	grad_norm 135.4946 (163.5356)	mem 14369MB
[2022-12-20 16:25:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [156/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8744 (0.8840)	loss 2.4935 (3.4003)	grad_norm 118.8389 (160.8607)	mem 14369MB
[2022-12-20 16:25:03 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 156 training takes 0:01:05
[2022-12-20 16:25:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][0/74]	eta 0:01:52 lr 0.000004	time 1.5194 (1.5194)	loss 3.0301 (3.0301)	grad_norm 131.8317 (131.8317)	mem 14369MB
[2022-12-20 16:25:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8739 (0.9365)	loss 2.6670 (3.1687)	grad_norm 192.8614 (177.4858)	mem 14369MB
[2022-12-20 16:25:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][20/74]	eta 0:00:49 lr 0.000004	time 0.8862 (0.9086)	loss 2.7234 (3.1842)	grad_norm 121.4351 (178.8604)	mem 14369MB
[2022-12-20 16:25:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8761 (0.8970)	loss 3.2544 (3.3640)	grad_norm 219.9260 (178.2173)	mem 14369MB
[2022-12-20 16:25:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8717 (0.8917)	loss 3.4888 (3.3392)	grad_norm 135.6105 (171.4035)	mem 14369MB
[2022-12-20 16:25:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8762 (0.8877)	loss 3.2713 (3.3177)	grad_norm 96.8262 (171.9549)	mem 14369MB
[2022-12-20 16:25:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8824 (0.8854)	loss 2.7833 (3.4220)	grad_norm 186.5526 (176.1644)	mem 14369MB
[2022-12-20 16:26:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [157/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8740 (0.8842)	loss 2.9556 (3.4626)	grad_norm 158.8356 (187.2051)	mem 14369MB
[2022-12-20 16:26:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 157 training takes 0:01:05
[2022-12-20 16:26:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][0/74]	eta 0:01:51 lr 0.000004	time 1.5096 (1.5096)	loss 2.8316 (2.8316)	grad_norm 235.3828 (235.3828)	mem 14369MB
[2022-12-20 16:26:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8718 (0.9295)	loss 4.7712 (3.5569)	grad_norm 211.2633 (178.5958)	mem 14369MB
[2022-12-20 16:26:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][20/74]	eta 0:00:48 lr 0.000004	time 0.8754 (0.9038)	loss 3.4802 (3.4835)	grad_norm 124.4502 (159.0870)	mem 14369MB
[2022-12-20 16:26:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8826 (0.8939)	loss 2.7652 (3.4049)	grad_norm 183.1475 (152.3753)	mem 14369MB
[2022-12-20 16:26:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8755 (0.8894)	loss 4.1552 (3.4265)	grad_norm 106.6746 (152.4331)	mem 14369MB
[2022-12-20 16:26:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8798 (0.8879)	loss 3.9749 (3.4546)	grad_norm 143.5599 (151.0740)	mem 14369MB
[2022-12-20 16:27:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8677 (0.8864)	loss 3.1218 (3.4341)	grad_norm 113.8401 (156.0764)	mem 14369MB
[2022-12-20 16:27:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [158/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8798 (0.8851)	loss 2.7534 (3.3586)	grad_norm 169.0018 (155.6188)	mem 14369MB
[2022-12-20 16:27:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 158 training takes 0:01:05
[2022-12-20 16:27:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][0/74]	eta 0:01:53 lr 0.000004	time 1.5291 (1.5291)	loss 2.4454 (2.4454)	grad_norm 138.4161 (138.4161)	mem 14369MB
[2022-12-20 16:27:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][10/74]	eta 0:00:59 lr 0.000004	time 0.8795 (0.9351)	loss 3.2470 (3.0867)	grad_norm 135.3447 (150.9404)	mem 14369MB
[2022-12-20 16:27:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][20/74]	eta 0:00:49 lr 0.000004	time 0.8898 (0.9075)	loss 3.0164 (3.0486)	grad_norm 91.6726 (157.7692)	mem 14369MB
[2022-12-20 16:27:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][30/74]	eta 0:00:39 lr 0.000004	time 0.8699 (0.9042)	loss 2.2429 (3.0410)	grad_norm 177.4821 (150.1762)	mem 14369MB
[2022-12-20 16:27:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][40/74]	eta 0:00:30 lr 0.000004	time 0.8704 (0.8962)	loss 3.0084 (3.2911)	grad_norm 77.1021 (156.7633)	mem 14369MB
[2022-12-20 16:28:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][50/74]	eta 0:00:21 lr 0.000004	time 0.8838 (0.8920)	loss 2.7074 (3.3232)	grad_norm 136.8889 (164.3148)	mem 14369MB
[2022-12-20 16:28:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][60/74]	eta 0:00:12 lr 0.000004	time 0.8729 (0.8887)	loss 2.6341 (3.3410)	grad_norm 127.7341 (168.5175)	mem 14369MB
[2022-12-20 16:28:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [159/300][70/74]	eta 0:00:03 lr 0.000004	time 0.8784 (0.8865)	loss 4.7024 (3.3729)	grad_norm 124.0687 (165.0005)	mem 14369MB
[2022-12-20 16:28:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 159 training takes 0:01:05
[2022-12-20 16:28:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][0/74]	eta 0:01:53 lr 0.000003	time 1.5349 (1.5349)	loss 3.0567 (3.0567)	grad_norm 142.5602 (142.5602)	mem 14369MB
[2022-12-20 16:28:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8726 (0.9353)	loss 2.9451 (3.2304)	grad_norm 388.1748 (166.9568)	mem 14369MB
[2022-12-20 16:28:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8653 (0.9039)	loss 2.7369 (3.4178)	grad_norm 121.1724 (160.3864)	mem 14369MB
[2022-12-20 16:28:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8691 (0.8958)	loss 2.7037 (3.4336)	grad_norm 132.6510 (167.5404)	mem 14369MB
[2022-12-20 16:28:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8746 (0.8916)	loss 3.0036 (3.3601)	grad_norm 210.9889 (163.7031)	mem 14369MB
[2022-12-20 16:29:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8699 (0.8887)	loss 3.2308 (3.3780)	grad_norm 150.3428 (162.2386)	mem 14369MB
[2022-12-20 16:29:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8777 (0.8882)	loss 3.2926 (3.3422)	grad_norm 162.3516 (161.1393)	mem 14369MB
[2022-12-20 16:29:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [160/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8680 (0.8874)	loss 3.6941 (3.3316)	grad_norm 152.7964 (161.5535)	mem 14369MB
[2022-12-20 16:29:25 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 160 training takes 0:01:05
[2022-12-20 16:29:25 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_160.pth saving......
[2022-12-20 16:29:26 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_160.pth saved !!!
[2022-12-20 16:29:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][0/74]	eta 0:01:51 lr 0.000003	time 1.5098 (1.5098)	loss 3.0621 (3.0621)	grad_norm 286.4919 (286.4919)	mem 14369MB
[2022-12-20 16:29:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8805 (0.9317)	loss 2.9877 (3.1461)	grad_norm 113.8488 (158.8011)	mem 14369MB
[2022-12-20 16:29:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8707 (0.9022)	loss 2.5333 (3.4494)	grad_norm 92.8050 (157.2693)	mem 14369MB
[2022-12-20 16:29:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8832 (0.8932)	loss 2.9679 (3.3840)	grad_norm 131.1651 (166.2057)	mem 14369MB
[2022-12-20 16:30:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8649 (0.8884)	loss 2.9447 (3.3590)	grad_norm 216.6880 (164.5945)	mem 14369MB
[2022-12-20 16:30:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8726 (0.8861)	loss 2.9822 (3.3169)	grad_norm 253.3240 (168.5800)	mem 14369MB
[2022-12-20 16:30:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8845 (0.8841)	loss 4.0243 (3.3982)	grad_norm 187.2910 (169.3563)	mem 14369MB
[2022-12-20 16:30:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [161/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8753 (0.8828)	loss 2.5967 (3.3397)	grad_norm 126.4393 (165.5996)	mem 14369MB
[2022-12-20 16:30:32 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 161 training takes 0:01:05
[2022-12-20 16:30:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][0/74]	eta 0:01:51 lr 0.000003	time 1.5055 (1.5055)	loss 3.1093 (3.1093)	grad_norm 77.8788 (77.8788)	mem 14369MB
[2022-12-20 16:30:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8754 (0.9315)	loss 3.2424 (3.2883)	grad_norm 145.3892 (115.1851)	mem 14369MB
[2022-12-20 16:30:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8717 (0.9013)	loss 3.0277 (3.3801)	grad_norm 223.2042 (153.0933)	mem 14369MB
[2022-12-20 16:30:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8633 (0.8910)	loss 2.3614 (3.3004)	grad_norm 211.7459 (160.5913)	mem 14369MB
[2022-12-20 16:31:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8827 (0.8864)	loss 2.8102 (3.3424)	grad_norm 114.4617 (159.9559)	mem 14369MB
[2022-12-20 16:31:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8876 (0.8847)	loss 5.4992 (3.4020)	grad_norm 416.5578 (163.9638)	mem 14369MB
[2022-12-20 16:31:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8719 (0.8831)	loss 3.0009 (3.3654)	grad_norm 108.6006 (165.6657)	mem 14369MB
[2022-12-20 16:31:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [162/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8980 (0.8828)	loss 3.7970 (3.4225)	grad_norm 117.6281 (168.3265)	mem 14369MB
[2022-12-20 16:31:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 162 training takes 0:01:05
[2022-12-20 16:31:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5180 (1.5180)	loss 3.7553 (3.7553)	grad_norm 172.0940 (172.0940)	mem 14369MB
[2022-12-20 16:31:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8666 (0.9314)	loss 3.1785 (3.3932)	grad_norm 174.3247 (141.4229)	mem 14369MB
[2022-12-20 16:31:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8786 (0.9026)	loss 2.7471 (3.3729)	grad_norm 144.0150 (145.3036)	mem 14369MB
[2022-12-20 16:32:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8667 (0.8914)	loss 2.9088 (3.2223)	grad_norm 253.5884 (157.5913)	mem 14369MB
[2022-12-20 16:32:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8944 (0.8883)	loss 3.3283 (3.2692)	grad_norm 193.4263 (161.4540)	mem 14369MB
[2022-12-20 16:32:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8715 (0.8858)	loss 4.1571 (3.4279)	grad_norm 127.6387 (162.6989)	mem 14369MB
[2022-12-20 16:32:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8765 (0.8835)	loss 3.0099 (3.3960)	grad_norm 152.6684 (169.1794)	mem 14369MB
[2022-12-20 16:32:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [163/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8695 (0.8822)	loss 3.0927 (3.4196)	grad_norm 141.0378 (166.3518)	mem 14369MB
[2022-12-20 16:32:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 163 training takes 0:01:05
[2022-12-20 16:32:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][0/74]	eta 0:01:51 lr 0.000003	time 1.5040 (1.5040)	loss 2.7468 (2.7468)	grad_norm 95.0908 (95.0908)	mem 14369MB
[2022-12-20 16:32:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8786 (0.9309)	loss 3.5453 (3.7284)	grad_norm 125.4458 (151.4254)	mem 14369MB
[2022-12-20 16:33:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][20/74]	eta 0:00:49 lr 0.000003	time 0.8956 (0.9084)	loss 3.2290 (3.4044)	grad_norm 79.3012 (143.9106)	mem 14369MB
[2022-12-20 16:33:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8693 (0.8968)	loss 2.6240 (3.3520)	grad_norm 222.4666 (150.5518)	mem 14369MB
[2022-12-20 16:33:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8853 (0.8914)	loss 2.6912 (3.3833)	grad_norm 166.4542 (153.0757)	mem 14369MB
[2022-12-20 16:33:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8766 (0.8875)	loss 3.5503 (3.3878)	grad_norm 151.1881 (160.4038)	mem 14369MB
[2022-12-20 16:33:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8625 (0.8854)	loss 2.4257 (3.3317)	grad_norm 187.7748 (159.5210)	mem 14369MB
[2022-12-20 16:33:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [164/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8789 (0.8839)	loss 2.7553 (3.3605)	grad_norm 89.9577 (163.1329)	mem 14369MB
[2022-12-20 16:33:47 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 164 training takes 0:01:05
[2022-12-20 16:33:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5221 (1.5221)	loss 2.7432 (2.7432)	grad_norm 104.2186 (104.2186)	mem 14369MB
[2022-12-20 16:33:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8703 (0.9295)	loss 3.2538 (2.9538)	grad_norm 137.0501 (163.9046)	mem 14369MB
[2022-12-20 16:34:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8768 (0.9058)	loss 2.7515 (3.1871)	grad_norm 218.5744 (165.4469)	mem 14369MB
[2022-12-20 16:34:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8861 (0.8956)	loss 3.4695 (3.2782)	grad_norm 78.8988 (167.9491)	mem 14369MB
[2022-12-20 16:34:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8754 (0.8899)	loss 2.6386 (3.2957)	grad_norm 123.2589 (171.3149)	mem 14369MB
[2022-12-20 16:34:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8811 (0.8867)	loss 3.3492 (3.3291)	grad_norm 157.9159 (168.8208)	mem 14369MB
[2022-12-20 16:34:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8697 (0.8851)	loss 3.0361 (3.3445)	grad_norm 123.8921 (169.4071)	mem 14369MB
[2022-12-20 16:34:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [165/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8743 (0.8834)	loss 3.8387 (3.3366)	grad_norm 187.7626 (169.8299)	mem 14369MB
[2022-12-20 16:34:53 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 165 training takes 0:01:05
[2022-12-20 16:34:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][0/74]	eta 0:01:50 lr 0.000003	time 1.4998 (1.4998)	loss 4.4490 (4.4490)	grad_norm 154.1296 (154.1296)	mem 14369MB
[2022-12-20 16:35:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8840 (0.9263)	loss 4.4003 (3.2590)	grad_norm 240.7699 (176.9487)	mem 14369MB
[2022-12-20 16:35:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8696 (0.8990)	loss 2.6869 (3.3529)	grad_norm 174.9722 (177.8054)	mem 14369MB
[2022-12-20 16:35:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8736 (0.8891)	loss 3.3558 (3.5802)	grad_norm 146.7755 (170.9836)	mem 14369MB
[2022-12-20 16:35:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8729 (0.8864)	loss 2.6250 (3.4164)	grad_norm 303.6696 (171.9294)	mem 14369MB
[2022-12-20 16:35:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8749 (0.8862)	loss 3.8991 (3.3811)	grad_norm 249.9699 (168.1397)	mem 14369MB
[2022-12-20 16:35:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8918 (0.8856)	loss 3.2594 (3.4361)	grad_norm 197.7774 (162.1839)	mem 14369MB
[2022-12-20 16:35:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [166/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8815 (0.8856)	loss 3.0379 (3.4290)	grad_norm 124.4721 (157.6814)	mem 14369MB
[2022-12-20 16:35:58 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 166 training takes 0:01:05
[2022-12-20 16:36:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5236 (1.5236)	loss 2.8067 (2.8067)	grad_norm 104.6673 (104.6673)	mem 14369MB
[2022-12-20 16:36:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][10/74]	eta 0:01:00 lr 0.000003	time 0.9986 (0.9442)	loss 2.9915 (3.1647)	grad_norm 159.7669 (170.3696)	mem 14369MB
[2022-12-20 16:36:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][20/74]	eta 0:00:50 lr 0.000003	time 0.8847 (0.9375)	loss 2.5846 (3.2387)	grad_norm 132.9709 (163.1137)	mem 14369MB
[2022-12-20 16:36:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][30/74]	eta 0:00:40 lr 0.000003	time 0.8951 (0.9192)	loss 2.8993 (3.2664)	grad_norm 103.2529 (160.5284)	mem 14369MB
[2022-12-20 16:36:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8722 (0.9093)	loss 2.9809 (3.2706)	grad_norm 152.6705 (153.5042)	mem 14369MB
[2022-12-20 16:36:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8745 (0.9021)	loss 2.2995 (3.3836)	grad_norm 66.4040 (159.4336)	mem 14369MB
[2022-12-20 16:36:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8760 (0.8976)	loss 3.1901 (3.3840)	grad_norm 163.5217 (158.8727)	mem 14369MB
[2022-12-20 16:37:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [167/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8828 (0.8946)	loss 2.3969 (3.3253)	grad_norm 85.6470 (157.0939)	mem 14369MB
[2022-12-20 16:37:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 167 training takes 0:01:06
[2022-12-20 16:37:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5147 (1.5147)	loss 3.5972 (3.5972)	grad_norm 130.0941 (130.0941)	mem 14369MB
[2022-12-20 16:37:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8695 (0.9296)	loss 3.0198 (3.3165)	grad_norm 129.8966 (154.8944)	mem 14369MB
[2022-12-20 16:37:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8773 (0.9015)	loss 2.6257 (3.1574)	grad_norm 120.9247 (167.9499)	mem 14369MB
[2022-12-20 16:37:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8624 (0.8924)	loss 2.7583 (3.3948)	grad_norm 347.2823 (165.6869)	mem 14369MB
[2022-12-20 16:37:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8648 (0.8882)	loss 3.3397 (3.4644)	grad_norm 125.0668 (162.6589)	mem 14369MB
[2022-12-20 16:37:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8893 (0.8853)	loss 2.6524 (3.3902)	grad_norm 86.3237 (160.5096)	mem 14369MB
[2022-12-20 16:37:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8731 (0.8833)	loss 3.2954 (3.3398)	grad_norm 78.1317 (158.6700)	mem 14369MB
[2022-12-20 16:38:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [168/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8699 (0.8813)	loss 3.2821 (3.3358)	grad_norm 142.3763 (160.8158)	mem 14369MB
[2022-12-20 16:38:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 168 training takes 0:01:05
[2022-12-20 16:38:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5254 (1.5254)	loss 3.3707 (3.3707)	grad_norm 62.4671 (62.4671)	mem 14369MB
[2022-12-20 16:38:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8631 (0.9294)	loss 2.8735 (3.2991)	grad_norm 242.5367 (138.5657)	mem 14369MB
[2022-12-20 16:38:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8716 (0.9012)	loss 6.2931 (3.4854)	grad_norm 119.1215 (141.2802)	mem 14369MB
[2022-12-20 16:38:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8667 (0.8918)	loss 2.9447 (3.4383)	grad_norm 177.9155 (145.0862)	mem 14369MB
[2022-12-20 16:38:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8659 (0.8866)	loss 3.2685 (3.4007)	grad_norm 161.6205 (149.8481)	mem 14369MB
[2022-12-20 16:38:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8725 (0.8851)	loss 2.7569 (3.3709)	grad_norm 271.7586 (155.4848)	mem 14369MB
[2022-12-20 16:39:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8684 (0.8834)	loss 3.6983 (3.3248)	grad_norm 248.7441 (160.7250)	mem 14369MB
[2022-12-20 16:39:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [169/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8811 (0.8816)	loss 3.2093 (3.3407)	grad_norm 91.0638 (161.9672)	mem 14369MB
[2022-12-20 16:39:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 169 training takes 0:01:05
[2022-12-20 16:39:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][0/74]	eta 0:01:53 lr 0.000003	time 1.5272 (1.5272)	loss 2.4897 (2.4897)	grad_norm 75.0432 (75.0432)	mem 14369MB
[2022-12-20 16:39:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8686 (0.9282)	loss 2.5656 (3.0789)	grad_norm 189.1359 (150.4651)	mem 14369MB
[2022-12-20 16:39:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8815 (0.9014)	loss 3.0652 (3.3538)	grad_norm 139.7666 (183.4659)	mem 14369MB
[2022-12-20 16:39:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8764 (0.8910)	loss 3.9314 (3.3113)	grad_norm 150.5207 (175.5568)	mem 14369MB
[2022-12-20 16:39:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8861 (0.8866)	loss 3.4731 (3.2993)	grad_norm 161.4717 (172.9681)	mem 14369MB
[2022-12-20 16:40:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8669 (0.8835)	loss 2.7793 (3.4226)	grad_norm 95.0241 (165.4643)	mem 14369MB
[2022-12-20 16:40:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8664 (0.8821)	loss 2.2799 (3.4006)	grad_norm 98.6548 (161.6559)	mem 14369MB
[2022-12-20 16:40:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [170/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8821 (0.8812)	loss 3.0722 (3.3532)	grad_norm 118.7217 (157.7392)	mem 14369MB
[2022-12-20 16:40:20 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 170 training takes 0:01:05
[2022-12-20 16:40:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][0/74]	eta 0:01:54 lr 0.000003	time 1.5425 (1.5425)	loss 2.4602 (2.4602)	grad_norm 105.3590 (105.3590)	mem 14369MB
[2022-12-20 16:40:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][10/74]	eta 0:01:00 lr 0.000003	time 0.8830 (0.9395)	loss 3.0768 (3.3726)	grad_norm 103.5227 (129.2873)	mem 14369MB
[2022-12-20 16:40:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][20/74]	eta 0:00:49 lr 0.000003	time 0.8779 (0.9110)	loss 2.8704 (3.2418)	grad_norm 252.9671 (145.4625)	mem 14369MB
[2022-12-20 16:40:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8622 (0.9051)	loss 4.3920 (3.3017)	grad_norm 167.0268 (145.6732)	mem 14369MB
[2022-12-20 16:40:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8673 (0.8968)	loss 3.0982 (3.2669)	grad_norm 163.6112 (148.7933)	mem 14369MB
[2022-12-20 16:41:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8651 (0.8918)	loss 3.2114 (3.2584)	grad_norm 132.3447 (151.2500)	mem 14369MB
[2022-12-20 16:41:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8679 (0.8885)	loss 2.8304 (3.3195)	grad_norm 115.9600 (153.0524)	mem 14369MB
[2022-12-20 16:41:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [171/300][70/74]	eta 0:00:03 lr 0.000003	time 0.9033 (0.8867)	loss 3.4323 (3.3410)	grad_norm 130.2623 (152.9476)	mem 14369MB
[2022-12-20 16:41:25 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 171 training takes 0:01:05
[2022-12-20 16:41:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][0/74]	eta 0:01:51 lr 0.000003	time 1.5134 (1.5134)	loss 3.0751 (3.0751)	grad_norm 150.5001 (150.5001)	mem 14369MB
[2022-12-20 16:41:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8728 (0.9324)	loss 2.8107 (3.4359)	grad_norm 151.5785 (122.6124)	mem 14369MB
[2022-12-20 16:41:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8644 (0.9042)	loss 5.6254 (3.2906)	grad_norm 236.2012 (137.4715)	mem 14369MB
[2022-12-20 16:41:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8690 (0.8953)	loss 3.6135 (3.3252)	grad_norm 101.3827 (133.2500)	mem 14369MB
[2022-12-20 16:42:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8856 (0.8906)	loss 3.5142 (3.3556)	grad_norm 87.8520 (140.0052)	mem 14369MB
[2022-12-20 16:42:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8704 (0.8886)	loss 3.7206 (3.3064)	grad_norm 249.2586 (137.5199)	mem 14369MB
[2022-12-20 16:42:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8743 (0.8865)	loss 2.8847 (3.3233)	grad_norm 160.0856 (137.6308)	mem 14369MB
[2022-12-20 16:42:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [172/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8800 (0.8859)	loss 3.0967 (3.3151)	grad_norm 56.8967 (140.3569)	mem 14369MB
[2022-12-20 16:42:31 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 172 training takes 0:01:05
[2022-12-20 16:42:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][0/74]	eta 0:01:53 lr 0.000003	time 1.5351 (1.5351)	loss 3.2535 (3.2535)	grad_norm 141.9588 (141.9588)	mem 14369MB
[2022-12-20 16:42:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][10/74]	eta 0:01:00 lr 0.000003	time 0.8742 (0.9404)	loss 3.3527 (3.1455)	grad_norm 127.3293 (152.8792)	mem 14369MB
[2022-12-20 16:42:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][20/74]	eta 0:00:49 lr 0.000003	time 0.8770 (0.9120)	loss 4.7705 (3.4029)	grad_norm 86.6403 (147.0015)	mem 14369MB
[2022-12-20 16:42:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8719 (0.8995)	loss 2.3677 (3.6051)	grad_norm 158.6894 (154.6367)	mem 14369MB
[2022-12-20 16:43:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8734 (0.8927)	loss 5.4434 (3.4647)	grad_norm 162.4079 (152.9267)	mem 14369MB
[2022-12-20 16:43:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8695 (0.8893)	loss 2.2953 (3.3439)	grad_norm 193.2691 (154.3960)	mem 14369MB
[2022-12-20 16:43:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8725 (0.8871)	loss 3.8716 (3.3366)	grad_norm 211.2448 (151.0283)	mem 14369MB
[2022-12-20 16:43:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [173/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8804 (0.8862)	loss 4.0169 (3.3548)	grad_norm 65.3359 (151.5839)	mem 14369MB
[2022-12-20 16:43:36 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 173 training takes 0:01:05
[2022-12-20 16:43:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5143 (1.5143)	loss 2.8030 (2.8030)	grad_norm 149.1598 (149.1598)	mem 14369MB
[2022-12-20 16:43:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8765 (0.9313)	loss 2.8268 (2.8935)	grad_norm 154.4833 (174.0987)	mem 14369MB
[2022-12-20 16:43:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8843 (0.9035)	loss 2.4881 (3.0473)	grad_norm 78.1152 (172.1891)	mem 14369MB
[2022-12-20 16:44:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8705 (0.8933)	loss 3.4813 (3.2266)	grad_norm 201.7084 (179.0085)	mem 14369MB
[2022-12-20 16:44:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8985 (0.8904)	loss 3.2099 (3.3275)	grad_norm 162.1763 (178.4702)	mem 14369MB
[2022-12-20 16:44:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8901 (0.8890)	loss 2.9900 (3.2570)	grad_norm 130.6859 (169.5295)	mem 14369MB
[2022-12-20 16:44:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8768 (0.8878)	loss 2.8399 (3.3377)	grad_norm 148.3878 (162.4569)	mem 14369MB
[2022-12-20 16:44:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [174/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8726 (0.8869)	loss 3.4547 (3.3590)	grad_norm 98.1841 (162.4570)	mem 14369MB
[2022-12-20 16:44:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 174 training takes 0:01:05
[2022-12-20 16:44:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5140 (1.5140)	loss 2.7437 (2.7437)	grad_norm 89.7774 (89.7774)	mem 14369MB
[2022-12-20 16:44:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8700 (0.9282)	loss 3.1973 (3.2800)	grad_norm 128.6761 (164.9859)	mem 14369MB
[2022-12-20 16:45:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8677 (0.9026)	loss 2.7332 (3.5659)	grad_norm 132.9584 (164.2095)	mem 14369MB
[2022-12-20 16:45:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8593 (0.8931)	loss 3.5406 (3.3455)	grad_norm 373.4065 (168.3663)	mem 14369MB
[2022-12-20 16:45:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8696 (0.8890)	loss 2.5785 (3.3133)	grad_norm 60.3202 (160.7522)	mem 14369MB
[2022-12-20 16:45:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8647 (0.8855)	loss 3.3400 (3.2960)	grad_norm 284.4946 (163.4030)	mem 14369MB
[2022-12-20 16:45:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8742 (0.8835)	loss 8.3591 (3.3632)	grad_norm 153.1256 (163.7402)	mem 14369MB
[2022-12-20 16:45:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [175/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8849 (0.8853)	loss 3.2383 (3.3060)	grad_norm 162.1556 (161.5702)	mem 14369MB
[2022-12-20 16:45:47 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 175 training takes 0:01:05
[2022-12-20 16:45:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5218 (1.5218)	loss 2.4985 (2.4985)	grad_norm 99.3843 (99.3843)	mem 14369MB
[2022-12-20 16:45:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8751 (0.9284)	loss 3.2575 (3.5140)	grad_norm 140.9516 (194.9530)	mem 14369MB
[2022-12-20 16:46:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8841 (0.9019)	loss 3.6590 (3.4817)	grad_norm 138.8224 (183.4567)	mem 14369MB
[2022-12-20 16:46:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8659 (0.8921)	loss 6.5421 (3.4689)	grad_norm 106.2498 (166.6763)	mem 14369MB
[2022-12-20 16:46:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8706 (0.8875)	loss 3.0059 (3.4126)	grad_norm 112.3237 (153.9326)	mem 14369MB
[2022-12-20 16:46:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8783 (0.8843)	loss 3.3952 (3.4261)	grad_norm 186.8901 (158.2483)	mem 14369MB
[2022-12-20 16:46:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8649 (0.8820)	loss 2.9817 (3.3880)	grad_norm 144.3332 (156.9612)	mem 14369MB
[2022-12-20 16:46:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [176/300][70/74]	eta 0:00:03 lr 0.000003	time 0.9030 (0.8813)	loss 3.4677 (3.3441)	grad_norm 189.2308 (155.3233)	mem 14369MB
[2022-12-20 16:46:52 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 176 training takes 0:01:05
[2022-12-20 16:46:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5266 (1.5266)	loss 2.9556 (2.9556)	grad_norm 92.7482 (92.7482)	mem 14369MB
[2022-12-20 16:47:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8683 (0.9328)	loss 2.4571 (3.1305)	grad_norm 168.2858 (136.2047)	mem 14369MB
[2022-12-20 16:47:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8840 (0.9041)	loss 2.9507 (3.2797)	grad_norm 156.4206 (147.2310)	mem 14369MB
[2022-12-20 16:47:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8639 (0.8939)	loss 3.3724 (3.5561)	grad_norm 212.1446 (166.7173)	mem 14369MB
[2022-12-20 16:47:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8700 (0.8889)	loss 3.0307 (3.4563)	grad_norm 148.8869 (167.7320)	mem 14369MB
[2022-12-20 16:47:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8666 (0.8853)	loss 3.3959 (3.4227)	grad_norm 252.4413 (168.7768)	mem 14369MB
[2022-12-20 16:47:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8837 (0.8835)	loss 4.2961 (3.4809)	grad_norm 91.3477 (167.2069)	mem 14369MB
[2022-12-20 16:47:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [177/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8660 (0.8824)	loss 3.7257 (3.4726)	grad_norm 172.1324 (163.7797)	mem 14369MB
[2022-12-20 16:47:57 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 177 training takes 0:01:05
[2022-12-20 16:47:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5155 (1.5155)	loss 4.3085 (4.3085)	grad_norm 223.2635 (223.2635)	mem 14369MB
[2022-12-20 16:48:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8653 (0.9286)	loss 3.1096 (3.1864)	grad_norm 122.5649 (182.0804)	mem 14369MB
[2022-12-20 16:48:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8792 (0.9018)	loss 3.1217 (3.3264)	grad_norm 197.8376 (174.1749)	mem 14369MB
[2022-12-20 16:48:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8703 (0.8931)	loss 2.9052 (3.2249)	grad_norm 204.6821 (157.2671)	mem 14369MB
[2022-12-20 16:48:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8741 (0.8875)	loss 2.6591 (3.1828)	grad_norm 182.6351 (158.1681)	mem 14369MB
[2022-12-20 16:48:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8666 (0.8847)	loss 3.3871 (3.2883)	grad_norm 224.8443 (165.5489)	mem 14369MB
[2022-12-20 16:48:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8703 (0.8825)	loss 3.5940 (3.3319)	grad_norm 180.9584 (162.9268)	mem 14369MB
[2022-12-20 16:49:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [178/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8780 (0.8815)	loss 3.7450 (3.3538)	grad_norm 150.9250 (160.9609)	mem 14369MB
[2022-12-20 16:49:02 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 178 training takes 0:01:05
[2022-12-20 16:49:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5163 (1.5163)	loss 2.8408 (2.8408)	grad_norm 140.5582 (140.5582)	mem 14369MB
[2022-12-20 16:49:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8874 (0.9292)	loss 3.5547 (3.1640)	grad_norm 86.9983 (156.8785)	mem 14369MB
[2022-12-20 16:49:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8626 (0.9028)	loss 2.2613 (3.1637)	grad_norm 89.3856 (150.8526)	mem 14369MB
[2022-12-20 16:49:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8735 (0.8940)	loss 3.6181 (3.2844)	grad_norm 132.4759 (148.2561)	mem 14369MB
[2022-12-20 16:49:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8698 (0.8895)	loss 2.5224 (3.2689)	grad_norm 252.1485 (148.1353)	mem 14369MB
[2022-12-20 16:49:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8845 (0.8863)	loss 7.2285 (3.3143)	grad_norm 161.3066 (152.1847)	mem 14369MB
[2022-12-20 16:49:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8639 (0.8843)	loss 3.5250 (3.2954)	grad_norm 172.8511 (156.4197)	mem 14369MB
[2022-12-20 16:50:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [179/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8709 (0.8826)	loss 2.3864 (3.2739)	grad_norm 139.6970 (154.0373)	mem 14369MB
[2022-12-20 16:50:08 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 179 training takes 0:01:05
[2022-12-20 16:50:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5244 (1.5244)	loss 3.2127 (3.2127)	grad_norm 86.6194 (86.6194)	mem 14369MB
[2022-12-20 16:50:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8729 (0.9324)	loss 3.8592 (3.0504)	grad_norm 102.0340 (143.3107)	mem 14369MB
[2022-12-20 16:50:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8753 (0.9056)	loss 6.8825 (3.2321)	grad_norm 223.3062 (154.6153)	mem 14369MB
[2022-12-20 16:50:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8889 (0.8943)	loss 2.8815 (3.0996)	grad_norm 113.2450 (150.4927)	mem 14369MB
[2022-12-20 16:50:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8779 (0.8886)	loss 3.7150 (3.2146)	grad_norm 138.9828 (148.6315)	mem 14369MB
[2022-12-20 16:50:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8741 (0.8856)	loss 4.1575 (3.2554)	grad_norm 145.3410 (157.1102)	mem 14369MB
[2022-12-20 16:51:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8671 (0.8832)	loss 3.0781 (3.3121)	grad_norm 108.4000 (156.0360)	mem 14369MB
[2022-12-20 16:51:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [180/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8699 (0.8817)	loss 3.0056 (3.3257)	grad_norm 215.8522 (155.5644)	mem 14369MB
[2022-12-20 16:51:13 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 180 training takes 0:01:05
[2022-12-20 16:51:13 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_180.pth saving......
[2022-12-20 16:51:14 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_180.pth saved !!!
[2022-12-20 16:51:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][0/74]	eta 0:01:51 lr 0.000003	time 1.5105 (1.5105)	loss 3.1215 (3.1215)	grad_norm 134.6071 (134.6071)	mem 14369MB
[2022-12-20 16:51:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8743 (0.9321)	loss 3.2937 (3.4449)	grad_norm 111.7628 (134.0830)	mem 14369MB
[2022-12-20 16:51:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8751 (0.9025)	loss 2.8285 (3.2038)	grad_norm 67.9377 (135.2102)	mem 14369MB
[2022-12-20 16:51:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8743 (0.8905)	loss 2.5055 (3.2279)	grad_norm 155.6659 (134.3217)	mem 14369MB
[2022-12-20 16:51:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8700 (0.8865)	loss 3.1378 (3.1739)	grad_norm 51.6612 (134.0706)	mem 14369MB
[2022-12-20 16:51:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8657 (0.8843)	loss 2.9223 (3.2357)	grad_norm 166.8619 (135.6907)	mem 14369MB
[2022-12-20 16:52:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8764 (0.8824)	loss 3.5772 (3.2389)	grad_norm 115.1498 (140.7351)	mem 14369MB
[2022-12-20 16:52:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [181/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8693 (0.8809)	loss 2.9741 (3.2816)	grad_norm 175.7255 (147.3120)	mem 14369MB
[2022-12-20 16:52:19 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 181 training takes 0:01:05
[2022-12-20 16:52:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5265 (1.5265)	loss 2.6274 (2.6274)	grad_norm 67.8544 (67.8544)	mem 14369MB
[2022-12-20 16:52:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8620 (0.9289)	loss 3.6825 (3.1102)	grad_norm 250.2069 (129.4170)	mem 14369MB
[2022-12-20 16:52:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8682 (0.9012)	loss 3.7439 (3.3872)	grad_norm 158.0497 (156.4962)	mem 14369MB
[2022-12-20 16:52:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8726 (0.8914)	loss 2.9052 (3.3375)	grad_norm 107.2842 (154.2190)	mem 14369MB
[2022-12-20 16:52:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8707 (0.8861)	loss 2.9517 (3.3169)	grad_norm 96.5446 (156.3112)	mem 14369MB
[2022-12-20 16:53:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8700 (0.8830)	loss 2.7413 (3.2464)	grad_norm 100.0672 (145.0221)	mem 14369MB
[2022-12-20 16:53:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8886 (0.8816)	loss 4.0819 (3.3090)	grad_norm 180.5501 (146.1889)	mem 14369MB
[2022-12-20 16:53:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [182/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8645 (0.8805)	loss 3.0783 (3.3340)	grad_norm 210.2009 (148.8990)	mem 14369MB
[2022-12-20 16:53:24 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 182 training takes 0:01:05
[2022-12-20 16:53:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5140 (1.5140)	loss 2.8739 (2.8739)	grad_norm 92.6875 (92.6875)	mem 14369MB
[2022-12-20 16:53:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8644 (0.9301)	loss 3.2827 (2.9744)	grad_norm 177.5760 (145.7793)	mem 14369MB
[2022-12-20 16:53:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8748 (0.9034)	loss 3.7234 (3.1471)	grad_norm 122.7682 (168.0695)	mem 14369MB
[2022-12-20 16:53:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8751 (0.8928)	loss 2.4460 (3.1086)	grad_norm 81.5928 (153.2476)	mem 14369MB
[2022-12-20 16:54:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8657 (0.8872)	loss 3.3330 (3.2475)	grad_norm 225.5976 (162.1351)	mem 14369MB
[2022-12-20 16:54:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8853 (0.8864)	loss 3.2681 (3.2466)	grad_norm 184.5052 (156.9548)	mem 14369MB
[2022-12-20 16:54:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8777 (0.8856)	loss 3.4994 (3.2538)	grad_norm 93.7708 (150.2449)	mem 14369MB
[2022-12-20 16:54:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [183/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8824 (0.8850)	loss 2.1932 (3.3640)	grad_norm 155.8474 (154.5788)	mem 14369MB
[2022-12-20 16:54:30 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 183 training takes 0:01:05
[2022-12-20 16:54:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5195 (1.5195)	loss 2.7099 (2.7099)	grad_norm 133.2553 (133.2553)	mem 14369MB
[2022-12-20 16:54:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8824 (0.9294)	loss 3.2219 (2.9098)	grad_norm 98.3301 (148.4499)	mem 14369MB
[2022-12-20 16:54:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][20/74]	eta 0:00:48 lr 0.000003	time 0.8719 (0.9019)	loss 2.7672 (2.9850)	grad_norm 98.7588 (144.1363)	mem 14369MB
[2022-12-20 16:54:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][30/74]	eta 0:00:39 lr 0.000003	time 0.8716 (0.8931)	loss 3.6653 (3.0212)	grad_norm 176.4505 (137.5178)	mem 14369MB
[2022-12-20 16:55:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][40/74]	eta 0:00:30 lr 0.000003	time 0.8681 (0.8871)	loss 3.8292 (3.0922)	grad_norm 262.6387 (144.5269)	mem 14369MB
[2022-12-20 16:55:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][50/74]	eta 0:00:21 lr 0.000003	time 0.8756 (0.8836)	loss 3.1408 (3.2820)	grad_norm 114.4168 (140.6889)	mem 14369MB
[2022-12-20 16:55:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][60/74]	eta 0:00:12 lr 0.000003	time 0.8843 (0.8818)	loss 3.3149 (3.2932)	grad_norm 106.5333 (140.7780)	mem 14369MB
[2022-12-20 16:55:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [184/300][70/74]	eta 0:00:03 lr 0.000003	time 0.8643 (0.8804)	loss 2.8844 (3.2994)	grad_norm 98.2982 (143.6779)	mem 14369MB
[2022-12-20 16:55:35 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 184 training takes 0:01:05
[2022-12-20 16:55:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][0/74]	eta 0:01:52 lr 0.000003	time 1.5257 (1.5257)	loss 4.6424 (4.6424)	grad_norm 236.9613 (236.9613)	mem 14369MB
[2022-12-20 16:55:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][10/74]	eta 0:00:59 lr 0.000003	time 0.8658 (0.9335)	loss 3.9803 (3.3396)	grad_norm 110.6625 (135.0465)	mem 14369MB
[2022-12-20 16:55:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8629 (0.9043)	loss 3.8003 (3.1941)	grad_norm 170.9720 (139.7586)	mem 14369MB
[2022-12-20 16:56:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8624 (0.8925)	loss 3.0340 (3.1253)	grad_norm 177.3395 (147.4704)	mem 14369MB
[2022-12-20 16:56:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8681 (0.8872)	loss 2.2799 (3.3128)	grad_norm 88.6848 (144.5854)	mem 14369MB
[2022-12-20 16:56:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8664 (0.8843)	loss 3.9046 (3.3473)	grad_norm 493.4807 (150.8036)	mem 14369MB
[2022-12-20 16:56:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8801 (0.8819)	loss 3.4081 (3.3574)	grad_norm 206.1617 (157.6696)	mem 14369MB
[2022-12-20 16:56:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [185/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8741 (0.8816)	loss 2.7580 (3.3451)	grad_norm 67.8048 (153.3840)	mem 14369MB
[2022-12-20 16:56:40 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 185 training takes 0:01:05
[2022-12-20 16:56:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5368 (1.5368)	loss 2.8988 (2.8988)	grad_norm 115.4889 (115.4889)	mem 14369MB
[2022-12-20 16:56:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8684 (0.9319)	loss 2.9780 (3.8135)	grad_norm 145.3322 (160.7864)	mem 14369MB
[2022-12-20 16:56:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8722 (0.9032)	loss 3.7483 (3.5257)	grad_norm 144.3432 (145.4707)	mem 14369MB
[2022-12-20 16:57:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8767 (0.8965)	loss 3.0037 (3.3611)	grad_norm 170.1055 (141.0429)	mem 14369MB
[2022-12-20 16:57:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8754 (0.8929)	loss 2.6580 (3.3337)	grad_norm 206.2628 (140.8771)	mem 14369MB
[2022-12-20 16:57:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8742 (0.8906)	loss 4.4057 (3.3006)	grad_norm 65.5165 (134.2144)	mem 14369MB
[2022-12-20 16:57:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8674 (0.8874)	loss 6.2200 (3.2962)	grad_norm 112.9468 (133.2276)	mem 14369MB
[2022-12-20 16:57:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [186/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8786 (0.8853)	loss 2.7512 (3.2445)	grad_norm 89.2626 (132.5253)	mem 14369MB
[2022-12-20 16:57:45 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 186 training takes 0:01:05
[2022-12-20 16:57:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5296 (1.5296)	loss 2.4411 (2.4411)	grad_norm 149.5411 (149.5411)	mem 14369MB
[2022-12-20 16:57:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8864 (0.9312)	loss 2.8099 (3.7754)	grad_norm 121.3935 (161.2557)	mem 14369MB
[2022-12-20 16:58:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8680 (0.9029)	loss 3.7949 (3.5224)	grad_norm 150.5543 (145.8486)	mem 14369MB
[2022-12-20 16:58:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8656 (0.8926)	loss 2.2391 (3.3418)	grad_norm 167.6797 (140.7862)	mem 14369MB
[2022-12-20 16:58:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8698 (0.8890)	loss 2.5688 (3.4138)	grad_norm 140.7494 (139.5485)	mem 14369MB
[2022-12-20 16:58:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8896 (0.8864)	loss 2.6067 (3.3843)	grad_norm 83.2491 (137.9902)	mem 14369MB
[2022-12-20 16:58:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8664 (0.8848)	loss 3.3476 (3.2934)	grad_norm 209.6400 (137.1391)	mem 14369MB
[2022-12-20 16:58:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [187/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8716 (0.8831)	loss 2.5810 (3.2829)	grad_norm 106.6507 (137.1479)	mem 14369MB
[2022-12-20 16:58:51 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 187 training takes 0:01:05
[2022-12-20 16:58:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5315 (1.5315)	loss 3.2919 (3.2919)	grad_norm 318.9517 (318.9517)	mem 14369MB
[2022-12-20 16:59:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8619 (0.9316)	loss 2.5350 (2.7677)	grad_norm 197.7411 (181.7901)	mem 14369MB
[2022-12-20 16:59:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8638 (0.9022)	loss 2.9119 (2.9496)	grad_norm 116.0909 (162.4323)	mem 14369MB
[2022-12-20 16:59:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8614 (0.8933)	loss 3.3527 (3.0156)	grad_norm 224.7376 (155.6954)	mem 14369MB
[2022-12-20 16:59:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8664 (0.8883)	loss 3.0474 (3.0240)	grad_norm 91.2724 (151.8477)	mem 14369MB
[2022-12-20 16:59:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8809 (0.8850)	loss 2.4049 (3.1646)	grad_norm 133.5377 (148.0468)	mem 14369MB
[2022-12-20 16:59:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8740 (0.8832)	loss 2.8934 (3.2311)	grad_norm 96.8872 (149.4946)	mem 14369MB
[2022-12-20 16:59:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [188/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8795 (0.8817)	loss 3.9270 (3.2313)	grad_norm 127.7460 (146.3136)	mem 14369MB
[2022-12-20 16:59:56 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 188 training takes 0:01:05
[2022-12-20 16:59:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5275 (1.5275)	loss 2.2885 (2.2885)	grad_norm 77.6741 (77.6741)	mem 14369MB
[2022-12-20 17:00:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8867 (0.9360)	loss 2.9908 (3.4046)	grad_norm 150.3074 (155.5621)	mem 14369MB
[2022-12-20 17:00:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8717 (0.9067)	loss 2.9676 (3.3085)	grad_norm 214.5276 (152.2636)	mem 14369MB
[2022-12-20 17:00:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8683 (0.8954)	loss 2.6440 (3.2435)	grad_norm 209.5000 (153.2076)	mem 14369MB
[2022-12-20 17:00:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8766 (0.8899)	loss 2.8923 (3.2328)	grad_norm 126.8689 (155.4236)	mem 14369MB
[2022-12-20 17:00:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8612 (0.8859)	loss 3.4130 (3.3550)	grad_norm 221.3283 (158.0377)	mem 14369MB
[2022-12-20 17:00:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8633 (0.8835)	loss 3.8526 (3.3316)	grad_norm 227.8414 (156.3659)	mem 14369MB
[2022-12-20 17:00:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [189/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8714 (0.8819)	loss 3.5692 (3.2846)	grad_norm 99.8859 (151.9093)	mem 14369MB
[2022-12-20 17:01:01 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 189 training takes 0:01:05
[2022-12-20 17:01:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5381 (1.5381)	loss 2.3863 (2.3863)	grad_norm 84.4271 (84.4271)	mem 14369MB
[2022-12-20 17:01:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8715 (0.9343)	loss 4.8256 (3.0843)	grad_norm 201.9211 (142.3527)	mem 14369MB
[2022-12-20 17:01:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8710 (0.9056)	loss 2.3108 (3.2763)	grad_norm 88.8138 (138.4320)	mem 14369MB
[2022-12-20 17:01:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8748 (0.8944)	loss 2.3303 (3.1692)	grad_norm 140.9198 (133.1278)	mem 14369MB
[2022-12-20 17:01:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8691 (0.8889)	loss 3.2220 (3.1834)	grad_norm 331.4801 (141.0318)	mem 14369MB
[2022-12-20 17:01:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8728 (0.8863)	loss 3.3424 (3.2592)	grad_norm 145.9344 (141.4375)	mem 14369MB
[2022-12-20 17:01:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8656 (0.8840)	loss 2.7413 (3.2563)	grad_norm 189.4499 (143.6607)	mem 14369MB
[2022-12-20 17:02:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [190/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8837 (0.8837)	loss 2.8101 (3.2642)	grad_norm 155.5616 (143.4582)	mem 14369MB
[2022-12-20 17:02:06 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 190 training takes 0:01:05
[2022-12-20 17:02:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5292 (1.5292)	loss 4.3653 (4.3653)	grad_norm 134.8456 (134.8456)	mem 14369MB
[2022-12-20 17:02:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8989 (0.9356)	loss 2.5200 (3.1187)	grad_norm 99.8228 (109.6397)	mem 14369MB
[2022-12-20 17:02:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8811 (0.9065)	loss 2.7413 (3.2323)	grad_norm 173.0313 (139.5407)	mem 14369MB
[2022-12-20 17:02:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8677 (0.8973)	loss 2.7324 (3.2488)	grad_norm 165.8227 (149.1241)	mem 14369MB
[2022-12-20 17:02:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8678 (0.8908)	loss 4.0912 (3.2841)	grad_norm 92.6686 (144.5557)	mem 14369MB
[2022-12-20 17:02:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8657 (0.8868)	loss 3.6115 (3.3336)	grad_norm 164.6201 (144.0620)	mem 14369MB
[2022-12-20 17:03:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8833 (0.8857)	loss 4.1136 (3.4180)	grad_norm 204.8147 (150.0497)	mem 14369MB
[2022-12-20 17:03:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [191/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8755 (0.8843)	loss 2.8502 (3.3531)	grad_norm 193.8315 (151.8664)	mem 14369MB
[2022-12-20 17:03:12 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 191 training takes 0:01:05
[2022-12-20 17:03:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][0/74]	eta 0:01:52 lr 0.000002	time 1.5218 (1.5218)	loss 2.7007 (2.7007)	grad_norm 163.0874 (163.0874)	mem 14369MB
[2022-12-20 17:03:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8723 (0.9304)	loss 3.4423 (3.0770)	grad_norm 231.6528 (151.3737)	mem 14369MB
[2022-12-20 17:03:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8847 (0.9010)	loss 2.5958 (3.1391)	grad_norm 98.2814 (155.6057)	mem 14369MB
[2022-12-20 17:03:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8750 (0.8917)	loss 2.8495 (3.3931)	grad_norm 74.9983 (155.4106)	mem 14369MB
[2022-12-20 17:03:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8727 (0.8878)	loss 3.0205 (3.3409)	grad_norm 165.4694 (156.6124)	mem 14369MB
[2022-12-20 17:03:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8817 (0.8862)	loss 2.6055 (3.2600)	grad_norm 85.6066 (153.7200)	mem 14369MB
[2022-12-20 17:04:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8674 (0.8841)	loss 6.7617 (3.3631)	grad_norm 357.3499 (153.7218)	mem 14369MB
[2022-12-20 17:04:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [192/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8741 (0.8823)	loss 3.4396 (3.2970)	grad_norm 157.9209 (153.7576)	mem 14369MB
[2022-12-20 17:04:17 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 192 training takes 0:01:05
[2022-12-20 17:04:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5064 (1.5064)	loss 3.4133 (3.4133)	grad_norm 238.4758 (238.4758)	mem 14369MB
[2022-12-20 17:04:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8789 (0.9320)	loss 2.9013 (3.1844)	grad_norm 117.5306 (120.7787)	mem 14369MB
[2022-12-20 17:04:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8774 (0.9045)	loss 3.4375 (3.2233)	grad_norm 166.2224 (128.9527)	mem 14369MB
[2022-12-20 17:04:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8676 (0.8945)	loss 2.7018 (3.2111)	grad_norm 75.3981 (129.3590)	mem 14369MB
[2022-12-20 17:04:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8754 (0.8896)	loss 2.9979 (3.1725)	grad_norm 112.7613 (133.4858)	mem 14369MB
[2022-12-20 17:05:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8729 (0.8861)	loss 3.4245 (3.1842)	grad_norm 140.9204 (138.9905)	mem 14369MB
[2022-12-20 17:05:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8921 (0.8843)	loss 2.9029 (3.2512)	grad_norm 120.8591 (136.5385)	mem 14369MB
[2022-12-20 17:05:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [193/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8654 (0.8824)	loss 2.6979 (3.2624)	grad_norm 214.7482 (140.0337)	mem 14369MB
[2022-12-20 17:05:22 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 193 training takes 0:01:05
[2022-12-20 17:05:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][0/74]	eta 0:01:52 lr 0.000002	time 1.5231 (1.5231)	loss 3.1849 (3.1849)	grad_norm 255.8784 (255.8784)	mem 14369MB
[2022-12-20 17:05:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8663 (0.9355)	loss 3.5349 (2.8620)	grad_norm 152.1263 (156.4964)	mem 14369MB
[2022-12-20 17:05:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8767 (0.9047)	loss 2.9159 (3.0460)	grad_norm 149.1017 (145.4787)	mem 14369MB
[2022-12-20 17:05:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8759 (0.8948)	loss 3.4159 (3.0976)	grad_norm 110.9796 (156.0592)	mem 14369MB
[2022-12-20 17:05:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8807 (0.8904)	loss 3.0300 (3.1687)	grad_norm 157.8389 (152.0782)	mem 14369MB
[2022-12-20 17:06:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8749 (0.8874)	loss 2.8046 (3.1973)	grad_norm 112.2701 (148.0329)	mem 14369MB
[2022-12-20 17:06:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8855 (0.8856)	loss 3.6434 (3.2495)	grad_norm 118.3837 (142.4270)	mem 14369MB
[2022-12-20 17:06:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [194/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8677 (0.8843)	loss 2.8337 (3.2759)	grad_norm 157.2068 (140.3809)	mem 14369MB
[2022-12-20 17:06:27 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 194 training takes 0:01:05
[2022-12-20 17:06:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][0/74]	eta 0:01:52 lr 0.000002	time 1.5242 (1.5242)	loss 5.4712 (5.4712)	grad_norm 188.4701 (188.4701)	mem 14369MB
[2022-12-20 17:06:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8683 (0.9313)	loss 2.9346 (3.4091)	grad_norm 151.6227 (149.4004)	mem 14369MB
[2022-12-20 17:06:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8772 (0.9036)	loss 2.3675 (3.4748)	grad_norm 88.0893 (139.4592)	mem 14369MB
[2022-12-20 17:06:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8658 (0.8927)	loss 3.0246 (3.3316)	grad_norm 327.4423 (139.9144)	mem 14369MB
[2022-12-20 17:07:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8711 (0.8877)	loss 3.0024 (3.3846)	grad_norm 86.0801 (142.3611)	mem 14369MB
[2022-12-20 17:07:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8726 (0.8853)	loss 3.3965 (3.3486)	grad_norm 124.6309 (139.3472)	mem 14369MB
[2022-12-20 17:07:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8639 (0.8841)	loss 3.1360 (3.3311)	grad_norm 217.5984 (139.8506)	mem 14369MB
[2022-12-20 17:07:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [195/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8786 (0.8832)	loss 3.5819 (3.2903)	grad_norm 123.3749 (138.3485)	mem 14369MB
[2022-12-20 17:07:33 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 195 training takes 0:01:05
[2022-12-20 17:07:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][0/74]	eta 0:01:54 lr 0.000002	time 1.5410 (1.5410)	loss 2.4390 (2.4390)	grad_norm 140.2154 (140.2154)	mem 14369MB
[2022-12-20 17:07:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][10/74]	eta 0:01:00 lr 0.000002	time 0.8704 (0.9406)	loss 2.9994 (2.9794)	grad_norm 102.8030 (128.2527)	mem 14369MB
[2022-12-20 17:07:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][20/74]	eta 0:00:49 lr 0.000002	time 0.8733 (0.9081)	loss 3.3183 (3.1163)	grad_norm 68.8300 (134.8472)	mem 14369MB
[2022-12-20 17:08:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8905 (0.8965)	loss 3.1761 (3.1620)	grad_norm 118.1669 (140.5179)	mem 14369MB
[2022-12-20 17:08:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8761 (0.8910)	loss 2.6972 (3.1025)	grad_norm 97.7740 (140.1843)	mem 14369MB
[2022-12-20 17:08:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8743 (0.8880)	loss 2.8045 (3.2438)	grad_norm 128.6872 (134.6237)	mem 14369MB
[2022-12-20 17:08:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8763 (0.8858)	loss 2.6490 (3.2138)	grad_norm 167.5149 (140.7134)	mem 14369MB
[2022-12-20 17:08:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [196/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8693 (0.8844)	loss 2.7421 (3.2054)	grad_norm 110.6987 (140.2728)	mem 14369MB
[2022-12-20 17:08:38 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 196 training takes 0:01:05
[2022-12-20 17:08:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5306 (1.5306)	loss 3.2471 (3.2471)	grad_norm 194.5194 (194.5194)	mem 14369MB
[2022-12-20 17:08:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8695 (0.9357)	loss 2.8621 (3.1907)	grad_norm 158.2448 (133.5234)	mem 14369MB
[2022-12-20 17:08:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][20/74]	eta 0:00:49 lr 0.000002	time 0.8864 (0.9131)	loss 3.9409 (3.4241)	grad_norm 143.7997 (130.1938)	mem 14369MB
[2022-12-20 17:09:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8794 (0.9038)	loss 3.1400 (3.3119)	grad_norm 81.7620 (134.5276)	mem 14369MB
[2022-12-20 17:09:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8676 (0.8972)	loss 7.5908 (3.3097)	grad_norm 213.9574 (136.9548)	mem 14369MB
[2022-12-20 17:09:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8753 (0.8933)	loss 4.2438 (3.3036)	grad_norm 184.4719 (145.6215)	mem 14369MB
[2022-12-20 17:09:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8682 (0.8901)	loss 3.0508 (3.3483)	grad_norm 171.9919 (143.8069)	mem 14369MB
[2022-12-20 17:09:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [197/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8749 (0.8884)	loss 2.2828 (3.3407)	grad_norm 88.6479 (142.8987)	mem 14369MB
[2022-12-20 17:09:44 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 197 training takes 0:01:05
[2022-12-20 17:09:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5396 (1.5396)	loss 2.8830 (2.8830)	grad_norm 211.9636 (211.9636)	mem 14369MB
[2022-12-20 17:09:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8728 (0.9364)	loss 3.3270 (3.1451)	grad_norm 191.1278 (121.0494)	mem 14369MB
[2022-12-20 17:10:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][20/74]	eta 0:00:49 lr 0.000002	time 0.8818 (0.9092)	loss 2.4988 (3.2820)	grad_norm 97.5482 (138.9989)	mem 14369MB
[2022-12-20 17:10:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8758 (0.8972)	loss 2.4719 (3.3721)	grad_norm 120.0305 (145.9868)	mem 14369MB
[2022-12-20 17:10:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8740 (0.8914)	loss 2.7268 (3.3560)	grad_norm 164.7392 (146.8264)	mem 14369MB
[2022-12-20 17:10:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8889 (0.8891)	loss 6.7269 (3.4037)	grad_norm 439.1118 (149.1626)	mem 14369MB
[2022-12-20 17:10:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8765 (0.8874)	loss 4.9032 (3.4305)	grad_norm 224.6114 (155.5644)	mem 14369MB
[2022-12-20 17:10:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [198/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8799 (0.8866)	loss 3.2356 (3.3981)	grad_norm 124.3184 (154.2788)	mem 14369MB
[2022-12-20 17:10:49 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 198 training takes 0:01:05
[2022-12-20 17:10:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5289 (1.5289)	loss 3.2567 (3.2567)	grad_norm 244.7739 (244.7739)	mem 14369MB
[2022-12-20 17:10:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8798 (0.9331)	loss 3.7598 (3.4052)	grad_norm 132.0403 (152.7006)	mem 14369MB
[2022-12-20 17:11:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8754 (0.9045)	loss 3.6494 (3.4238)	grad_norm 74.2166 (154.8846)	mem 14369MB
[2022-12-20 17:11:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8791 (0.8965)	loss 2.5031 (3.3031)	grad_norm 138.8396 (142.4446)	mem 14369MB
[2022-12-20 17:11:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8663 (0.8913)	loss 3.5226 (3.2546)	grad_norm 168.5883 (149.9473)	mem 14369MB
[2022-12-20 17:11:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8810 (0.8895)	loss 2.8863 (3.3584)	grad_norm 174.5124 (154.6214)	mem 14369MB
[2022-12-20 17:11:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8816 (0.8879)	loss 2.9131 (3.4024)	grad_norm 121.3491 (157.2435)	mem 14369MB
[2022-12-20 17:11:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [199/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8961 (0.8869)	loss 2.4878 (3.3536)	grad_norm 115.4925 (157.8920)	mem 14369MB
[2022-12-20 17:11:55 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 199 training takes 0:01:05
[2022-12-20 17:11:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5386 (1.5386)	loss 3.8058 (3.8058)	grad_norm 186.6015 (186.6015)	mem 14369MB
[2022-12-20 17:12:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][10/74]	eta 0:01:00 lr 0.000002	time 0.8741 (0.9396)	loss 4.0876 (3.5348)	grad_norm 150.5140 (153.3789)	mem 14369MB
[2022-12-20 17:12:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][20/74]	eta 0:00:49 lr 0.000002	time 0.8717 (0.9080)	loss 3.2812 (3.3571)	grad_norm 233.5798 (146.2924)	mem 14369MB
[2022-12-20 17:12:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8818 (0.8972)	loss 2.9200 (3.1933)	grad_norm 63.5617 (145.1531)	mem 14369MB
[2022-12-20 17:12:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8980 (0.8939)	loss 2.7717 (3.2268)	grad_norm 70.6187 (145.5049)	mem 14369MB
[2022-12-20 17:12:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8807 (0.8908)	loss 3.4991 (3.2179)	grad_norm 136.7561 (147.9012)	mem 14369MB
[2022-12-20 17:12:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8815 (0.8895)	loss 2.4956 (3.2882)	grad_norm 134.8522 (148.2657)	mem 14369MB
[2022-12-20 17:12:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [200/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8764 (0.8882)	loss 2.8541 (3.2803)	grad_norm 190.6385 (147.6070)	mem 14369MB
[2022-12-20 17:13:00 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 200 training takes 0:01:05
[2022-12-20 17:13:00 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_200.pth saving......
[2022-12-20 17:13:01 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_200.pth saved !!!
[2022-12-20 17:13:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5054 (1.5054)	loss 2.9759 (2.9759)	grad_norm 123.6028 (123.6028)	mem 14369MB
[2022-12-20 17:13:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8722 (0.9281)	loss 4.2042 (3.7460)	grad_norm 96.0181 (148.5370)	mem 14369MB
[2022-12-20 17:13:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8783 (0.9033)	loss 2.8536 (3.5172)	grad_norm 119.1118 (140.2220)	mem 14369MB
[2022-12-20 17:13:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8771 (0.8928)	loss 2.8026 (3.4582)	grad_norm 152.5681 (139.0865)	mem 14369MB
[2022-12-20 17:13:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8762 (0.8885)	loss 2.8762 (3.3241)	grad_norm 136.3276 (141.2671)	mem 14369MB
[2022-12-20 17:13:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8878 (0.8852)	loss 3.2974 (3.2755)	grad_norm 88.2303 (141.9313)	mem 14369MB
[2022-12-20 17:13:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][60/74]	eta 0:00:12 lr 0.000002	time 0.9974 (0.8845)	loss 3.4410 (3.1955)	grad_norm 197.7156 (140.4941)	mem 14369MB
[2022-12-20 17:14:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [201/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8730 (0.8898)	loss 3.5868 (3.2373)	grad_norm 152.2901 (141.5686)	mem 14369MB
[2022-12-20 17:14:07 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 201 training takes 0:01:05
[2022-12-20 17:14:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5082 (1.5082)	loss 6.0497 (6.0497)	grad_norm 104.6465 (104.6465)	mem 14369MB
[2022-12-20 17:14:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8815 (0.9302)	loss 3.1784 (3.3083)	grad_norm 135.0607 (138.9551)	mem 14369MB
[2022-12-20 17:14:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8631 (0.9024)	loss 4.4677 (3.2801)	grad_norm 84.5949 (132.5389)	mem 14369MB
[2022-12-20 17:14:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8655 (0.8922)	loss 3.1528 (3.2377)	grad_norm 95.5275 (133.2243)	mem 14369MB
[2022-12-20 17:14:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8699 (0.8876)	loss 4.6034 (3.3125)	grad_norm 149.8585 (142.8783)	mem 14369MB
[2022-12-20 17:14:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8761 (0.8850)	loss 3.1221 (3.3376)	grad_norm 127.3152 (157.5259)	mem 14369MB
[2022-12-20 17:15:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8794 (0.8832)	loss 3.0780 (3.3046)	grad_norm 129.3630 (154.2934)	mem 14369MB
[2022-12-20 17:15:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [202/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8637 (0.8820)	loss 2.5638 (3.2981)	grad_norm 163.4845 (152.1364)	mem 14369MB
[2022-12-20 17:15:12 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 202 training takes 0:01:05
[2022-12-20 17:15:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5275 (1.5275)	loss 2.8582 (2.8582)	grad_norm 86.9567 (86.9567)	mem 14369MB
[2022-12-20 17:15:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8658 (0.9287)	loss 3.7247 (3.0218)	grad_norm 129.8076 (163.0297)	mem 14369MB
[2022-12-20 17:15:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8737 (0.9000)	loss 3.6414 (2.9807)	grad_norm 247.8594 (162.1209)	mem 14369MB
[2022-12-20 17:15:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8686 (0.8901)	loss 3.2614 (3.1217)	grad_norm 185.3402 (151.2294)	mem 14369MB
[2022-12-20 17:15:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8782 (0.8875)	loss 4.1341 (3.2882)	grad_norm 238.5738 (148.2113)	mem 14369MB
[2022-12-20 17:15:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8725 (0.8841)	loss 2.4365 (3.2061)	grad_norm 91.7836 (146.2346)	mem 14369MB
[2022-12-20 17:16:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8774 (0.8825)	loss 3.7555 (3.2354)	grad_norm 74.2337 (144.4575)	mem 14369MB
[2022-12-20 17:16:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [203/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8719 (0.8814)	loss 2.7566 (3.2252)	grad_norm 85.7889 (141.5750)	mem 14369MB
[2022-12-20 17:16:17 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 203 training takes 0:01:05
[2022-12-20 17:16:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5113 (1.5113)	loss 3.2555 (3.2555)	grad_norm 194.3240 (194.3240)	mem 14369MB
[2022-12-20 17:16:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8702 (0.9292)	loss 2.6491 (3.3210)	grad_norm 126.0438 (161.7655)	mem 14369MB
[2022-12-20 17:16:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8792 (0.9016)	loss 3.7775 (3.3026)	grad_norm 119.0551 (140.0007)	mem 14369MB
[2022-12-20 17:16:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8695 (0.8916)	loss 3.9132 (3.2840)	grad_norm 139.5075 (134.4373)	mem 14369MB
[2022-12-20 17:16:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8879 (0.8876)	loss 2.6383 (3.3369)	grad_norm 123.1782 (131.2738)	mem 14369MB
[2022-12-20 17:17:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8707 (0.8849)	loss 3.8962 (3.3151)	grad_norm 275.8303 (145.3402)	mem 14369MB
[2022-12-20 17:17:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8730 (0.8828)	loss 3.3233 (3.3015)	grad_norm 124.4835 (142.6742)	mem 14369MB
[2022-12-20 17:17:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [204/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8670 (0.8808)	loss 2.7465 (3.2542)	grad_norm 154.6012 (138.6537)	mem 14369MB
[2022-12-20 17:17:23 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 204 training takes 0:01:05
[2022-12-20 17:17:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][0/74]	eta 0:01:52 lr 0.000002	time 1.5211 (1.5211)	loss 4.4542 (4.4542)	grad_norm 106.8946 (106.8946)	mem 14369MB
[2022-12-20 17:17:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8828 (0.9327)	loss 2.8776 (3.1142)	grad_norm 88.3779 (132.5458)	mem 14369MB
[2022-12-20 17:17:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8735 (0.9038)	loss 2.7888 (3.3348)	grad_norm 86.1658 (123.0496)	mem 14369MB
[2022-12-20 17:17:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8697 (0.8945)	loss 2.4721 (3.2533)	grad_norm 137.1216 (120.4356)	mem 14369MB
[2022-12-20 17:17:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8736 (0.8891)	loss 2.9497 (3.2648)	grad_norm 138.2624 (123.2382)	mem 14369MB
[2022-12-20 17:18:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8802 (0.8857)	loss 3.0580 (3.2249)	grad_norm 86.1858 (133.5731)	mem 14369MB
[2022-12-20 17:18:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8744 (0.8835)	loss 2.8841 (3.2291)	grad_norm 145.7069 (134.8724)	mem 14369MB
[2022-12-20 17:18:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [205/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8632 (0.8817)	loss 2.1319 (3.2461)	grad_norm 151.1970 (134.6667)	mem 14369MB
[2022-12-20 17:18:28 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 205 training takes 0:01:05
[2022-12-20 17:18:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5126 (1.5126)	loss 2.6327 (2.6327)	grad_norm 112.8608 (112.8608)	mem 14369MB
[2022-12-20 17:18:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8645 (0.9309)	loss 3.5047 (3.1467)	grad_norm 86.1343 (134.6912)	mem 14369MB
[2022-12-20 17:18:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8657 (0.9034)	loss 3.3031 (3.0428)	grad_norm 86.9231 (133.3687)	mem 14369MB
[2022-12-20 17:18:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8623 (0.8925)	loss 3.5855 (3.1812)	grad_norm 113.2070 (140.0273)	mem 14369MB
[2022-12-20 17:19:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8699 (0.8872)	loss 3.3234 (3.1889)	grad_norm 147.1743 (140.2983)	mem 14369MB
[2022-12-20 17:19:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8663 (0.8849)	loss 3.2474 (3.1940)	grad_norm 138.2248 (138.6921)	mem 14369MB
[2022-12-20 17:19:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8728 (0.8829)	loss 4.1401 (3.1893)	grad_norm 166.5999 (139.2799)	mem 14369MB
[2022-12-20 17:19:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [206/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8786 (0.8817)	loss 3.0485 (3.1821)	grad_norm 138.6588 (137.9257)	mem 14369MB
[2022-12-20 17:19:33 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 206 training takes 0:01:05
[2022-12-20 17:19:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][0/74]	eta 0:01:52 lr 0.000002	time 1.5177 (1.5177)	loss 2.5344 (2.5344)	grad_norm 117.2680 (117.2680)	mem 14369MB
[2022-12-20 17:19:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8634 (0.9288)	loss 2.8547 (3.1501)	grad_norm 256.8639 (152.6031)	mem 14369MB
[2022-12-20 17:19:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8737 (0.9040)	loss 4.0375 (3.1284)	grad_norm 140.9738 (138.4064)	mem 14369MB
[2022-12-20 17:20:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8781 (0.8942)	loss 2.5571 (3.2938)	grad_norm 110.4481 (138.6072)	mem 14369MB
[2022-12-20 17:20:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8721 (0.8883)	loss 2.7275 (3.3341)	grad_norm 92.9418 (137.6809)	mem 14369MB
[2022-12-20 17:20:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8643 (0.8852)	loss 2.1376 (3.3195)	grad_norm 212.8924 (136.6863)	mem 14369MB
[2022-12-20 17:20:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8732 (0.8831)	loss 3.7233 (3.3296)	grad_norm 119.9463 (146.1654)	mem 14369MB
[2022-12-20 17:20:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [207/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8795 (0.8822)	loss 4.0998 (3.3015)	grad_norm 117.6911 (147.5390)	mem 14369MB
[2022-12-20 17:20:38 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 207 training takes 0:01:05
[2022-12-20 17:20:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5282 (1.5282)	loss 5.6770 (5.6770)	grad_norm 83.0736 (83.0736)	mem 14369MB
[2022-12-20 17:20:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8726 (0.9358)	loss 4.1277 (3.7331)	grad_norm 123.6836 (124.4317)	mem 14369MB
[2022-12-20 17:20:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8742 (0.9072)	loss 3.1692 (3.2967)	grad_norm 178.1912 (129.8587)	mem 14369MB
[2022-12-20 17:21:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8783 (0.8981)	loss 3.1352 (3.3076)	grad_norm 117.2433 (132.8218)	mem 14369MB
[2022-12-20 17:21:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8857 (0.8934)	loss 2.4679 (3.1915)	grad_norm 72.9280 (133.0779)	mem 14369MB
[2022-12-20 17:21:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8856 (0.8899)	loss 3.7661 (3.2093)	grad_norm 87.6775 (130.9863)	mem 14369MB
[2022-12-20 17:21:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8714 (0.8877)	loss 2.5337 (3.2137)	grad_norm 91.0716 (128.1824)	mem 14369MB
[2022-12-20 17:21:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [208/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8709 (0.8854)	loss 3.5351 (3.2401)	grad_norm 127.2059 (130.4074)	mem 14369MB
[2022-12-20 17:21:43 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 208 training takes 0:01:05
[2022-12-20 17:21:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][0/74]	eta 0:01:52 lr 0.000002	time 1.5201 (1.5201)	loss 3.0124 (3.0124)	grad_norm 164.1313 (164.1313)	mem 14369MB
[2022-12-20 17:21:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8696 (0.9312)	loss 2.5133 (3.1080)	grad_norm 79.5214 (171.7983)	mem 14369MB
[2022-12-20 17:22:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8679 (0.9029)	loss 2.5666 (3.4525)	grad_norm 139.6470 (152.4303)	mem 14369MB
[2022-12-20 17:22:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8833 (0.8936)	loss 3.0319 (3.3306)	grad_norm 100.6065 (146.8358)	mem 14369MB
[2022-12-20 17:22:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8793 (0.8891)	loss 2.7184 (3.2890)	grad_norm 164.7131 (150.4249)	mem 14369MB
[2022-12-20 17:22:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8795 (0.8862)	loss 3.9100 (3.4058)	grad_norm 109.4363 (148.1540)	mem 14369MB
[2022-12-20 17:22:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8949 (0.8850)	loss 2.7164 (3.3276)	grad_norm 75.2148 (147.2767)	mem 14369MB
[2022-12-20 17:22:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [209/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8858 (0.8840)	loss 3.2698 (3.3028)	grad_norm 54.9906 (144.6569)	mem 14369MB
[2022-12-20 17:22:49 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 209 training takes 0:01:05
[2022-12-20 17:22:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][0/74]	eta 0:01:53 lr 0.000002	time 1.5279 (1.5279)	loss 2.9605 (2.9605)	grad_norm 74.7835 (74.7835)	mem 14369MB
[2022-12-20 17:22:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8847 (0.9334)	loss 2.5459 (3.5910)	grad_norm 112.2382 (118.0326)	mem 14369MB
[2022-12-20 17:23:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8756 (0.9048)	loss 3.2194 (3.3728)	grad_norm 232.7956 (137.9245)	mem 14369MB
[2022-12-20 17:23:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8796 (0.8959)	loss 3.0629 (3.1410)	grad_norm 265.0487 (146.9929)	mem 14369MB
[2022-12-20 17:23:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8784 (0.8912)	loss 3.1449 (3.1506)	grad_norm 96.6269 (140.7193)	mem 14369MB
[2022-12-20 17:23:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8835 (0.8933)	loss 5.0556 (3.1535)	grad_norm 131.1556 (136.2524)	mem 14369MB
[2022-12-20 17:23:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8730 (0.8905)	loss 2.6887 (3.1896)	grad_norm 126.5080 (134.6767)	mem 14369MB
[2022-12-20 17:23:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [210/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8704 (0.8880)	loss 2.9930 (3.2189)	grad_norm 205.2447 (132.9247)	mem 14369MB
[2022-12-20 17:23:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 210 training takes 0:01:05
[2022-12-20 17:23:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][0/74]	eta 0:01:51 lr 0.000002	time 1.5041 (1.5041)	loss 2.8531 (2.8531)	grad_norm 284.1623 (284.1623)	mem 14369MB
[2022-12-20 17:24:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8633 (0.9308)	loss 3.2297 (3.4823)	grad_norm 397.2549 (181.1330)	mem 14369MB
[2022-12-20 17:24:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8695 (0.9027)	loss 2.6362 (3.3454)	grad_norm 63.3899 (161.4481)	mem 14369MB
[2022-12-20 17:24:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8632 (0.8925)	loss 3.0086 (3.2263)	grad_norm 145.4162 (144.6475)	mem 14369MB
[2022-12-20 17:24:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8772 (0.8898)	loss 2.5780 (3.1913)	grad_norm 85.8782 (136.2607)	mem 14369MB
[2022-12-20 17:24:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8836 (0.8868)	loss 2.4952 (3.1486)	grad_norm 159.8584 (135.1728)	mem 14369MB
[2022-12-20 17:24:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8830 (0.8847)	loss 4.1123 (3.1603)	grad_norm 130.2926 (134.5689)	mem 14369MB
[2022-12-20 17:24:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [211/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8629 (0.8824)	loss 4.4882 (3.2521)	grad_norm 193.6152 (136.3769)	mem 14369MB
[2022-12-20 17:25:00 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 211 training takes 0:01:05
[2022-12-20 17:25:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][0/74]	eta 0:01:54 lr 0.000002	time 1.5427 (1.5427)	loss 2.5928 (2.5928)	grad_norm 136.7199 (136.7199)	mem 14369MB
[2022-12-20 17:25:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8707 (0.9373)	loss 2.0841 (2.9613)	grad_norm 131.7418 (136.6045)	mem 14369MB
[2022-12-20 17:25:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8689 (0.9057)	loss 3.0716 (2.9219)	grad_norm 137.9851 (145.2528)	mem 14369MB
[2022-12-20 17:25:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][30/74]	eta 0:00:39 lr 0.000002	time 0.8777 (0.8971)	loss 6.3809 (3.0428)	grad_norm 158.0527 (140.5194)	mem 14369MB
[2022-12-20 17:25:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][40/74]	eta 0:00:30 lr 0.000002	time 0.8748 (0.8919)	loss 3.2022 (3.3062)	grad_norm 96.9166 (149.8706)	mem 14369MB
[2022-12-20 17:25:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][50/74]	eta 0:00:21 lr 0.000002	time 0.8610 (0.8879)	loss 4.4555 (3.2709)	grad_norm 197.3962 (155.7243)	mem 14369MB
[2022-12-20 17:25:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][60/74]	eta 0:00:12 lr 0.000002	time 0.8791 (0.8861)	loss 3.7821 (3.3299)	grad_norm 126.4938 (151.3473)	mem 14369MB
[2022-12-20 17:26:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [212/300][70/74]	eta 0:00:03 lr 0.000002	time 0.8652 (0.8848)	loss 2.5546 (3.2734)	grad_norm 176.9010 (148.8527)	mem 14369MB
[2022-12-20 17:26:05 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 212 training takes 0:01:05
[2022-12-20 17:26:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][0/74]	eta 0:01:52 lr 0.000002	time 1.5245 (1.5245)	loss 2.8502 (2.8502)	grad_norm 275.5348 (275.5348)	mem 14369MB
[2022-12-20 17:26:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][10/74]	eta 0:00:59 lr 0.000002	time 0.8625 (0.9317)	loss 2.5864 (3.0868)	grad_norm 128.7392 (128.6970)	mem 14369MB
[2022-12-20 17:26:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][20/74]	eta 0:00:48 lr 0.000002	time 0.8692 (0.9028)	loss 2.7924 (3.3108)	grad_norm 65.2424 (139.7219)	mem 14369MB
[2022-12-20 17:26:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8792 (0.8966)	loss 2.9519 (3.3539)	grad_norm 161.4187 (146.4340)	mem 14369MB
[2022-12-20 17:26:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8796 (0.8931)	loss 4.7879 (3.3190)	grad_norm 97.6087 (145.1406)	mem 14369MB
[2022-12-20 17:26:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8912 (0.8910)	loss 4.2267 (3.2983)	grad_norm 281.5294 (146.7078)	mem 14369MB
[2022-12-20 17:26:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8844 (0.8892)	loss 2.2468 (3.2794)	grad_norm 130.2400 (144.1006)	mem 14369MB
[2022-12-20 17:27:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [213/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8778 (0.8873)	loss 3.1540 (3.2858)	grad_norm 89.3433 (144.0424)	mem 14369MB
[2022-12-20 17:27:11 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 213 training takes 0:01:05
[2022-12-20 17:27:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5291 (1.5291)	loss 2.6751 (2.6751)	grad_norm 113.6613 (113.6613)	mem 14369MB
[2022-12-20 17:27:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8832 (0.9309)	loss 3.1141 (3.0908)	grad_norm 216.6717 (126.7019)	mem 14369MB
[2022-12-20 17:27:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8661 (0.9033)	loss 2.5501 (2.9973)	grad_norm 106.6858 (139.5593)	mem 14369MB
[2022-12-20 17:27:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8708 (0.8933)	loss 2.5666 (3.0265)	grad_norm 82.4158 (137.0426)	mem 14369MB
[2022-12-20 17:27:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8679 (0.8878)	loss 2.4192 (3.2505)	grad_norm 125.0605 (139.8695)	mem 14369MB
[2022-12-20 17:27:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8808 (0.8847)	loss 3.6127 (3.3008)	grad_norm 76.2228 (135.6436)	mem 14369MB
[2022-12-20 17:28:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][60/74]	eta 0:00:12 lr 0.000001	time 0.9160 (0.8839)	loss 3.8363 (3.2725)	grad_norm 319.1714 (133.6143)	mem 14369MB
[2022-12-20 17:28:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [214/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8692 (0.8823)	loss 3.1142 (3.2526)	grad_norm 194.8384 (137.2360)	mem 14369MB
[2022-12-20 17:28:16 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 214 training takes 0:01:05
[2022-12-20 17:28:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5187 (1.5187)	loss 2.5128 (2.5128)	grad_norm 164.2003 (164.2003)	mem 14369MB
[2022-12-20 17:28:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8677 (0.9320)	loss 2.4323 (3.4144)	grad_norm 147.1837 (144.5072)	mem 14369MB
[2022-12-20 17:28:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8613 (0.9023)	loss 2.8838 (3.4736)	grad_norm 183.7643 (134.0031)	mem 14369MB
[2022-12-20 17:28:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8692 (0.8927)	loss 2.0754 (3.3678)	grad_norm 180.4545 (130.4123)	mem 14369MB
[2022-12-20 17:28:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8683 (0.8879)	loss 3.5051 (3.3725)	grad_norm 167.0482 (141.9855)	mem 14369MB
[2022-12-20 17:29:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8683 (0.8847)	loss 3.5011 (3.3085)	grad_norm 169.0352 (137.8043)	mem 14369MB
[2022-12-20 17:29:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8760 (0.8827)	loss 2.3999 (3.2808)	grad_norm 140.0095 (143.8190)	mem 14369MB
[2022-12-20 17:29:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [215/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8627 (0.8808)	loss 3.2567 (3.2668)	grad_norm 121.2398 (144.8398)	mem 14369MB
[2022-12-20 17:29:21 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 215 training takes 0:01:05
[2022-12-20 17:29:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5235 (1.5235)	loss 3.9328 (3.9328)	grad_norm 198.5868 (198.5868)	mem 14369MB
[2022-12-20 17:29:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8658 (0.9322)	loss 3.6503 (3.7254)	grad_norm 192.9920 (165.7772)	mem 14369MB
[2022-12-20 17:29:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8706 (0.9032)	loss 3.2290 (3.4585)	grad_norm 75.5668 (142.3322)	mem 14369MB
[2022-12-20 17:29:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8724 (0.8929)	loss 5.6697 (3.4173)	grad_norm 100.3583 (135.0124)	mem 14369MB
[2022-12-20 17:29:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8872 (0.8885)	loss 2.5723 (3.3822)	grad_norm 118.6403 (131.9041)	mem 14369MB
[2022-12-20 17:30:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8828 (0.8857)	loss 3.2374 (3.3561)	grad_norm 127.8068 (133.2871)	mem 14369MB
[2022-12-20 17:30:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8934 (0.8850)	loss 2.8576 (3.3515)	grad_norm 99.2654 (131.8861)	mem 14369MB
[2022-12-20 17:30:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [216/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8792 (0.8846)	loss 3.0535 (3.2598)	grad_norm 128.5229 (130.3346)	mem 14369MB
[2022-12-20 17:30:26 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 216 training takes 0:01:05
[2022-12-20 17:30:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5126 (1.5126)	loss 4.8255 (4.8255)	grad_norm 257.6959 (257.6959)	mem 14369MB
[2022-12-20 17:30:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8633 (0.9326)	loss 2.5004 (3.4426)	grad_norm 151.1757 (144.1889)	mem 14369MB
[2022-12-20 17:30:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8778 (0.9035)	loss 2.7290 (3.2962)	grad_norm 113.9984 (130.2125)	mem 14369MB
[2022-12-20 17:30:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8745 (0.8934)	loss 2.5911 (3.2309)	grad_norm 129.4640 (129.0319)	mem 14369MB
[2022-12-20 17:31:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8717 (0.8897)	loss 2.7074 (3.2150)	grad_norm 51.9899 (124.0019)	mem 14369MB
[2022-12-20 17:31:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8636 (0.8856)	loss 2.5642 (3.1751)	grad_norm 240.3626 (123.8857)	mem 14369MB
[2022-12-20 17:31:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8731 (0.8837)	loss 5.2027 (3.1976)	grad_norm 109.0962 (120.5899)	mem 14369MB
[2022-12-20 17:31:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [217/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8718 (0.8815)	loss 3.0727 (3.2162)	grad_norm 87.8058 (129.4943)	mem 14369MB
[2022-12-20 17:31:31 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 217 training takes 0:01:05
[2022-12-20 17:31:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5129 (1.5129)	loss 3.9085 (3.9085)	grad_norm 124.9752 (124.9752)	mem 14369MB
[2022-12-20 17:31:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8622 (0.9257)	loss 2.7705 (3.4447)	grad_norm 151.7429 (145.1634)	mem 14369MB
[2022-12-20 17:31:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8666 (0.9005)	loss 2.6602 (3.5738)	grad_norm 88.2368 (143.2280)	mem 14369MB
[2022-12-20 17:31:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8749 (0.8911)	loss 3.2599 (3.3530)	grad_norm 58.1819 (131.5854)	mem 14369MB
[2022-12-20 17:32:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8757 (0.8869)	loss 2.5510 (3.2461)	grad_norm 93.2455 (128.7536)	mem 14369MB
[2022-12-20 17:32:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8635 (0.8839)	loss 3.1971 (3.2281)	grad_norm 84.1919 (135.8433)	mem 14369MB
[2022-12-20 17:32:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8699 (0.8820)	loss 2.3490 (3.1978)	grad_norm 75.6964 (130.5379)	mem 14369MB
[2022-12-20 17:32:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [218/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8863 (0.8808)	loss 2.3324 (3.2313)	grad_norm 106.7159 (130.6416)	mem 14369MB
[2022-12-20 17:32:36 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 218 training takes 0:01:05
[2022-12-20 17:32:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5201 (1.5201)	loss 2.5355 (2.5355)	grad_norm 82.6969 (82.6969)	mem 14369MB
[2022-12-20 17:32:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8806 (0.9343)	loss 3.4180 (3.4184)	grad_norm 120.7731 (140.2946)	mem 14369MB
[2022-12-20 17:32:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8795 (0.9063)	loss 3.5975 (3.2205)	grad_norm 64.3710 (129.3100)	mem 14369MB
[2022-12-20 17:33:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8651 (0.8962)	loss 3.5043 (3.1798)	grad_norm 107.7265 (133.5896)	mem 14369MB
[2022-12-20 17:33:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8795 (0.8908)	loss 2.6258 (3.1280)	grad_norm 60.5743 (126.0862)	mem 14369MB
[2022-12-20 17:33:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8810 (0.8876)	loss 2.8334 (3.1604)	grad_norm 80.3608 (123.7699)	mem 14369MB
[2022-12-20 17:33:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8714 (0.8854)	loss 4.0695 (3.2589)	grad_norm 94.4213 (126.6143)	mem 14369MB
[2022-12-20 17:33:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [219/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8820 (0.8838)	loss 4.7116 (3.2245)	grad_norm 259.1484 (129.4231)	mem 14369MB
[2022-12-20 17:33:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 219 training takes 0:01:05
[2022-12-20 17:33:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][0/74]	eta 0:01:54 lr 0.000001	time 1.5500 (1.5500)	loss 3.1123 (3.1123)	grad_norm 107.4524 (107.4524)	mem 14369MB
[2022-12-20 17:33:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8878 (0.9335)	loss 2.5142 (3.1756)	grad_norm 80.4657 (123.3420)	mem 14369MB
[2022-12-20 17:34:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8789 (0.9062)	loss 3.5560 (3.1331)	grad_norm 157.8895 (129.6969)	mem 14369MB
[2022-12-20 17:34:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8697 (0.8984)	loss 2.7318 (3.1485)	grad_norm 147.8271 (121.2935)	mem 14369MB
[2022-12-20 17:34:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8744 (0.8929)	loss 3.2425 (3.1286)	grad_norm 124.6678 (129.9068)	mem 14369MB
[2022-12-20 17:34:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8707 (0.8884)	loss 3.8442 (3.1051)	grad_norm 51.7717 (124.8162)	mem 14369MB
[2022-12-20 17:34:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8840 (0.8858)	loss 2.9889 (3.1617)	grad_norm 52.5312 (126.3480)	mem 14369MB
[2022-12-20 17:34:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [220/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8733 (0.8839)	loss 4.2073 (3.1727)	grad_norm 127.0017 (125.6320)	mem 14369MB
[2022-12-20 17:34:47 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 220 training takes 0:01:05
[2022-12-20 17:34:47 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_220.pth saving......
[2022-12-20 17:34:48 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_220.pth saved !!!
[2022-12-20 17:34:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5051 (1.5051)	loss 2.5940 (2.5940)	grad_norm 129.5935 (129.5935)	mem 14369MB
[2022-12-20 17:34:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8628 (0.9269)	loss 2.7256 (3.0375)	grad_norm 196.2649 (145.9481)	mem 14369MB
[2022-12-20 17:35:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8910 (0.9010)	loss 2.1730 (3.0083)	grad_norm 200.5318 (135.4430)	mem 14369MB
[2022-12-20 17:35:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8880 (0.8926)	loss 2.8185 (3.2838)	grad_norm 89.1874 (138.8911)	mem 14369MB
[2022-12-20 17:35:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8845 (0.8878)	loss 3.3304 (3.3010)	grad_norm 188.8604 (143.2735)	mem 14369MB
[2022-12-20 17:35:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8922 (0.8855)	loss 2.6103 (3.2678)	grad_norm 55.8322 (137.1869)	mem 14369MB
[2022-12-20 17:35:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8805 (0.8843)	loss 3.0605 (3.2228)	grad_norm 113.1775 (133.3460)	mem 14369MB
[2022-12-20 17:35:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [221/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8701 (0.8833)	loss 3.6817 (3.2276)	grad_norm 79.0151 (131.4271)	mem 14369MB
[2022-12-20 17:35:54 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 221 training takes 0:01:05
[2022-12-20 17:35:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5158 (1.5158)	loss 3.0029 (3.0029)	grad_norm 145.5857 (145.5857)	mem 14369MB
[2022-12-20 17:36:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8799 (0.9324)	loss 3.1750 (2.9344)	grad_norm 178.5211 (137.7224)	mem 14369MB
[2022-12-20 17:36:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8724 (0.9050)	loss 2.6493 (2.9827)	grad_norm 100.6637 (143.1331)	mem 14369MB
[2022-12-20 17:36:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8710 (0.8930)	loss 3.1449 (2.9810)	grad_norm 103.3154 (137.9449)	mem 14369MB
[2022-12-20 17:36:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8734 (0.8880)	loss 3.5890 (3.0994)	grad_norm 98.6693 (131.7556)	mem 14369MB
[2022-12-20 17:36:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8671 (0.8852)	loss 2.4400 (3.0700)	grad_norm 125.5200 (126.5655)	mem 14369MB
[2022-12-20 17:36:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8624 (0.8830)	loss 3.4152 (3.1281)	grad_norm 304.5856 (127.5745)	mem 14369MB
[2022-12-20 17:36:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [222/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8825 (0.8813)	loss 2.5000 (3.1558)	grad_norm 97.0291 (126.8305)	mem 14369MB
[2022-12-20 17:36:59 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 222 training takes 0:01:05
[2022-12-20 17:37:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5164 (1.5164)	loss 2.7296 (2.7296)	grad_norm 194.2970 (194.2970)	mem 14369MB
[2022-12-20 17:37:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8673 (0.9302)	loss 3.1166 (3.2346)	grad_norm 128.7201 (118.5291)	mem 14369MB
[2022-12-20 17:37:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8777 (0.9015)	loss 3.0724 (3.0569)	grad_norm 73.6444 (118.1088)	mem 14369MB
[2022-12-20 17:37:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8729 (0.8931)	loss 3.0396 (3.1671)	grad_norm 127.8114 (118.2476)	mem 14369MB
[2022-12-20 17:37:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8668 (0.8871)	loss 2.8515 (3.0742)	grad_norm 126.4634 (123.7683)	mem 14369MB
[2022-12-20 17:37:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8684 (0.8843)	loss 2.4557 (3.1057)	grad_norm 79.4055 (121.1110)	mem 14369MB
[2022-12-20 17:37:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8664 (0.8826)	loss 2.8692 (3.0832)	grad_norm 232.7716 (123.2646)	mem 14369MB
[2022-12-20 17:38:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [223/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8846 (0.8807)	loss 2.7670 (3.2097)	grad_norm 96.6846 (124.5385)	mem 14369MB
[2022-12-20 17:38:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 223 training takes 0:01:05
[2022-12-20 17:38:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5100 (1.5100)	loss 3.5205 (3.5205)	grad_norm 137.9299 (137.9299)	mem 14369MB
[2022-12-20 17:38:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8892 (0.9338)	loss 4.1466 (3.3386)	grad_norm 257.9697 (171.5207)	mem 14369MB
[2022-12-20 17:38:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8749 (0.9041)	loss 2.9891 (3.1911)	grad_norm 65.1160 (143.7275)	mem 14369MB
[2022-12-20 17:38:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8741 (0.8930)	loss 3.0280 (3.1399)	grad_norm 71.9828 (133.6504)	mem 14369MB
[2022-12-20 17:38:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8634 (0.8878)	loss 2.7956 (3.0676)	grad_norm 100.9612 (129.3892)	mem 14369MB
[2022-12-20 17:38:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8865 (0.8848)	loss 3.0846 (3.0774)	grad_norm 98.0533 (124.4372)	mem 14369MB
[2022-12-20 17:38:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8684 (0.8839)	loss 3.1042 (3.2208)	grad_norm 183.6027 (124.8081)	mem 14369MB
[2022-12-20 17:39:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [224/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8850 (0.8828)	loss 2.5665 (3.2493)	grad_norm 112.0546 (129.5762)	mem 14369MB
[2022-12-20 17:39:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 224 training takes 0:01:05
[2022-12-20 17:39:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5354 (1.5354)	loss 5.7675 (5.7675)	grad_norm 307.9905 (307.9905)	mem 14369MB
[2022-12-20 17:39:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8733 (0.9303)	loss 3.0593 (3.4310)	grad_norm 123.5451 (139.2117)	mem 14369MB
[2022-12-20 17:39:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8668 (0.9011)	loss 3.1307 (3.5599)	grad_norm 60.1226 (123.2826)	mem 14369MB
[2022-12-20 17:39:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8726 (0.8937)	loss 2.8572 (3.4620)	grad_norm 104.9688 (120.7012)	mem 14369MB
[2022-12-20 17:39:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8841 (0.8889)	loss 2.3695 (3.3925)	grad_norm 68.2977 (125.5521)	mem 14369MB
[2022-12-20 17:39:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8788 (0.8859)	loss 3.1916 (3.3712)	grad_norm 127.7418 (128.9373)	mem 14369MB
[2022-12-20 17:40:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8757 (0.8836)	loss 2.7226 (3.3368)	grad_norm 70.4168 (131.8816)	mem 14369MB
[2022-12-20 17:40:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [225/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8697 (0.8821)	loss 3.5106 (3.3064)	grad_norm 99.6201 (131.8799)	mem 14369MB
[2022-12-20 17:40:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 225 training takes 0:01:05
[2022-12-20 17:40:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5182 (1.5182)	loss 2.4880 (2.4880)	grad_norm 136.0582 (136.0582)	mem 14369MB
[2022-12-20 17:40:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8703 (0.9375)	loss 2.1951 (2.8241)	grad_norm 138.7885 (125.2468)	mem 14369MB
[2022-12-20 17:40:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][20/74]	eta 0:00:49 lr 0.000001	time 0.8799 (0.9089)	loss 3.6737 (2.9399)	grad_norm 63.8661 (124.0366)	mem 14369MB
[2022-12-20 17:40:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8788 (0.8990)	loss 3.5811 (3.1795)	grad_norm 54.4355 (129.7612)	mem 14369MB
[2022-12-20 17:40:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8851 (0.8940)	loss 3.4270 (3.3356)	grad_norm 85.9855 (132.1467)	mem 14369MB
[2022-12-20 17:41:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8690 (0.8898)	loss 4.0035 (3.2961)	grad_norm 114.2122 (131.4931)	mem 14369MB
[2022-12-20 17:41:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8745 (0.8866)	loss 4.2338 (3.3542)	grad_norm 159.7896 (127.8416)	mem 14369MB
[2022-12-20 17:41:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [226/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8711 (0.8850)	loss 3.0298 (3.2692)	grad_norm 118.8365 (126.0577)	mem 14369MB
[2022-12-20 17:41:19 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 226 training takes 0:01:05
[2022-12-20 17:41:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5221 (1.5221)	loss 2.7439 (2.7439)	grad_norm 70.9319 (70.9319)	mem 14369MB
[2022-12-20 17:41:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8620 (0.9271)	loss 2.6399 (3.2850)	grad_norm 269.4410 (127.3303)	mem 14369MB
[2022-12-20 17:41:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8693 (0.8995)	loss 2.6366 (3.4848)	grad_norm 100.1542 (112.3229)	mem 14369MB
[2022-12-20 17:41:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8651 (0.8918)	loss 2.3983 (3.3480)	grad_norm 177.2687 (116.9375)	mem 14369MB
[2022-12-20 17:41:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8691 (0.8883)	loss 2.9853 (3.3045)	grad_norm 162.5921 (123.8263)	mem 14369MB
[2022-12-20 17:42:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8772 (0.8857)	loss 2.7415 (3.2364)	grad_norm 64.8547 (121.9004)	mem 14369MB
[2022-12-20 17:42:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8697 (0.8841)	loss 2.6048 (3.1866)	grad_norm 176.4467 (122.7678)	mem 14369MB
[2022-12-20 17:42:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [227/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8680 (0.8819)	loss 2.6764 (3.2161)	grad_norm 96.6904 (125.3788)	mem 14369MB
[2022-12-20 17:42:25 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 227 training takes 0:01:05
[2022-12-20 17:42:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5132 (1.5132)	loss 2.4834 (2.4834)	grad_norm 135.2371 (135.2371)	mem 14369MB
[2022-12-20 17:42:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8746 (0.9336)	loss 3.7980 (3.3268)	grad_norm 76.9375 (132.7262)	mem 14369MB
[2022-12-20 17:42:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8690 (0.9067)	loss 3.3073 (3.3103)	grad_norm 234.4091 (128.2569)	mem 14369MB
[2022-12-20 17:42:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8742 (0.8953)	loss 5.0029 (3.3655)	grad_norm 208.2819 (137.8941)	mem 14369MB
[2022-12-20 17:43:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8674 (0.8900)	loss 2.2393 (3.3337)	grad_norm 101.0913 (134.9548)	mem 14369MB
[2022-12-20 17:43:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8668 (0.8865)	loss 3.5513 (3.2732)	grad_norm 65.6896 (129.7881)	mem 14369MB
[2022-12-20 17:43:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8660 (0.8846)	loss 2.7579 (3.2276)	grad_norm 128.6470 (129.6996)	mem 14369MB
[2022-12-20 17:43:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [228/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8701 (0.8827)	loss 2.4355 (3.2475)	grad_norm 98.5904 (130.3518)	mem 14369MB
[2022-12-20 17:43:30 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 228 training takes 0:01:05
[2022-12-20 17:43:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5002 (1.5002)	loss 2.9276 (2.9276)	grad_norm 112.3614 (112.3614)	mem 14369MB
[2022-12-20 17:43:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8864 (0.9282)	loss 4.3589 (3.1382)	grad_norm 130.3861 (121.6609)	mem 14369MB
[2022-12-20 17:43:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8685 (0.9028)	loss 3.1806 (3.4215)	grad_norm 176.7743 (119.5561)	mem 14369MB
[2022-12-20 17:43:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8629 (0.8917)	loss 6.0351 (3.5531)	grad_norm 306.5626 (126.8513)	mem 14369MB
[2022-12-20 17:44:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8745 (0.8874)	loss 3.9150 (3.3964)	grad_norm 132.4853 (136.3393)	mem 14369MB
[2022-12-20 17:44:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8861 (0.8847)	loss 2.3750 (3.3084)	grad_norm 143.3397 (133.3924)	mem 14369MB
[2022-12-20 17:44:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8709 (0.8833)	loss 3.2823 (3.2806)	grad_norm 65.5813 (128.1587)	mem 14369MB
[2022-12-20 17:44:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [229/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8693 (0.8817)	loss 2.3916 (3.2233)	grad_norm 178.9067 (127.3108)	mem 14369MB
[2022-12-20 17:44:35 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 229 training takes 0:01:05
[2022-12-20 17:44:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5287 (1.5287)	loss 3.8918 (3.8918)	grad_norm 119.3916 (119.3916)	mem 14369MB
[2022-12-20 17:44:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8809 (0.9363)	loss 2.9369 (3.0665)	grad_norm 56.6070 (135.1383)	mem 14369MB
[2022-12-20 17:44:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][20/74]	eta 0:00:49 lr 0.000001	time 0.8886 (0.9090)	loss 4.4336 (3.1968)	grad_norm 274.0487 (127.9425)	mem 14369MB
[2022-12-20 17:45:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8727 (0.8958)	loss 8.8479 (3.3594)	grad_norm 160.2017 (135.4896)	mem 14369MB
[2022-12-20 17:45:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8807 (0.8900)	loss 4.6381 (3.2944)	grad_norm 325.8140 (143.6117)	mem 14369MB
[2022-12-20 17:45:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8710 (0.8866)	loss 2.8026 (3.2580)	grad_norm 149.5960 (137.1996)	mem 14369MB
[2022-12-20 17:45:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8677 (0.8851)	loss 2.6925 (3.2067)	grad_norm 127.9293 (133.8510)	mem 14369MB
[2022-12-20 17:45:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [230/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8687 (0.8834)	loss 7.1441 (3.2158)	grad_norm 301.5596 (133.5841)	mem 14369MB
[2022-12-20 17:45:40 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 230 training takes 0:01:05
[2022-12-20 17:45:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5374 (1.5374)	loss 3.0421 (3.0421)	grad_norm 150.4336 (150.4336)	mem 14369MB
[2022-12-20 17:45:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8673 (0.9344)	loss 2.9627 (3.0947)	grad_norm 174.8737 (143.1204)	mem 14369MB
[2022-12-20 17:45:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8621 (0.9038)	loss 2.8112 (3.1050)	grad_norm 166.7877 (135.9474)	mem 14369MB
[2022-12-20 17:46:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8693 (0.8937)	loss 3.8320 (3.3055)	grad_norm 47.4924 (124.1780)	mem 14369MB
[2022-12-20 17:46:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8872 (0.8891)	loss 2.3883 (3.1933)	grad_norm 94.0899 (125.6258)	mem 14369MB
[2022-12-20 17:46:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8798 (0.8855)	loss 2.4918 (3.1564)	grad_norm 113.3815 (121.0624)	mem 14369MB
[2022-12-20 17:46:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8747 (0.8831)	loss 3.5349 (3.2878)	grad_norm 72.1585 (127.1714)	mem 14369MB
[2022-12-20 17:46:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [231/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8728 (0.8820)	loss 2.5831 (3.2414)	grad_norm 73.5273 (125.7118)	mem 14369MB
[2022-12-20 17:46:45 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 231 training takes 0:01:05
[2022-12-20 17:46:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5300 (1.5300)	loss 2.9740 (2.9740)	grad_norm 122.5932 (122.5932)	mem 14369MB
[2022-12-20 17:46:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8626 (0.9313)	loss 2.8149 (3.1862)	grad_norm 89.3021 (118.0139)	mem 14369MB
[2022-12-20 17:47:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8727 (0.9028)	loss 3.0131 (3.0680)	grad_norm 111.9380 (121.9438)	mem 14369MB
[2022-12-20 17:47:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8665 (0.8936)	loss 2.0434 (3.1334)	grad_norm 82.7522 (119.8885)	mem 14369MB
[2022-12-20 17:47:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8727 (0.8886)	loss 2.9806 (3.1582)	grad_norm 83.4795 (118.4412)	mem 14369MB
[2022-12-20 17:47:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8841 (0.8867)	loss 2.8933 (3.0924)	grad_norm 102.5351 (111.8848)	mem 14369MB
[2022-12-20 17:47:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8739 (0.8845)	loss 5.1820 (3.1295)	grad_norm 80.8946 (109.0991)	mem 14369MB
[2022-12-20 17:47:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [232/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8801 (0.8835)	loss 4.6986 (3.1545)	grad_norm 102.9858 (109.3016)	mem 14369MB
[2022-12-20 17:47:51 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 232 training takes 0:01:05
[2022-12-20 17:47:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5220 (1.5220)	loss 4.7509 (4.7509)	grad_norm 140.7862 (140.7862)	mem 14369MB
[2022-12-20 17:48:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8669 (0.9367)	loss 2.5423 (3.0460)	grad_norm 148.9560 (129.9397)	mem 14369MB
[2022-12-20 17:48:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8881 (0.9059)	loss 3.6080 (3.3760)	grad_norm 199.5930 (132.3760)	mem 14369MB
[2022-12-20 17:48:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8720 (0.8960)	loss 2.8924 (3.2022)	grad_norm 123.1212 (125.0076)	mem 14369MB
[2022-12-20 17:48:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8705 (0.8913)	loss 2.9403 (3.1599)	grad_norm 125.0528 (127.0820)	mem 14369MB
[2022-12-20 17:48:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8692 (0.8881)	loss 2.7476 (3.2379)	grad_norm 126.7336 (128.8165)	mem 14369MB
[2022-12-20 17:48:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8678 (0.8862)	loss 3.1436 (3.2288)	grad_norm 145.2721 (127.0812)	mem 14369MB
[2022-12-20 17:48:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [233/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8704 (0.8841)	loss 3.0763 (3.2501)	grad_norm 99.7608 (129.8794)	mem 14369MB
[2022-12-20 17:48:56 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 233 training takes 0:01:05
[2022-12-20 17:48:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5064 (1.5064)	loss 2.7778 (2.7778)	grad_norm 97.1672 (97.1672)	mem 14369MB
[2022-12-20 17:49:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8662 (0.9321)	loss 3.1980 (3.1435)	grad_norm 119.6623 (123.0456)	mem 14369MB
[2022-12-20 17:49:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8753 (0.9017)	loss 2.4080 (3.3682)	grad_norm 67.1270 (134.8235)	mem 14369MB
[2022-12-20 17:49:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8698 (0.8919)	loss 2.5860 (3.2266)	grad_norm 184.0977 (126.0362)	mem 14369MB
[2022-12-20 17:49:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8737 (0.8875)	loss 3.7728 (3.2942)	grad_norm 127.6990 (130.7668)	mem 14369MB
[2022-12-20 17:49:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8743 (0.8852)	loss 2.7692 (3.2769)	grad_norm 116.3082 (128.6384)	mem 14369MB
[2022-12-20 17:49:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8775 (0.8830)	loss 3.4292 (3.2587)	grad_norm 180.4070 (130.0691)	mem 14369MB
[2022-12-20 17:49:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [234/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8696 (0.8828)	loss 2.5841 (3.2171)	grad_norm 189.1798 (131.2197)	mem 14369MB
[2022-12-20 17:50:01 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 234 training takes 0:01:05
[2022-12-20 17:50:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5323 (1.5323)	loss 4.8415 (4.8415)	grad_norm 163.5063 (163.5063)	mem 14369MB
[2022-12-20 17:50:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8874 (0.9336)	loss 3.1624 (3.5674)	grad_norm 124.0914 (101.7181)	mem 14369MB
[2022-12-20 17:50:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8706 (0.9049)	loss 2.3787 (3.3024)	grad_norm 92.2698 (110.8776)	mem 14369MB
[2022-12-20 17:50:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8650 (0.8944)	loss 2.7660 (3.2044)	grad_norm 95.0445 (120.8536)	mem 14369MB
[2022-12-20 17:50:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8678 (0.8891)	loss 2.6121 (3.3473)	grad_norm 133.6056 (128.4115)	mem 14369MB
[2022-12-20 17:50:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8725 (0.8859)	loss 4.4897 (3.3282)	grad_norm 103.9757 (128.3958)	mem 14369MB
[2022-12-20 17:50:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8769 (0.8851)	loss 3.0883 (3.2585)	grad_norm 179.9170 (130.7714)	mem 14369MB
[2022-12-20 17:51:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [235/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8731 (0.8834)	loss 2.9120 (3.2310)	grad_norm 102.2811 (130.6934)	mem 14369MB
[2022-12-20 17:51:07 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 235 training takes 0:01:05
[2022-12-20 17:51:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5234 (1.5234)	loss 3.2073 (3.2073)	grad_norm 166.5752 (166.5752)	mem 14369MB
[2022-12-20 17:51:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][10/74]	eta 0:01:00 lr 0.000001	time 0.8715 (0.9383)	loss 3.1379 (3.0652)	grad_norm 98.9888 (131.0310)	mem 14369MB
[2022-12-20 17:51:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][20/74]	eta 0:00:49 lr 0.000001	time 0.8775 (0.9099)	loss 5.8168 (3.2642)	grad_norm 81.5104 (121.0717)	mem 14369MB
[2022-12-20 17:51:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8806 (0.9000)	loss 2.1092 (3.2556)	grad_norm 238.0368 (127.3806)	mem 14369MB
[2022-12-20 17:51:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8662 (0.8938)	loss 2.5777 (3.2058)	grad_norm 95.4302 (122.4366)	mem 14369MB
[2022-12-20 17:51:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8654 (0.8892)	loss 3.0478 (3.2066)	grad_norm 70.3373 (125.9893)	mem 14369MB
[2022-12-20 17:52:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8754 (0.8860)	loss 3.6961 (3.1890)	grad_norm 86.8562 (127.7207)	mem 14369MB
[2022-12-20 17:52:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [236/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8810 (0.8844)	loss 3.5833 (3.2097)	grad_norm 91.9255 (125.3477)	mem 14369MB
[2022-12-20 17:52:12 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 236 training takes 0:01:05
[2022-12-20 17:52:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5212 (1.5212)	loss 3.2323 (3.2323)	grad_norm 85.1901 (85.1901)	mem 14369MB
[2022-12-20 17:52:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8852 (0.9319)	loss 2.6262 (3.3966)	grad_norm 97.7714 (118.7898)	mem 14369MB
[2022-12-20 17:52:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8758 (0.9030)	loss 2.4617 (3.1267)	grad_norm 73.7628 (115.4732)	mem 14369MB
[2022-12-20 17:52:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8743 (0.8935)	loss 3.3762 (3.1591)	grad_norm 116.1471 (114.0994)	mem 14369MB
[2022-12-20 17:52:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8698 (0.8888)	loss 3.0399 (3.1996)	grad_norm 177.3648 (114.3411)	mem 14369MB
[2022-12-20 17:52:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8697 (0.8852)	loss 2.6584 (3.1615)	grad_norm 112.1758 (117.3110)	mem 14369MB
[2022-12-20 17:53:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8653 (0.8824)	loss 2.1686 (3.1800)	grad_norm 196.2416 (126.3539)	mem 14369MB
[2022-12-20 17:53:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [237/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8679 (0.8809)	loss 2.3872 (3.1746)	grad_norm 70.7502 (123.4266)	mem 14369MB
[2022-12-20 17:53:17 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 237 training takes 0:01:05
[2022-12-20 17:53:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5207 (1.5207)	loss 3.5741 (3.5741)	grad_norm 129.9412 (129.9412)	mem 14369MB
[2022-12-20 17:53:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8641 (0.9248)	loss 2.2506 (3.2859)	grad_norm 94.3875 (140.4053)	mem 14369MB
[2022-12-20 17:53:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8835 (0.8999)	loss 5.3052 (3.2339)	grad_norm 186.2655 (140.2156)	mem 14369MB
[2022-12-20 17:53:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8684 (0.8920)	loss 3.1965 (3.1901)	grad_norm 258.2998 (136.4007)	mem 14369MB
[2022-12-20 17:53:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8779 (0.8895)	loss 2.3141 (3.1195)	grad_norm 87.1545 (137.4858)	mem 14369MB
[2022-12-20 17:54:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8729 (0.8864)	loss 3.8305 (3.1592)	grad_norm 163.7314 (136.2010)	mem 14369MB
[2022-12-20 17:54:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8699 (0.8844)	loss 2.6722 (3.1899)	grad_norm 114.2157 (133.3879)	mem 14369MB
[2022-12-20 17:54:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [238/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8699 (0.8828)	loss 2.8534 (3.1408)	grad_norm 124.5819 (131.0294)	mem 14369MB
[2022-12-20 17:54:22 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 238 training takes 0:01:05
[2022-12-20 17:54:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5191 (1.5191)	loss 2.8704 (2.8704)	grad_norm 173.1896 (173.1896)	mem 14369MB
[2022-12-20 17:54:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8732 (0.9368)	loss 3.1515 (3.0241)	grad_norm 194.4531 (120.8449)	mem 14369MB
[2022-12-20 17:54:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][20/74]	eta 0:00:49 lr 0.000001	time 0.8691 (0.9095)	loss 3.1735 (3.2338)	grad_norm 106.9444 (119.4326)	mem 14369MB
[2022-12-20 17:54:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8817 (0.9001)	loss 3.3870 (3.3048)	grad_norm 80.4450 (115.7351)	mem 14369MB
[2022-12-20 17:54:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8754 (0.8931)	loss 2.7173 (3.2230)	grad_norm 95.5467 (124.8355)	mem 14369MB
[2022-12-20 17:55:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8778 (0.8891)	loss 3.2576 (3.2622)	grad_norm 116.1972 (124.2361)	mem 14369MB
[2022-12-20 17:55:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8716 (0.8863)	loss 2.6840 (3.2237)	grad_norm 117.8388 (119.5986)	mem 14369MB
[2022-12-20 17:55:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [239/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8696 (0.8840)	loss 3.2970 (3.2264)	grad_norm 127.7700 (119.7596)	mem 14369MB
[2022-12-20 17:55:28 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 239 training takes 0:01:05
[2022-12-20 17:55:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5130 (1.5130)	loss 3.7720 (3.7720)	grad_norm 155.7439 (155.7439)	mem 14369MB
[2022-12-20 17:55:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8739 (0.9308)	loss 5.2216 (3.6832)	grad_norm 72.8106 (98.4534)	mem 14369MB
[2022-12-20 17:55:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8691 (0.9026)	loss 2.9234 (3.4282)	grad_norm 76.3800 (105.6227)	mem 14369MB
[2022-12-20 17:55:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8713 (0.8924)	loss 3.7577 (3.2529)	grad_norm 129.8485 (110.4541)	mem 14369MB
[2022-12-20 17:56:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8767 (0.8869)	loss 2.6182 (3.1712)	grad_norm 96.8942 (115.4793)	mem 14369MB
[2022-12-20 17:56:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8822 (0.8852)	loss 3.0504 (3.1864)	grad_norm 125.5686 (115.4136)	mem 14369MB
[2022-12-20 17:56:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8824 (0.8833)	loss 3.7334 (3.1844)	grad_norm 225.0237 (119.6393)	mem 14369MB
[2022-12-20 17:56:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [240/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8736 (0.8819)	loss 2.9041 (3.1451)	grad_norm 49.4097 (120.6933)	mem 14369MB
[2022-12-20 17:56:33 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 240 training takes 0:01:05
[2022-12-20 17:56:33 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_240.pth saving......
[2022-12-20 17:56:34 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_240.pth saved !!!
[2022-12-20 17:56:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5099 (1.5099)	loss 2.6488 (2.6488)	grad_norm 76.1020 (76.1020)	mem 14369MB
[2022-12-20 17:56:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8788 (0.9368)	loss 3.7695 (3.4575)	grad_norm 105.9385 (114.9924)	mem 14369MB
[2022-12-20 17:56:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][20/74]	eta 0:00:49 lr 0.000001	time 0.8774 (0.9099)	loss 3.2633 (3.3954)	grad_norm 192.4272 (125.4687)	mem 14369MB
[2022-12-20 17:57:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8696 (0.8995)	loss 3.3978 (3.3054)	grad_norm 108.4322 (118.4165)	mem 14369MB
[2022-12-20 17:57:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8771 (0.8933)	loss 2.7203 (3.1946)	grad_norm 173.9047 (123.6644)	mem 14369MB
[2022-12-20 17:57:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8752 (0.8905)	loss 3.3582 (3.2023)	grad_norm 224.5057 (127.6496)	mem 14369MB
[2022-12-20 17:57:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8611 (0.8870)	loss 4.2739 (3.2077)	grad_norm 232.6472 (125.8433)	mem 14369MB
[2022-12-20 17:57:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [241/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8659 (0.8848)	loss 2.9153 (3.2153)	grad_norm 114.4895 (127.9157)	mem 14369MB
[2022-12-20 17:57:39 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 241 training takes 0:01:05
[2022-12-20 17:57:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5109 (1.5109)	loss 3.9467 (3.9467)	grad_norm 121.4190 (121.4190)	mem 14369MB
[2022-12-20 17:57:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8764 (0.9228)	loss 3.6577 (3.4689)	grad_norm 107.2599 (129.9855)	mem 14369MB
[2022-12-20 17:57:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8643 (0.8977)	loss 2.8687 (3.1362)	grad_norm 54.1556 (118.1110)	mem 14369MB
[2022-12-20 17:58:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8666 (0.8888)	loss 2.6450 (3.1240)	grad_norm 66.3718 (113.0332)	mem 14369MB
[2022-12-20 17:58:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8720 (0.8868)	loss 2.4132 (3.1189)	grad_norm 136.6145 (113.8096)	mem 14369MB
[2022-12-20 17:58:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8681 (0.8852)	loss 2.6805 (3.1170)	grad_norm 170.9886 (112.2372)	mem 14369MB
[2022-12-20 17:58:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8632 (0.8831)	loss 2.0599 (3.1820)	grad_norm 143.7715 (122.5558)	mem 14369MB
[2022-12-20 17:58:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [242/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8691 (0.8817)	loss 2.2590 (3.1539)	grad_norm 163.2810 (122.8077)	mem 14369MB
[2022-12-20 17:58:44 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 242 training takes 0:01:05
[2022-12-20 17:58:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5235 (1.5235)	loss 3.3175 (3.3175)	grad_norm 150.2717 (150.2717)	mem 14369MB
[2022-12-20 17:58:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8896 (0.9313)	loss 3.8091 (3.4593)	grad_norm 203.4219 (129.8012)	mem 14369MB
[2022-12-20 17:59:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8763 (0.9017)	loss 3.7718 (3.3016)	grad_norm 90.1378 (112.5611)	mem 14369MB
[2022-12-20 17:59:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8650 (0.8903)	loss 4.0247 (3.2556)	grad_norm 129.4621 (116.8594)	mem 14369MB
[2022-12-20 17:59:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8676 (0.8848)	loss 3.1839 (3.3159)	grad_norm 133.1042 (114.9311)	mem 14369MB
[2022-12-20 17:59:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8685 (0.8824)	loss 2.3794 (3.2811)	grad_norm 123.7729 (114.3568)	mem 14369MB
[2022-12-20 17:59:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8970 (0.8820)	loss 2.9553 (3.2513)	grad_norm 89.7774 (118.1648)	mem 14369MB
[2022-12-20 17:59:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [243/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8729 (0.8813)	loss 3.4331 (3.1728)	grad_norm 120.4302 (117.6855)	mem 14369MB
[2022-12-20 17:59:50 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 243 training takes 0:01:05
[2022-12-20 17:59:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5181 (1.5181)	loss 2.4337 (2.4337)	grad_norm 138.7301 (138.7301)	mem 14369MB
[2022-12-20 18:00:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8757 (0.9345)	loss 3.1242 (3.3460)	grad_norm 96.0075 (116.6925)	mem 14369MB
[2022-12-20 18:00:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8787 (0.9062)	loss 3.4763 (3.2217)	grad_norm 121.2100 (112.3620)	mem 14369MB
[2022-12-20 18:00:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8813 (0.8956)	loss 3.9044 (3.3228)	grad_norm 127.9307 (136.6912)	mem 14369MB
[2022-12-20 18:00:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8680 (0.8897)	loss 2.7404 (3.1900)	grad_norm 101.6662 (132.0191)	mem 14369MB
[2022-12-20 18:00:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8759 (0.8865)	loss 3.0176 (3.2148)	grad_norm 97.3733 (128.4893)	mem 14369MB
[2022-12-20 18:00:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8646 (0.8849)	loss 2.1249 (3.1872)	grad_norm 71.9672 (131.2809)	mem 14369MB
[2022-12-20 18:00:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [244/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8835 (0.8836)	loss 2.4363 (3.1622)	grad_norm 79.4676 (132.2140)	mem 14369MB
[2022-12-20 18:00:55 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 244 training takes 0:01:05
[2022-12-20 18:00:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5202 (1.5202)	loss 3.3648 (3.3648)	grad_norm 169.9450 (169.9450)	mem 14369MB
[2022-12-20 18:01:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8810 (0.9307)	loss 2.6692 (3.0582)	grad_norm 95.3654 (123.9670)	mem 14369MB
[2022-12-20 18:01:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8658 (0.9015)	loss 2.3973 (2.9158)	grad_norm 109.0123 (125.2869)	mem 14369MB
[2022-12-20 18:01:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8618 (0.8907)	loss 2.9924 (2.9795)	grad_norm 192.2599 (121.3094)	mem 14369MB
[2022-12-20 18:01:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8699 (0.8859)	loss 3.0943 (3.0542)	grad_norm 114.7546 (122.3709)	mem 14369MB
[2022-12-20 18:01:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8753 (0.8835)	loss 2.7285 (3.1675)	grad_norm 68.5057 (122.4371)	mem 14369MB
[2022-12-20 18:01:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8759 (0.8815)	loss 2.5743 (3.0915)	grad_norm 107.9729 (121.1114)	mem 14369MB
[2022-12-20 18:01:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [245/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8800 (0.8802)	loss 3.3626 (3.1553)	grad_norm 112.3299 (120.1348)	mem 14369MB
[2022-12-20 18:02:00 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 245 training takes 0:01:04
[2022-12-20 18:02:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5314 (1.5314)	loss 3.0644 (3.0644)	grad_norm 183.3094 (183.3094)	mem 14369MB
[2022-12-20 18:02:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8682 (0.9307)	loss 3.0154 (3.0067)	grad_norm 94.3803 (119.5172)	mem 14369MB
[2022-12-20 18:02:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8706 (0.9014)	loss 3.4464 (3.5217)	grad_norm 164.8759 (125.0585)	mem 14369MB
[2022-12-20 18:02:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8751 (0.8921)	loss 2.9815 (3.3316)	grad_norm 127.8289 (124.0143)	mem 14369MB
[2022-12-20 18:02:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8695 (0.8885)	loss 2.6688 (3.2304)	grad_norm 154.5474 (122.6458)	mem 14369MB
[2022-12-20 18:02:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8727 (0.8953)	loss 3.8575 (3.2340)	grad_norm 90.4659 (124.3896)	mem 14369MB
[2022-12-20 18:02:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8747 (0.8920)	loss 2.6955 (3.2425)	grad_norm 101.2570 (123.4714)	mem 14369MB
[2022-12-20 18:03:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [246/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8770 (0.8901)	loss 3.6218 (3.2096)	grad_norm 166.8599 (123.5174)	mem 14369MB
[2022-12-20 18:03:06 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 246 training takes 0:01:05
[2022-12-20 18:03:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5192 (1.5192)	loss 3.3050 (3.3050)	grad_norm 92.2894 (92.2894)	mem 14369MB
[2022-12-20 18:03:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8634 (0.9325)	loss 3.4726 (3.0058)	grad_norm 57.4458 (102.6769)	mem 14369MB
[2022-12-20 18:03:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8889 (0.9014)	loss 3.2749 (3.1095)	grad_norm 67.1111 (105.4851)	mem 14369MB
[2022-12-20 18:03:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8559 (0.8909)	loss 3.1250 (3.0457)	grad_norm 149.0458 (112.9874)	mem 14369MB
[2022-12-20 18:03:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8891 (0.8879)	loss 2.6595 (3.1518)	grad_norm 110.1104 (115.8033)	mem 14369MB
[2022-12-20 18:03:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8660 (0.8843)	loss 6.0932 (3.2241)	grad_norm 107.2049 (113.2438)	mem 14369MB
[2022-12-20 18:03:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8827 (0.8825)	loss 2.3199 (3.2282)	grad_norm 111.2794 (115.9893)	mem 14369MB
[2022-12-20 18:04:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [247/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8639 (0.8805)	loss 2.5202 (3.1856)	grad_norm 89.3223 (114.5841)	mem 14369MB
[2022-12-20 18:04:11 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 247 training takes 0:01:05
[2022-12-20 18:04:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5214 (1.5214)	loss 3.2635 (3.2635)	grad_norm 83.0957 (83.0957)	mem 14369MB
[2022-12-20 18:04:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8834 (0.9336)	loss 3.9271 (3.1896)	grad_norm 109.4305 (118.9066)	mem 14369MB
[2022-12-20 18:04:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8759 (0.9057)	loss 2.6868 (3.1959)	grad_norm 73.3451 (113.7334)	mem 14369MB
[2022-12-20 18:04:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8714 (0.8948)	loss 3.0126 (3.0712)	grad_norm 128.9802 (117.2397)	mem 14369MB
[2022-12-20 18:04:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8817 (0.8901)	loss 3.4734 (3.0902)	grad_norm 67.9486 (113.5456)	mem 14369MB
[2022-12-20 18:04:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8741 (0.8872)	loss 2.5642 (3.0905)	grad_norm 158.7391 (114.1598)	mem 14369MB
[2022-12-20 18:05:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8852 (0.8855)	loss 2.5631 (3.0849)	grad_norm 56.4281 (117.0789)	mem 14369MB
[2022-12-20 18:05:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [248/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8787 (0.8851)	loss 3.1500 (3.1503)	grad_norm 172.2694 (119.7241)	mem 14369MB
[2022-12-20 18:05:16 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 248 training takes 0:01:05
[2022-12-20 18:05:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][0/74]	eta 0:01:51 lr 0.000001	time 1.5086 (1.5086)	loss 2.4253 (2.4253)	grad_norm 110.0818 (110.0818)	mem 14369MB
[2022-12-20 18:05:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8680 (0.9287)	loss 2.8258 (3.1214)	grad_norm 100.0261 (111.7681)	mem 14369MB
[2022-12-20 18:05:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8644 (0.9008)	loss 2.8238 (3.0997)	grad_norm 238.0904 (128.5496)	mem 14369MB
[2022-12-20 18:05:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8756 (0.8942)	loss 2.6534 (3.1442)	grad_norm 80.1174 (123.7327)	mem 14369MB
[2022-12-20 18:05:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8744 (0.8896)	loss 3.2603 (3.1363)	grad_norm 135.0491 (123.0923)	mem 14369MB
[2022-12-20 18:06:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8789 (0.8890)	loss 2.6610 (3.1614)	grad_norm 117.0101 (118.2453)	mem 14369MB
[2022-12-20 18:06:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8692 (0.8860)	loss 3.1259 (3.1432)	grad_norm 117.7117 (115.0015)	mem 14369MB
[2022-12-20 18:06:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [249/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8664 (0.8842)	loss 2.6188 (3.1930)	grad_norm 106.7030 (116.1453)	mem 14369MB
[2022-12-20 18:06:21 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 249 training takes 0:01:05
[2022-12-20 18:06:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][0/74]	eta 0:01:52 lr 0.000001	time 1.5149 (1.5149)	loss 3.7287 (3.7287)	grad_norm 126.0767 (126.0767)	mem 14369MB
[2022-12-20 18:06:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8718 (0.9272)	loss 3.9916 (3.2040)	grad_norm 172.9324 (133.2502)	mem 14369MB
[2022-12-20 18:06:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][20/74]	eta 0:00:48 lr 0.000001	time 0.8773 (0.9013)	loss 3.0585 (3.1081)	grad_norm 103.9340 (114.0090)	mem 14369MB
[2022-12-20 18:06:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][30/74]	eta 0:00:39 lr 0.000001	time 0.8698 (0.8920)	loss 3.5772 (3.3451)	grad_norm 96.5155 (115.5914)	mem 14369MB
[2022-12-20 18:06:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][40/74]	eta 0:00:30 lr 0.000001	time 0.8816 (0.8875)	loss 2.3545 (3.2902)	grad_norm 72.6445 (114.7625)	mem 14369MB
[2022-12-20 18:07:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][50/74]	eta 0:00:21 lr 0.000001	time 0.8638 (0.8839)	loss 2.6545 (3.2623)	grad_norm 203.3224 (119.9467)	mem 14369MB
[2022-12-20 18:07:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][60/74]	eta 0:00:12 lr 0.000001	time 0.8656 (0.8818)	loss 2.3304 (3.2687)	grad_norm 140.8048 (121.9696)	mem 14369MB
[2022-12-20 18:07:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [250/300][70/74]	eta 0:00:03 lr 0.000001	time 0.8806 (0.8814)	loss 2.9785 (3.2131)	grad_norm 118.8126 (120.8829)	mem 14369MB
[2022-12-20 18:07:27 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 250 training takes 0:01:05
[2022-12-20 18:07:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][0/74]	eta 0:01:53 lr 0.000001	time 1.5289 (1.5289)	loss 2.7749 (2.7749)	grad_norm 79.6304 (79.6304)	mem 14369MB
[2022-12-20 18:07:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][10/74]	eta 0:00:59 lr 0.000001	time 0.8791 (0.9308)	loss 2.6681 (3.4745)	grad_norm 101.2672 (128.2303)	mem 14369MB
[2022-12-20 18:07:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8845 (0.9049)	loss 3.1634 (3.2053)	grad_norm 104.4184 (115.4294)	mem 14369MB
[2022-12-20 18:07:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8815 (0.8962)	loss 3.3697 (3.1534)	grad_norm 89.9233 (110.4241)	mem 14369MB
[2022-12-20 18:08:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8745 (0.8917)	loss 2.3726 (3.1932)	grad_norm 109.1164 (109.3015)	mem 14369MB
[2022-12-20 18:08:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8743 (0.8879)	loss 6.6611 (3.2227)	grad_norm 162.0809 (110.6221)	mem 14369MB
[2022-12-20 18:08:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8733 (0.8855)	loss 2.8618 (3.1934)	grad_norm 106.7480 (112.3502)	mem 14369MB
[2022-12-20 18:08:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [251/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8756 (0.8842)	loss 3.0690 (3.1788)	grad_norm 95.8252 (111.2529)	mem 14369MB
[2022-12-20 18:08:32 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 251 training takes 0:01:05
[2022-12-20 18:08:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5077 (1.5077)	loss 2.4631 (2.4631)	grad_norm 233.8383 (233.8383)	mem 14369MB
[2022-12-20 18:08:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8849 (0.9353)	loss 2.5577 (2.9996)	grad_norm 70.3757 (111.8719)	mem 14369MB
[2022-12-20 18:08:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8695 (0.9056)	loss 3.1227 (3.0198)	grad_norm 75.6900 (107.1499)	mem 14369MB
[2022-12-20 18:09:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8661 (0.8972)	loss 3.0217 (3.0032)	grad_norm 136.7054 (103.9100)	mem 14369MB
[2022-12-20 18:09:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8668 (0.8915)	loss 2.7921 (3.0472)	grad_norm 94.9684 (107.9265)	mem 14369MB
[2022-12-20 18:09:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8668 (0.8870)	loss 3.7072 (3.1004)	grad_norm 250.0051 (114.9328)	mem 14369MB
[2022-12-20 18:09:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8763 (0.8845)	loss 5.1684 (3.1886)	grad_norm 51.9679 (118.1198)	mem 14369MB
[2022-12-20 18:09:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [252/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8802 (0.8839)	loss 3.7229 (3.1877)	grad_norm 117.4910 (119.3111)	mem 14369MB
[2022-12-20 18:09:37 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 252 training takes 0:01:05
[2022-12-20 18:09:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5094 (1.5094)	loss 2.9600 (2.9600)	grad_norm 143.0070 (143.0070)	mem 14369MB
[2022-12-20 18:09:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8593 (0.9282)	loss 2.6243 (3.3784)	grad_norm 289.2630 (164.0580)	mem 14369MB
[2022-12-20 18:09:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8707 (0.9018)	loss 3.4865 (3.4147)	grad_norm 123.5667 (144.2937)	mem 14369MB
[2022-12-20 18:10:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8708 (0.8927)	loss 2.7887 (3.2420)	grad_norm 168.8282 (138.5656)	mem 14369MB
[2022-12-20 18:10:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8881 (0.8897)	loss 3.2582 (3.2097)	grad_norm 81.6557 (129.7201)	mem 14369MB
[2022-12-20 18:10:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8745 (0.8877)	loss 2.9622 (3.1656)	grad_norm 84.9529 (123.5916)	mem 14369MB
[2022-12-20 18:10:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8758 (0.8862)	loss 3.3731 (3.1418)	grad_norm 132.1017 (123.6994)	mem 14369MB
[2022-12-20 18:10:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [253/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8807 (0.8844)	loss 3.1475 (3.1672)	grad_norm 87.9381 (124.6446)	mem 14369MB
[2022-12-20 18:10:42 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 253 training takes 0:01:05
[2022-12-20 18:10:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][0/74]	eta 0:01:50 lr 0.000000	time 1.4998 (1.4998)	loss 2.4173 (2.4173)	grad_norm 138.8121 (138.8121)	mem 14369MB
[2022-12-20 18:10:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8656 (0.9274)	loss 2.2264 (2.6936)	grad_norm 68.0690 (98.4904)	mem 14369MB
[2022-12-20 18:11:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8850 (0.9014)	loss 3.0266 (2.8478)	grad_norm 68.4552 (99.9522)	mem 14369MB
[2022-12-20 18:11:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8670 (0.8926)	loss 2.4423 (3.0367)	grad_norm 122.5184 (109.6289)	mem 14369MB
[2022-12-20 18:11:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8702 (0.8875)	loss 2.9970 (3.1175)	grad_norm 95.8572 (117.2601)	mem 14369MB
[2022-12-20 18:11:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8815 (0.8847)	loss 2.4542 (3.1777)	grad_norm 136.7614 (118.6766)	mem 14369MB
[2022-12-20 18:11:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8859 (0.8823)	loss 3.2993 (3.1042)	grad_norm 104.7698 (122.5657)	mem 14369MB
[2022-12-20 18:11:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [254/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8672 (0.8806)	loss 2.9605 (3.1506)	grad_norm 157.3073 (123.7515)	mem 14369MB
[2022-12-20 18:11:48 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 254 training takes 0:01:05
[2022-12-20 18:11:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][0/74]	eta 0:01:53 lr 0.000000	time 1.5310 (1.5310)	loss 3.0463 (3.0463)	grad_norm 111.6387 (111.6387)	mem 14369MB
[2022-12-20 18:11:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][10/74]	eta 0:01:00 lr 0.000000	time 0.8793 (0.9403)	loss 2.8665 (3.1144)	grad_norm 78.6643 (117.5178)	mem 14369MB
[2022-12-20 18:12:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][20/74]	eta 0:00:49 lr 0.000000	time 0.8751 (0.9079)	loss 2.6870 (3.0651)	grad_norm 130.1677 (116.4428)	mem 14369MB
[2022-12-20 18:12:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8760 (0.8965)	loss 2.8105 (3.1756)	grad_norm 87.5885 (125.5632)	mem 14369MB
[2022-12-20 18:12:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8880 (0.8939)	loss 3.1565 (3.2389)	grad_norm 88.1193 (125.2172)	mem 14369MB
[2022-12-20 18:12:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8785 (0.8962)	loss 3.1059 (3.2407)	grad_norm 137.6243 (128.4921)	mem 14369MB
[2022-12-20 18:12:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8781 (0.8927)	loss 3.4687 (3.2181)	grad_norm 89.9586 (121.2000)	mem 14369MB
[2022-12-20 18:12:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [255/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8859 (0.8902)	loss 3.1115 (3.2516)	grad_norm 103.8011 (121.7834)	mem 14369MB
[2022-12-20 18:12:53 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 255 training takes 0:01:05
[2022-12-20 18:12:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5200 (1.5200)	loss 2.6473 (2.6473)	grad_norm 85.7800 (85.7800)	mem 14369MB
[2022-12-20 18:13:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8734 (0.9336)	loss 2.5026 (3.2187)	grad_norm 75.5884 (112.8206)	mem 14369MB
[2022-12-20 18:13:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][20/74]	eta 0:00:49 lr 0.000000	time 0.8893 (0.9084)	loss 3.4429 (3.3619)	grad_norm 128.4017 (113.3506)	mem 14369MB
[2022-12-20 18:13:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8771 (0.8972)	loss 2.7431 (3.4440)	grad_norm 66.8856 (106.6826)	mem 14369MB
[2022-12-20 18:13:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8744 (0.8925)	loss 3.1778 (3.3218)	grad_norm 166.4704 (110.0753)	mem 14369MB
[2022-12-20 18:13:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8683 (0.8892)	loss 2.7355 (3.2574)	grad_norm 101.3590 (108.7079)	mem 14369MB
[2022-12-20 18:13:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8665 (0.8866)	loss 2.8510 (3.2302)	grad_norm 155.9948 (113.0726)	mem 14369MB
[2022-12-20 18:13:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [256/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8691 (0.8846)	loss 2.4712 (3.2529)	grad_norm 94.6707 (112.0241)	mem 14369MB
[2022-12-20 18:13:59 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 256 training takes 0:01:05
[2022-12-20 18:14:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5173 (1.5173)	loss 2.7482 (2.7482)	grad_norm 121.2539 (121.2539)	mem 14369MB
[2022-12-20 18:14:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8706 (0.9302)	loss 4.2981 (3.4026)	grad_norm 177.0814 (128.9719)	mem 14369MB
[2022-12-20 18:14:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8640 (0.9027)	loss 3.1688 (3.3977)	grad_norm 130.8416 (119.3061)	mem 14369MB
[2022-12-20 18:14:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8639 (0.8918)	loss 3.3642 (3.3069)	grad_norm 131.2093 (113.5779)	mem 14369MB
[2022-12-20 18:14:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8684 (0.8872)	loss 3.0192 (3.2606)	grad_norm 146.1286 (111.2305)	mem 14369MB
[2022-12-20 18:14:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8874 (0.8838)	loss 2.4310 (3.2590)	grad_norm 80.9918 (111.3555)	mem 14369MB
[2022-12-20 18:14:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8833 (0.8825)	loss 2.7664 (3.1894)	grad_norm 107.9698 (109.0047)	mem 14369MB
[2022-12-20 18:15:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [257/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8669 (0.8817)	loss 2.1584 (3.1706)	grad_norm 92.4326 (109.7214)	mem 14369MB
[2022-12-20 18:15:04 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 257 training takes 0:01:05
[2022-12-20 18:15:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5150 (1.5150)	loss 3.0044 (3.0044)	grad_norm 157.8583 (157.8583)	mem 14369MB
[2022-12-20 18:15:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8616 (0.9266)	loss 3.3096 (3.2743)	grad_norm 145.7342 (129.9391)	mem 14369MB
[2022-12-20 18:15:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8794 (0.9038)	loss 3.1640 (3.5425)	grad_norm 101.7612 (119.2068)	mem 14369MB
[2022-12-20 18:15:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8636 (0.8947)	loss 2.3486 (3.3941)	grad_norm 107.6577 (116.2678)	mem 14369MB
[2022-12-20 18:15:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8841 (0.8889)	loss 2.4392 (3.2287)	grad_norm 112.1360 (115.7338)	mem 14369MB
[2022-12-20 18:15:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8770 (0.8870)	loss 2.8831 (3.2185)	grad_norm 107.2715 (116.2243)	mem 14369MB
[2022-12-20 18:15:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8815 (0.8853)	loss 3.8173 (3.2157)	grad_norm 97.3803 (116.5439)	mem 14369MB
[2022-12-20 18:16:07 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [258/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8715 (0.8837)	loss 3.1982 (3.1561)	grad_norm 86.6531 (117.3723)	mem 14369MB
[2022-12-20 18:16:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 258 training takes 0:01:05
[2022-12-20 18:16:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][0/74]	eta 0:01:53 lr 0.000000	time 1.5321 (1.5321)	loss 3.1164 (3.1164)	grad_norm 166.8679 (166.8679)	mem 14369MB
[2022-12-20 18:16:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8860 (0.9319)	loss 2.5367 (3.1474)	grad_norm 60.8004 (116.7891)	mem 14369MB
[2022-12-20 18:16:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8856 (0.9043)	loss 3.7380 (3.2722)	grad_norm 204.6718 (129.5682)	mem 14369MB
[2022-12-20 18:16:37 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8782 (0.8943)	loss 2.7095 (3.1839)	grad_norm 131.9155 (129.5114)	mem 14369MB
[2022-12-20 18:16:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8674 (0.8883)	loss 2.8618 (3.1600)	grad_norm 173.2553 (125.7205)	mem 14369MB
[2022-12-20 18:16:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8648 (0.8845)	loss 2.9176 (3.1981)	grad_norm 101.6160 (121.1515)	mem 14369MB
[2022-12-20 18:17:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8771 (0.8824)	loss 2.9021 (3.2075)	grad_norm 93.9377 (123.7533)	mem 14369MB
[2022-12-20 18:17:12 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [259/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8693 (0.8811)	loss 3.9640 (3.2505)	grad_norm 86.9627 (123.0977)	mem 14369MB
[2022-12-20 18:17:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 259 training takes 0:01:05
[2022-12-20 18:17:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5094 (1.5094)	loss 3.2660 (3.2660)	grad_norm 61.6235 (61.6235)	mem 14369MB
[2022-12-20 18:17:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8674 (0.9303)	loss 3.3088 (3.2768)	grad_norm 61.6581 (92.8583)	mem 14369MB
[2022-12-20 18:17:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8696 (0.9001)	loss 4.0852 (3.2284)	grad_norm 83.2708 (111.4225)	mem 14369MB
[2022-12-20 18:17:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8742 (0.8918)	loss 2.5378 (3.1829)	grad_norm 145.0817 (109.6588)	mem 14369MB
[2022-12-20 18:17:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8776 (0.8869)	loss 3.7216 (3.1760)	grad_norm 59.8307 (113.0142)	mem 14369MB
[2022-12-20 18:17:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][50/74]	eta 0:00:21 lr 0.000000	time 0.9031 (0.8846)	loss 3.4737 (3.2262)	grad_norm 143.4886 (115.3752)	mem 14369MB
[2022-12-20 18:18:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8647 (0.8823)	loss 2.8141 (3.2114)	grad_norm 123.0011 (113.5736)	mem 14369MB
[2022-12-20 18:18:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [260/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8806 (0.8809)	loss 3.4898 (3.2007)	grad_norm 89.4876 (111.2360)	mem 14369MB
[2022-12-20 18:18:19 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 260 training takes 0:01:05
[2022-12-20 18:18:19 RepVGGplus-tinyism] (helpers.py 207): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_260.pth saving......
[2022-12-20 18:18:21 RepVGGplus-tinyism] (helpers.py 209): INFO ./output/repvggplus/RepVGGplus-tinyism/default/ckpt_epoch_260.pth saved !!!
[2022-12-20 18:18:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5223 (1.5223)	loss 2.4837 (2.4837)	grad_norm 98.0784 (98.0784)	mem 14369MB
[2022-12-20 18:18:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8835 (0.9341)	loss 2.7886 (2.8841)	grad_norm 104.3500 (91.9524)	mem 14369MB
[2022-12-20 18:18:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8781 (0.9031)	loss 3.5175 (3.0311)	grad_norm 250.5363 (122.0058)	mem 14369MB
[2022-12-20 18:18:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8796 (0.8945)	loss 2.5190 (3.0078)	grad_norm 88.7182 (113.9875)	mem 14369MB
[2022-12-20 18:18:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8775 (0.8899)	loss 3.2833 (3.0648)	grad_norm 100.1451 (116.9751)	mem 14369MB
[2022-12-20 18:19:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8581 (0.8857)	loss 2.5170 (3.0416)	grad_norm 91.4416 (110.9065)	mem 14369MB
[2022-12-20 18:19:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8841 (0.8839)	loss 3.5950 (3.0857)	grad_norm 100.1865 (110.8653)	mem 14369MB
[2022-12-20 18:19:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [261/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8706 (0.8819)	loss 2.1357 (3.1618)	grad_norm 44.6618 (112.8570)	mem 14369MB
[2022-12-20 18:19:26 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 261 training takes 0:01:05
[2022-12-20 18:19:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][0/74]	eta 0:01:53 lr 0.000000	time 1.5362 (1.5362)	loss 2.4416 (2.4416)	grad_norm 78.8118 (78.8118)	mem 14369MB
[2022-12-20 18:19:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8781 (0.9306)	loss 2.2819 (3.1649)	grad_norm 126.8438 (110.1153)	mem 14369MB
[2022-12-20 18:19:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8755 (0.9051)	loss 2.4726 (2.9994)	grad_norm 64.3858 (113.8020)	mem 14369MB
[2022-12-20 18:19:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8775 (0.8977)	loss 2.9541 (2.9828)	grad_norm 107.9815 (110.8177)	mem 14369MB
[2022-12-20 18:20:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8654 (0.8920)	loss 2.7811 (3.0204)	grad_norm 215.9534 (108.6990)	mem 14369MB
[2022-12-20 18:20:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8670 (0.8883)	loss 3.3810 (2.9979)	grad_norm 130.4022 (113.1636)	mem 14369MB
[2022-12-20 18:20:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8682 (0.8852)	loss 3.0988 (3.2392)	grad_norm 91.8085 (113.4419)	mem 14369MB
[2022-12-20 18:20:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [262/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8644 (0.8830)	loss 3.2328 (3.2243)	grad_norm 114.2235 (115.5605)	mem 14369MB
[2022-12-20 18:20:31 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 262 training takes 0:01:05
[2022-12-20 18:20:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5121 (1.5121)	loss 3.7129 (3.7129)	grad_norm 83.7470 (83.7470)	mem 14369MB
[2022-12-20 18:20:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8641 (0.9281)	loss 2.5830 (3.0217)	grad_norm 82.6638 (111.1347)	mem 14369MB
[2022-12-20 18:20:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8735 (0.9010)	loss 2.8108 (3.1664)	grad_norm 158.5738 (115.4930)	mem 14369MB
[2022-12-20 18:20:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8816 (0.8958)	loss 2.5018 (3.2377)	grad_norm 47.8523 (120.9380)	mem 14369MB
[2022-12-20 18:21:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8752 (0.8913)	loss 3.8487 (3.1643)	grad_norm 148.6408 (121.0066)	mem 14369MB
[2022-12-20 18:21:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8767 (0.8884)	loss 6.5687 (3.2541)	grad_norm 127.2335 (121.7813)	mem 14369MB
[2022-12-20 18:21:25 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8794 (0.8867)	loss 3.3736 (3.2244)	grad_norm 146.6701 (123.7234)	mem 14369MB
[2022-12-20 18:21:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [263/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8777 (0.8857)	loss 3.6500 (3.1782)	grad_norm 224.1325 (128.5589)	mem 14369MB
[2022-12-20 18:21:36 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 263 training takes 0:01:05
[2022-12-20 18:21:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5034 (1.5034)	loss 2.1455 (2.1455)	grad_norm 205.3290 (205.3290)	mem 14369MB
[2022-12-20 18:21:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8713 (0.9270)	loss 3.3502 (2.9512)	grad_norm 105.3105 (135.3128)	mem 14369MB
[2022-12-20 18:21:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8835 (0.9002)	loss 2.7380 (3.0083)	grad_norm 91.8090 (121.2195)	mem 14369MB
[2022-12-20 18:22:04 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8641 (0.8900)	loss 2.7676 (3.0349)	grad_norm 126.2736 (121.5954)	mem 14369MB
[2022-12-20 18:22:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8681 (0.8861)	loss 2.8015 (3.1610)	grad_norm 109.3796 (115.9891)	mem 14369MB
[2022-12-20 18:22:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8804 (0.8833)	loss 2.9924 (3.1368)	grad_norm 122.9027 (120.1314)	mem 14369MB
[2022-12-20 18:22:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8686 (0.8815)	loss 2.7316 (3.1024)	grad_norm 103.4008 (114.5308)	mem 14369MB
[2022-12-20 18:22:39 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [264/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8656 (0.8796)	loss 4.8396 (3.1443)	grad_norm 123.0835 (115.5782)	mem 14369MB
[2022-12-20 18:22:41 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 264 training takes 0:01:04
[2022-12-20 18:22:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5147 (1.5147)	loss 2.9983 (2.9983)	grad_norm 163.0219 (163.0219)	mem 14369MB
[2022-12-20 18:22:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8610 (0.9274)	loss 3.4880 (3.2602)	grad_norm 78.1401 (128.4990)	mem 14369MB
[2022-12-20 18:23:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8833 (0.9025)	loss 2.4156 (3.1786)	grad_norm 119.0185 (119.6785)	mem 14369MB
[2022-12-20 18:23:09 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8807 (0.8945)	loss 3.7247 (3.3606)	grad_norm 82.2934 (129.0156)	mem 14369MB
[2022-12-20 18:23:18 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8766 (0.8913)	loss 4.3446 (3.3299)	grad_norm 114.4151 (124.8731)	mem 14369MB
[2022-12-20 18:23:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8768 (0.8889)	loss 2.7163 (3.2627)	grad_norm 84.6409 (118.5223)	mem 14369MB
[2022-12-20 18:23:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8672 (0.8869)	loss 2.6960 (3.1900)	grad_norm 112.5874 (119.7921)	mem 14369MB
[2022-12-20 18:23:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [265/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8836 (0.8858)	loss 2.8932 (3.1479)	grad_norm 104.4806 (119.2246)	mem 14369MB
[2022-12-20 18:23:47 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 265 training takes 0:01:05
[2022-12-20 18:23:48 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5175 (1.5175)	loss 3.9377 (3.9377)	grad_norm 90.7500 (90.7500)	mem 14369MB
[2022-12-20 18:23:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][10/74]	eta 0:01:00 lr 0.000000	time 0.8836 (0.9395)	loss 2.4420 (3.0115)	grad_norm 74.9713 (105.5453)	mem 14369MB
[2022-12-20 18:24:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][20/74]	eta 0:00:49 lr 0.000000	time 0.8657 (0.9084)	loss 3.4761 (3.2381)	grad_norm 77.2233 (108.8678)	mem 14369MB
[2022-12-20 18:24:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8867 (0.8970)	loss 2.5565 (3.1485)	grad_norm 83.1781 (108.3791)	mem 14369MB
[2022-12-20 18:24:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8765 (0.8931)	loss 2.7008 (3.0637)	grad_norm 46.7378 (109.4173)	mem 14369MB
[2022-12-20 18:24:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8708 (0.8887)	loss 3.2251 (3.1379)	grad_norm 230.2700 (115.9974)	mem 14369MB
[2022-12-20 18:24:41 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8779 (0.8857)	loss 2.4587 (3.0863)	grad_norm 63.8390 (115.2227)	mem 14369MB
[2022-12-20 18:24:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [266/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8944 (0.8842)	loss 3.4005 (3.1114)	grad_norm 80.4863 (114.4467)	mem 14369MB
[2022-12-20 18:24:52 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 266 training takes 0:01:05
[2022-12-20 18:24:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][0/74]	eta 0:01:53 lr 0.000000	time 1.5402 (1.5402)	loss 3.3470 (3.3470)	grad_norm 64.0980 (64.0980)	mem 14369MB
[2022-12-20 18:25:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8824 (0.9344)	loss 2.5643 (3.0082)	grad_norm 79.9538 (111.5626)	mem 14369MB
[2022-12-20 18:25:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][20/74]	eta 0:00:49 lr 0.000000	time 0.8670 (0.9082)	loss 2.7963 (2.9913)	grad_norm 76.8387 (101.2100)	mem 14369MB
[2022-12-20 18:25:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8928 (0.8976)	loss 3.3139 (3.0503)	grad_norm 65.8638 (119.0933)	mem 14369MB
[2022-12-20 18:25:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8793 (0.8932)	loss 2.3689 (3.0950)	grad_norm 83.4695 (125.1769)	mem 14369MB
[2022-12-20 18:25:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8716 (0.8888)	loss 6.6143 (3.1558)	grad_norm 136.4441 (121.7917)	mem 14369MB
[2022-12-20 18:25:46 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8706 (0.8864)	loss 2.6928 (3.1689)	grad_norm 58.2785 (116.8525)	mem 14369MB
[2022-12-20 18:25:55 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [267/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8832 (0.8853)	loss 3.5553 (3.2370)	grad_norm 113.2048 (114.1791)	mem 14369MB
[2022-12-20 18:25:58 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 267 training takes 0:01:05
[2022-12-20 18:25:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5085 (1.5085)	loss 3.5743 (3.5743)	grad_norm 156.7831 (156.7831)	mem 14369MB
[2022-12-20 18:26:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][10/74]	eta 0:01:00 lr 0.000000	time 0.8704 (0.9393)	loss 2.6887 (2.9173)	grad_norm 319.3033 (132.4687)	mem 14369MB
[2022-12-20 18:26:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][20/74]	eta 0:00:49 lr 0.000000	time 0.8878 (0.9097)	loss 5.1136 (3.0618)	grad_norm 297.4159 (156.8391)	mem 14369MB
[2022-12-20 18:26:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8907 (0.8997)	loss 2.9589 (3.1359)	grad_norm 79.7612 (143.9569)	mem 14369MB
[2022-12-20 18:26:34 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8927 (0.8952)	loss 2.7442 (3.0565)	grad_norm 76.5607 (129.7930)	mem 14369MB
[2022-12-20 18:26:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8814 (0.8922)	loss 2.9054 (3.0526)	grad_norm 77.1325 (127.2022)	mem 14369MB
[2022-12-20 18:26:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8769 (0.8901)	loss 3.3363 (3.1387)	grad_norm 73.3724 (122.3152)	mem 14369MB
[2022-12-20 18:27:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [268/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8670 (0.8880)	loss 2.5674 (3.1654)	grad_norm 163.2921 (121.2676)	mem 14369MB
[2022-12-20 18:27:03 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 268 training takes 0:01:05
[2022-12-20 18:27:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5168 (1.5168)	loss 3.1521 (3.1521)	grad_norm 153.1810 (153.1810)	mem 14369MB
[2022-12-20 18:27:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8800 (0.9284)	loss 2.8358 (3.5113)	grad_norm 91.9994 (130.5004)	mem 14369MB
[2022-12-20 18:27:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8733 (0.9014)	loss 2.6160 (3.3301)	grad_norm 147.6836 (131.6562)	mem 14369MB
[2022-12-20 18:27:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8814 (0.8952)	loss 5.8607 (3.3764)	grad_norm 88.3925 (127.1664)	mem 14369MB
[2022-12-20 18:27:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8895 (0.8916)	loss 3.3146 (3.3001)	grad_norm 68.0770 (121.8795)	mem 14369MB
[2022-12-20 18:27:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8792 (0.8896)	loss 2.6105 (3.2128)	grad_norm 116.6977 (119.9518)	mem 14369MB
[2022-12-20 18:27:57 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8704 (0.8881)	loss 2.7997 (3.2452)	grad_norm 98.8856 (119.6117)	mem 14369MB
[2022-12-20 18:28:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [269/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8822 (0.8872)	loss 2.6575 (3.1960)	grad_norm 149.4638 (117.7646)	mem 14369MB
[2022-12-20 18:28:09 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 269 training takes 0:01:05
[2022-12-20 18:28:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5227 (1.5227)	loss 3.2640 (3.2640)	grad_norm 119.5342 (119.5342)	mem 14369MB
[2022-12-20 18:28:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8809 (0.9318)	loss 3.1873 (3.0277)	grad_norm 145.0735 (102.8405)	mem 14369MB
[2022-12-20 18:28:28 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8656 (0.9034)	loss 2.3160 (3.0337)	grad_norm 133.4078 (107.0550)	mem 14369MB
[2022-12-20 18:28:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8651 (0.8935)	loss 2.8488 (3.1758)	grad_norm 195.0331 (110.4043)	mem 14369MB
[2022-12-20 18:28:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8666 (0.8887)	loss 3.3605 (3.2552)	grad_norm 170.7846 (117.3780)	mem 14369MB
[2022-12-20 18:28:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8836 (0.8857)	loss 3.0382 (3.2346)	grad_norm 75.4756 (115.0707)	mem 14369MB
[2022-12-20 18:29:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8722 (0.8840)	loss 3.3072 (3.2224)	grad_norm 66.6030 (116.9470)	mem 14369MB
[2022-12-20 18:29:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [270/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8766 (0.8824)	loss 2.7161 (3.1871)	grad_norm 116.6727 (120.4072)	mem 14369MB
[2022-12-20 18:29:14 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 270 training takes 0:01:05
[2022-12-20 18:29:16 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5161 (1.5161)	loss 3.3051 (3.3051)	grad_norm 109.7599 (109.7599)	mem 14369MB
[2022-12-20 18:29:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8847 (0.9317)	loss 2.7411 (3.2573)	grad_norm 118.7292 (109.7966)	mem 14369MB
[2022-12-20 18:29:33 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8790 (0.9035)	loss 2.8440 (3.1139)	grad_norm 82.0413 (109.3868)	mem 14369MB
[2022-12-20 18:29:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8891 (0.8943)	loss 5.1169 (3.2189)	grad_norm 67.2865 (109.0721)	mem 14369MB
[2022-12-20 18:29:50 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8728 (0.8900)	loss 3.1316 (3.2327)	grad_norm 67.5277 (113.2837)	mem 14369MB
[2022-12-20 18:29:59 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8897 (0.8876)	loss 2.4711 (3.2072)	grad_norm 129.6161 (115.7073)	mem 14369MB
[2022-12-20 18:30:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8782 (0.8862)	loss 3.3213 (3.1436)	grad_norm 82.3780 (113.9908)	mem 14369MB
[2022-12-20 18:30:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [271/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8690 (0.8848)	loss 2.6982 (3.1366)	grad_norm 80.2197 (113.4073)	mem 14369MB
[2022-12-20 18:30:19 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 271 training takes 0:01:05
[2022-12-20 18:30:21 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5257 (1.5257)	loss 3.0364 (3.0364)	grad_norm 54.1869 (54.1869)	mem 14369MB
[2022-12-20 18:30:30 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8774 (0.9352)	loss 3.1742 (3.0539)	grad_norm 86.5330 (111.7496)	mem 14369MB
[2022-12-20 18:30:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8677 (0.9040)	loss 5.9698 (3.0576)	grad_norm 78.9735 (115.3886)	mem 14369MB
[2022-12-20 18:30:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8676 (0.8950)	loss 3.5426 (3.0295)	grad_norm 44.5177 (110.6244)	mem 14369MB
[2022-12-20 18:30:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8887 (0.8903)	loss 2.9934 (3.1344)	grad_norm 92.5596 (107.9046)	mem 14369MB
[2022-12-20 18:31:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8643 (0.8863)	loss 2.5919 (3.1084)	grad_norm 99.4585 (108.5648)	mem 14369MB
[2022-12-20 18:31:13 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8749 (0.8851)	loss 4.2472 (3.0735)	grad_norm 89.7465 (106.3519)	mem 14369MB
[2022-12-20 18:31:22 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [272/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8810 (0.8837)	loss 5.1360 (3.1333)	grad_norm 67.6389 (107.7150)	mem 14369MB
[2022-12-20 18:31:25 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 272 training takes 0:01:05
[2022-12-20 18:31:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5166 (1.5166)	loss 2.4666 (2.4666)	grad_norm 119.4145 (119.4145)	mem 14369MB
[2022-12-20 18:31:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8655 (0.9260)	loss 2.9016 (3.3148)	grad_norm 79.8118 (110.2140)	mem 14369MB
[2022-12-20 18:31:44 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8705 (0.8999)	loss 3.4894 (3.1704)	grad_norm 123.4228 (107.6396)	mem 14369MB
[2022-12-20 18:31:52 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8814 (0.8944)	loss 4.5563 (3.2442)	grad_norm 116.5147 (105.9216)	mem 14369MB
[2022-12-20 18:32:01 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8854 (0.8891)	loss 2.4919 (3.2142)	grad_norm 85.9221 (108.0333)	mem 14369MB
[2022-12-20 18:32:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8714 (0.8861)	loss 5.3694 (3.1991)	grad_norm 36.6887 (109.5050)	mem 14369MB
[2022-12-20 18:32:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8681 (0.8835)	loss 3.4050 (3.1937)	grad_norm 66.1375 (105.9382)	mem 14369MB
[2022-12-20 18:32:27 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [273/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8727 (0.8824)	loss 3.0841 (3.2023)	grad_norm 163.9180 (103.9900)	mem 14369MB
[2022-12-20 18:32:30 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 273 training takes 0:01:05
[2022-12-20 18:32:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5012 (1.5012)	loss 2.6241 (2.6241)	grad_norm 71.7351 (71.7351)	mem 14369MB
[2022-12-20 18:32:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8761 (0.9278)	loss 3.2667 (3.2298)	grad_norm 97.2207 (100.0730)	mem 14369MB
[2022-12-20 18:32:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8728 (0.8997)	loss 2.8709 (3.1576)	grad_norm 64.4600 (101.6698)	mem 14369MB
[2022-12-20 18:32:58 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8816 (0.8917)	loss 4.2918 (3.1702)	grad_norm 118.7904 (109.3047)	mem 14369MB
[2022-12-20 18:33:06 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8664 (0.8872)	loss 2.9777 (3.2020)	grad_norm 123.9141 (116.9687)	mem 14369MB
[2022-12-20 18:33:15 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8648 (0.8842)	loss 3.9985 (3.3074)	grad_norm 105.7369 (115.7660)	mem 14369MB
[2022-12-20 18:33:24 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8683 (0.8826)	loss 3.3061 (3.2735)	grad_norm 192.3204 (117.6456)	mem 14369MB
[2022-12-20 18:33:32 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [274/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8716 (0.8809)	loss 2.1947 (3.2014)	grad_norm 120.1167 (117.3628)	mem 14369MB
[2022-12-20 18:33:35 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 274 training takes 0:01:05
[2022-12-20 18:33:36 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][0/74]	eta 0:01:51 lr 0.000000	time 1.5053 (1.5053)	loss 2.5692 (2.5692)	grad_norm 160.6954 (160.6954)	mem 14369MB
[2022-12-20 18:33:45 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8681 (0.9308)	loss 3.7586 (3.1292)	grad_norm 90.1059 (115.8242)	mem 14369MB
[2022-12-20 18:33:54 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8633 (0.9029)	loss 2.6606 (3.4257)	grad_norm 167.2899 (111.6033)	mem 14369MB
[2022-12-20 18:34:03 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8732 (0.8930)	loss 2.8793 (3.3783)	grad_norm 133.7726 (114.9270)	mem 14369MB
[2022-12-20 18:34:11 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8699 (0.8883)	loss 2.7318 (3.2714)	grad_norm 86.7100 (111.1191)	mem 14369MB
[2022-12-20 18:34:20 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8656 (0.8857)	loss 4.8623 (3.2492)	grad_norm 103.7736 (109.2615)	mem 14369MB
[2022-12-20 18:34:29 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8685 (0.8832)	loss 3.5576 (3.2308)	grad_norm 63.2534 (109.8432)	mem 14369MB
[2022-12-20 18:34:38 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [275/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8703 (0.8819)	loss 2.7327 (3.1886)	grad_norm 69.3987 (109.6967)	mem 14369MB
[2022-12-20 18:34:40 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 275 training takes 0:01:05
[2022-12-20 18:34:42 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5163 (1.5163)	loss 3.2558 (3.2558)	grad_norm 167.0797 (167.0797)	mem 14369MB
[2022-12-20 18:34:51 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][10/74]	eta 0:01:02 lr 0.000000	time 0.8680 (0.9837)	loss 2.8097 (3.0954)	grad_norm 126.8547 (135.2204)	mem 14369MB
[2022-12-20 18:35:00 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][20/74]	eta 0:00:50 lr 0.000000	time 0.8734 (0.9293)	loss 2.5117 (3.2433)	grad_norm 113.3499 (126.4769)	mem 14369MB
[2022-12-20 18:35:08 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][30/74]	eta 0:00:40 lr 0.000000	time 0.8637 (0.9105)	loss 3.7996 (3.2389)	grad_norm 160.2705 (125.5892)	mem 14369MB
[2022-12-20 18:35:17 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8736 (0.9029)	loss 3.3038 (3.1270)	grad_norm 116.1665 (120.3234)	mem 14369MB
[2022-12-20 18:35:26 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8696 (0.8971)	loss 2.3556 (3.1508)	grad_norm 171.8992 (123.0434)	mem 14369MB
[2022-12-20 18:35:35 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8667 (0.8932)	loss 2.6515 (3.1754)	grad_norm 80.8219 (122.2323)	mem 14369MB
[2022-12-20 18:35:43 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [276/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8884 (0.8904)	loss 2.1186 (3.1279)	grad_norm 70.4812 (120.4478)	mem 14369MB
[2022-12-20 18:35:46 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 276 training takes 0:01:05
[2022-12-20 18:35:47 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][0/74]	eta 0:01:52 lr 0.000000	time 1.5198 (1.5198)	loss 2.3046 (2.3046)	grad_norm 90.9092 (90.9092)	mem 14369MB
[2022-12-20 18:35:56 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8803 (0.9362)	loss 2.5938 (2.9681)	grad_norm 62.5232 (98.1671)	mem 14369MB
[2022-12-20 18:36:05 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][20/74]	eta 0:00:49 lr 0.000000	time 0.8781 (0.9090)	loss 2.8108 (2.8213)	grad_norm 84.0370 (97.4736)	mem 14369MB
[2022-12-20 18:36:14 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8731 (0.8983)	loss 3.1048 (3.0195)	grad_norm 137.5615 (107.4663)	mem 14369MB
[2022-12-20 18:36:23 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][40/74]	eta 0:00:30 lr 0.000000	time 0.8684 (0.8927)	loss 2.7849 (3.0456)	grad_norm 67.3773 (109.3565)	mem 14369MB
[2022-12-20 18:36:31 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][50/74]	eta 0:00:21 lr 0.000000	time 0.8761 (0.8903)	loss 2.3052 (3.0019)	grad_norm 38.7935 (109.1860)	mem 14369MB
[2022-12-20 18:36:40 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][60/74]	eta 0:00:12 lr 0.000000	time 0.8716 (0.8875)	loss 3.1957 (3.1269)	grad_norm 85.1139 (113.9355)	mem 14369MB
[2022-12-20 18:36:49 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [277/300][70/74]	eta 0:00:03 lr 0.000000	time 0.8715 (0.8858)	loss 4.1311 (3.1852)	grad_norm 131.0855 (117.2207)	mem 14369MB
[2022-12-20 18:36:51 RepVGGplus-tinyism] (train_repvgg.py 217): INFO EPOCH 277 training takes 0:01:05
[2022-12-20 18:36:53 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [278/300][0/74]	eta 0:01:53 lr 0.000000	time 1.5393 (1.5393)	loss 3.0263 (3.0263)	grad_norm 175.5541 (175.5541)	mem 14369MB
[2022-12-20 18:37:02 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [278/300][10/74]	eta 0:00:59 lr 0.000000	time 0.8870 (0.9297)	loss 2.6942 (2.8593)	grad_norm 71.9083 (114.1150)	mem 14369MB
[2022-12-20 18:37:10 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [278/300][20/74]	eta 0:00:48 lr 0.000000	time 0.8672 (0.9016)	loss 2.3888 (3.1619)	grad_norm 146.8813 (117.1577)	mem 14369MB
[2022-12-20 18:37:19 RepVGGplus-tinyism] (train_repvgg.py 210): INFO Train: [278/300][30/74]	eta 0:00:39 lr 0.000000	time 0.8670 (0.8917)	loss 2.5936 (3.1135)	grad_norm 119.7094 (119.4885)	mem 14369MB
