{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.15 ('codeserver_py39')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n codeserver_py39 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openvino-dev\n",
    "#!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import torch\n",
    "sys.path.append(os.path.abspath('../models'))\n",
    "from tinyism import tinyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posencoding=True\n",
    "model=tinyModel(posEncoding=posencoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " weight=\"../weights/resnet18_inst.pth\"\n",
    " model.load_state_dict(torch.load(weight,map_location=torch.device('cpu')))\n",
    " model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.15 ('codeserver_py39')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n codeserver_py39 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "    sys.path.append(os.path.abspath('../datasets'))\n",
    "    from data_loader import preprocess\n",
    "    import cv2\n",
    "    img=cv2.imread(\"../test3.png\")\n",
    "    img=cv2.resize(img,(512,512))\n",
    "    x=preprocess((torch.from_numpy(img).float())).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchout=model(x)\n",
    "x.shape,torchout[0].shape,torchout[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names=['images']\n",
    "output_names = ['output0', 'output1'] \n",
    "dynamic = {'images': {0: 'batch'}}  \n",
    "dynamic['output0'] = {0: 'instances'} \n",
    "dynamic['output1'] = {0: 'instances'}  # shape(1,insts,64,64)\n",
    "\n",
    "\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"tinynet.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = input_names,   # the model's input names\n",
    "                  output_names = output_names, # the model's output names\n",
    "                  dynamic_axes=dynamic\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"tinynet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_outs[0].shape,ort_outs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image=to_numpy(x)\n",
    "torchout1=to_numpy(torchout[0])\n",
    "torchout2=to_numpy(torchout[1])\n",
    "ort_outs[0].shape,ort_outs[1].shape,torchout1.shape,torchout2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.allclose(torchout1, ort_outs[0], rtol=1e-03, atol=1e-05),np.allclose(torchout2, ort_outs[1], rtol=1e-03, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the command for Model Optimizer.\n",
    "from pathlib import Path\n",
    "onnx_path=\"tinynet.onnx\"\n",
    "model_path=\"irmodel\"\n",
    "model_path = Path(model_path)\n",
    "ir_path = model_path.with_suffix(\".xml\")\n",
    "IMAGE_HEIGHT=512\n",
    "IMAGE_WIDTH=512\n",
    "mo_command = f\"\"\"mo\n",
    "                 --input_model \"{onnx_path}\"\n",
    "                 --input_shape \"[1,3, {IMAGE_HEIGHT}, {IMAGE_WIDTH}]\"\n",
    "                 --data_type FP32\n",
    "                 --output_dir \"{model_path}\"\n",
    "                 \"\"\"\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert the ONNX model to OpenVINO:\")\n",
    "display(Markdown(f\"`{mo_command}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exporting ONNX model to IR... This may take a few minutes.\")\n",
    "mo_result = %sx $mo_command\n",
    "print(\"\\n\".join(mo_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_path=Path(\"irmodel/tinynet.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "ie = Core()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ir = ie.read_model(model=ir_path)\n",
    "compiled_model_ir = ie.compile_model(model=model_ir, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output layers.\n",
    "output_layer_ir = compiled_model_ir.output(1)\n",
    "output_layer_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ir = compiled_model_ir([input_image])[output_layer_ir]\n",
    "res_ir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(res_ir,torchout2,rtol=1e-04, atol=1e-05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('codeserver_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca522a4f3a95a8cc19c0c49aa2b52717208ab4d9caac282bf163cf809ab5536"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
